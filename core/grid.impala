struct AABB {
    xmin: real_t,
    xmax: real_t,
    ymin: real_t,
    ymax: real_t,
    zmin: real_t,
    zmax: real_t
}

struct Grid {
    aabb: AABB, // grid bounding box
    world_aabb: AABB, // global grid bounding box
    nx: i32, // number of cells in x dimension
    ny: i32, // number of cells in y dimension
    nz: i32, // number of cells in z dimension
    ncells_capacity: i32, // capacity of cell amount in the grid
    particle_capacity: i32, // particle capacity in grid
    cell_capacity: i32, // cell capacity in grid
    neighborlist_capacity: i32, // capacity of the neighborlists arrays
    ncells: i32, // number of cells in the grid
    nparticles: i32, // number of particles in the grid
    nghost: i32, // number of ghost particles in the grid
    cells_offset_x: i32, // cells offset for x dimension
    cells_offset_y: i32, // cells offset for y dimension
    cells_offset_z: i32, // cells offset for z dimension
    xlength: real_t, // grid length in x dimension for PBC correction
    ylength: real_t, // grid length in y dimension for PBC correction
    zlength: real_t, // grid length in z dimension for PBC correction
    spacing: real_t, // cell spacing

    cell_particles_cpu: Buffer, // particles in each cell [i32]
    cell_sizes_cpu: Buffer, // sizes of each cell [i32]
    particles_cell_cpu: Buffer, // cell assigned to particle [i32]
    masses_cpu: Buffer, // masses of all particles on the CPU: [real_t]
    positions: ArrayData, // positions of all particles on the CPU: [Vector3D]
    positions_copy: ArrayData, // copy positions of all particles on the CPU: [Vector3D]
    velocities: ArrayData, // velocities of all particles on the CPU: [Vector3D]
    velocities_copy: ArrayData, // copy velocities of all particles on the CPU: [Vector3D]
    forces: ArrayData, // forces of all particles on the CPU: [Vector3D]
    neighbors_sizes_cpu: Buffer, // neighbors per cluster on the CPU: [i32]
    neighborlists_cpu: Buffer, // neighborlists on the CPU: [i32]
    send_flags_cpu: Buffer, // send flag for particle [i8]
    cell_list_cpu: Buffer, // cell list on the CPU [i32]
    counter_buffer_cpu: Buffer, // counter buffer on the CPU: [i32]
    resize_buffer_cpu: Buffer, // resize buffer on the CPU: [i32]

    cell_particles_accelerator: Buffer, // particles in each cell [i32]
    cell_sizes_accelerator: Buffer, // sizes of each cell [i32]
    particles_cell_accelerator: Buffer, // cell assigned to particle on the accelerator [i32]
    masses_accelerator: Buffer, // masses of all particles on the accelerator: [real_t]
    neighbors_sizes_accelerator: Buffer, // neighbors per cluster on the accelerator: [i32]
    neighborlists_accelerator: Buffer, // neighborlists on the accelerator: [i32]
    send_flags_accelerator: Buffer, //send flag for particle on accelerator [i8]
    cell_list_accelerator: Buffer, // cell list on the accelerator [i32]
    counter_buffer_accelerator: Buffer, // counter buffer on the accelerator: [i32]
    resize_buffer_accelerator: Buffer, // resize buffer on the accelerator: [i32]
    mutex_accelerator: Buffer // mutex buffer on the accelerator: [i32]
}

fn @ParticleDataLayout() -> ArrayLayout { row_major_order_array(0) }
fn @get_position(i: i32, grid: Grid) -> Vector3D { array_2d_get_vec3(array_dev, ParticleDataLayout(), grid.positions, i) }
fn @set_position(i: i32, grid: Grid, p: Vector3D) -> () { array_2d_set_vec3(array_dev, ParticleDataLayout(), grid.positions, i, p); }
fn @get_velocity(i: i32, grid: Grid) -> Vector3D { array_2d_get_vec3(array_dev, ParticleDataLayout(), grid.velocities, i) }
fn @set_velocity(i: i32, grid: Grid, v: Vector3D) -> () { array_2d_set_vec3(array_dev, ParticleDataLayout(), grid.velocities, i, v); }
fn @get_force(i: i32, grid: Grid) -> Vector3D { array_2d_get_vec3(array_dev, ParticleDataLayout(), grid.forces, i) }
fn @set_force(i: i32, grid: Grid, f: Vector3D) -> () { array_2d_set_vec3(array_dev, ParticleDataLayout(), grid.forces, i, f); }
fn @sort_particles() -> bool { false }
fn @sparse_cell_list() -> bool { false }
fn @get_cell_offset(cell_index: i32, grid: &Grid) -> i32 { cell_index * grid.cell_capacity }
fn @get_neighborlist_offset(cell_index: i32, cluster_index: i32, grid: &Grid) -> i32 {
    grid.neighborlist_capacity * (cell_index * grid.cell_capacity + cluster_index)
}

fn allocate_grid(world_aabb: AABB, aabb: AABB, cell_spacing: f64, cell_capacity: i32, neighborlist_capacity: i32) -> Grid {
    let dev = device();
    let nx = real_floor(((aabb.xmax - aabb.xmin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32 + 1;
    let ny = real_floor(((aabb.ymax - aabb.ymin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32 + 1;
    let nz = real_floor(((aabb.zmax - aabb.zmin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32 + 1;
    let ncells = nx * ny * nz;
    let ncells_capacity = ncells * 4;
    let particle_capacity = ncells_capacity * 32;
    let neighbors_capacity = particle_capacity * neighborlist_capacity;

    let alloc_array = @|| { allocate_array(particle_capacity, 3, sizeof[real_t](), true) };
    let null_buf = Buffer {
        device: 0,
        data: 0 as &[i8],
        size: 0 as i64
    };

    Grid {
        aabb: aabb,
        world_aabb: world_aabb,
        nx: nx,
        ny: ny,
        nz: nz,
        ncells_capacity: ncells_capacity,
        particle_capacity: particle_capacity,
        cell_capacity: cell_capacity,
        neighborlist_capacity: neighborlist_capacity,
        ncells: ncells,
        nparticles: 0,
        nghost: 0,
        cells_offset_x: 0,
        cells_offset_y: 0,
        cells_offset_z: 0,
        xlength: world_aabb.xmax - world_aabb.xmin,
        ylength: world_aabb.ymax - world_aabb.ymin,
        zlength: world_aabb.zmax - world_aabb.zmin,
        spacing: cell_spacing,

        cell_particles_cpu: alloc_cpu(ncells_capacity * cell_capacity * sizeof[i32]()),
        cell_sizes_cpu: alloc_cpu(ncells_capacity * sizeof[i32]()),
        cell_list_cpu: alloc_cpu(ncells_capacity * sizeof[i32]()),
        particles_cell_cpu: alloc_cpu(particle_capacity * sizeof[i32]()),
        masses_cpu: alloc_cpu(particle_capacity * sizeof[real_t]()),
        positions: alloc_array(),
        velocities: alloc_array(),
        positions_copy: alloc_array(),
        velocities_copy: alloc_array(),
        forces: alloc_array(),
        neighbors_sizes_cpu: alloc_cpu(particle_capacity * sizeof[i32]()),
        neighborlists_cpu: alloc_cpu(neighbors_capacity * sizeof[i32]()),
        send_flags_cpu: alloc_cpu(particle_capacity * sizeof[i8]()),
        counter_buffer_cpu: alloc_cpu(sizeof[i32]()),
        resize_buffer_cpu: alloc_cpu(sizeof[i32]()),

        cell_particles_accelerator: dev.alloc(ncells_capacity * cell_capacity * sizeof[i32]()),
        cell_sizes_accelerator: dev.alloc(ncells_capacity * sizeof[i32]()),
        cell_list_accelerator: dev.alloc(ncells_capacity * sizeof[i32]()),
        particles_cell_accelerator: dev.alloc(particle_capacity * sizeof[i32]()),
        masses_accelerator: dev.alloc(particle_capacity * sizeof[real_t]()),
        neighbors_sizes_accelerator: dev.alloc(particle_capacity * sizeof[i32]()),
        neighborlists_accelerator: dev.alloc(neighbors_capacity * sizeof[i32]()),
        send_flags_accelerator: dev.alloc(particle_capacity * sizeof[i8]()),
        counter_buffer_accelerator: dev.alloc(sizeof[i32]()),
        resize_buffer_accelerator: dev.alloc(sizeof[i32]()),
        mutex_accelerator: dev.alloc(sizeof[i32]()),
    }
}

fn rescale_grid(grid: &mut Grid, aabb: AABB) -> () {
    grid.aabb = aabb;
    grid.nx = real_floor(((aabb.xmax - aabb.xmin + (grid.spacing / (2.0 as real_t))) / grid.spacing)) as i32 + 1;
    grid.ny = real_floor(((aabb.ymax - aabb.ymin + (grid.spacing / (2.0 as real_t))) / grid.spacing)) as i32 + 1;
    grid.nz = real_floor(((aabb.zmax - aabb.zmin + (grid.spacing / (2.0 as real_t))) / grid.spacing)) as i32 + 1;
    grid.ncells = grid.nx * grid.ny * grid.nz;

    if !sparse_cell_list() && grid.ncells > grid.ncells_capacity {
        reallocate_ncells_capacity(grid, grid.ncells * 4);
    }
}

fn deallocate_grid(grid: &mut Grid) -> () {
    grid.nparticles = 0;
    grid.nghost = 0;

    release(grid.cell_particles_cpu);
    release(grid.cell_sizes_cpu);
    release(grid.cell_list_cpu);
    release(grid.particles_cell_cpu);
    release(grid.masses_cpu);
    release_array(grid.positions);
    release_array(grid.positions_copy);
    release_array(grid.velocities);
    release_array(grid.velocities_copy);
    release_array(grid.forces);
    release(grid.neighbors_sizes_cpu);
    release(grid.neighborlists_cpu);
    release(grid.send_flags_cpu);
    release(grid.counter_buffer_cpu);
    release(grid.resize_buffer_cpu);

    release(grid.cell_particles_accelerator);
    release(grid.cell_sizes_accelerator);
    release(grid.cell_list_accelerator);
    release(grid.particles_cell_accelerator);
    release(grid.masses_accelerator);
    release(grid.send_flags_accelerator);
    release(grid.neighbors_sizes_accelerator);
    release(grid.neighborlists_accelerator);
    release(grid.counter_buffer_accelerator);
    release(grid.resize_buffer_accelerator);
    release(grid.mutex_accelerator);
}

fn reallocate_buffer(buffer: &mut Buffer, size: i32, elem_size: i32, @preserve: bool, allocate: fn(i32) -> Buffer) -> () {
    let new_buffer = allocate(size * elem_size);

    if preserve {
        copy(*buffer, new_buffer);
    }

    release(*buffer);
    *buffer = new_buffer;
}

// Do not preserve data in buffers
fn reallocate_ncells_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_ncells_capacity()", capacity);

    let dev = device();

    release(grid.cell_particles_cpu);
    release(grid.cell_sizes_cpu);
    release(grid.cell_list_cpu);
    release(grid.cell_particles_accelerator);
    release(grid.cell_sizes_accelerator);

    grid.cell_particles_cpu = alloc_cpu(capacity * grid.cell_capacity * sizeof[i32]());
    grid.cell_sizes_cpu = alloc_cpu(capacity * sizeof[i32]());
    grid.cell_list_cpu = alloc_cpu(capacity * sizeof[i32]());
    grid.cell_particles_accelerator = dev.alloc(capacity * grid.cell_capacity * sizeof[i32]());
    grid.cell_sizes_accelerator = dev.alloc(capacity * sizeof[i32]());
    grid.cell_list_accelerator = dev.alloc(capacity * sizeof[i32]());
    grid.ncells_capacity = capacity;
}

fn reallocate_particle_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_particle_capacity()", capacity);

    let dev = device();
    let neighborlists_capacity = capacity * grid.neighborlist_capacity;
    let realloc_buf = |buf, buf_acc, size, elem_size, preserve| {
        reallocate_buffer(buf, size, elem_size, preserve, alloc_cpu);
        release(*buf_acc);
        *buf_acc = dev.alloc(size * elem_size);
    };

    let realloc_arr = |arr| { reallocate_array(arr, capacity, 3, sizeof[real_t](), true); };

    realloc_buf(&mut grid.particles_cell_cpu, &mut grid.particles_cell_accelerator, capacity, sizeof[i32](), false);
    realloc_buf(&mut grid.masses_cpu, &mut grid.masses_accelerator, capacity, sizeof[real_t](), true);
    realloc_arr(&mut grid.positions);
    realloc_arr(&mut grid.velocities);
    realloc_arr(&mut grid.forces);
    realloc_buf(&mut grid.neighbors_sizes_cpu, &mut grid.neighbors_sizes_accelerator, capacity, sizeof[i32](), false);
    realloc_buf(&mut grid.send_flags_cpu, &mut grid.send_flags_accelerator, capacity, sizeof[i8](), true);
    realloc_buf(&mut grid.neighborlists_cpu, &mut grid.neighborlists_accelerator, neighborlists_capacity, sizeof[i32](), false);

    grid.particle_capacity = capacity;
}

fn reallocate_cell_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_cell_capacity()", capacity);

    let dev = device();
    release(grid.cell_particles_cpu);
    release(grid.cell_particles_accelerator);
    grid.cell_particles_cpu = alloc_cpu(capacity * grid.ncells_capacity * sizeof[i32]());
    grid.cell_particles_accelerator = dev.alloc(capacity * grid.ncells_capacity * sizeof[i32]());
    grid.cell_capacity = capacity;
}

fn reallocate_neighborlist_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_neighborlist_capacity()", capacity);

    let dev = device();

    release(grid.neighborlists_cpu);
    release(grid.neighborlists_accelerator);

    grid.neighborlists_cpu = alloc_cpu(capacity * grid.particle_capacity * sizeof[i32]());
    grid.neighborlists_accelerator = dev.alloc(capacity * grid.particle_capacity * sizeof[i32]());
    grid.neighborlist_capacity = capacity;
}

fn initialize_grid(
    masses: &[real_t],
    positions: &[Vector3D],
    velocities: &[Vector3D],
    nparticles: i32,
    grid: &mut Grid,
    allocate: fn(i32) -> Buffer) -> () {

    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    range(0, grid.ncells, |cell_index| {
        cell_sizes(cell_index) = 0;
    });

    range(0, nparticles, |i| {
        insert_particle(masses(i), positions(i), velocities(i), grid, allocate);
    });
}

fn insert_particle(mass: real_t, position: Vector3D, velocity: Vector3D, grid: &mut Grid, allocate: fn(i32) -> Buffer) -> () {
    let null_vec = Vector3D { x: 0.0 as real_t, y: 0.0 as real_t, z: 0.0 as real_t };
    let particle_index = grid.nparticles;
    let masses = get_array_of_reals(grid.masses_cpu);
    let neighbors_sizes = get_array_of_i32(grid.neighbors_sizes_cpu);

    if particle_index >= grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + 10;
        reallocate_particle_capacity(grid, new_capacity);
    }

    masses(particle_index) = mass;
    array_2d_set_vec3(array_host, ParticleDataLayout(), grid.positions, particle_index, position);
    array_2d_set_vec3(array_host, ParticleDataLayout(), grid.velocities, particle_index, velocity);
    array_2d_set_vec3(array_host, ParticleDataLayout(), grid.forces, particle_index, null_vec);
    neighbors_sizes(particle_index) = 0;

    grid.nparticles++;
}

fn delete_particle(particle_index: i32, grid: &mut Grid) -> () {
    swap_particles(particle_index, grid.nparticles - 1, grid);
    grid.nparticles--;
}

fn add_local_slots(slots: i32, grid: &mut Grid) -> i32 {
    let first_particle_index = grid.nparticles;

    if grid.nghost > 0 {
        print_string("Problem: adding local slots when there are ghost particles!\n");
    }

    if first_particle_index + slots > grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + slots;
        reallocate_particle_capacity(grid, new_capacity);
    }

    grid.nparticles += slots;
    first_particle_index
}

fn add_ghost_slots(slots: i32, grid: &mut Grid) -> i32 {
    let first_particle_index = grid.nparticles + grid.nghost;

    if first_particle_index + slots > grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + slots;
        reallocate_particle_capacity(grid, new_capacity);
    }

    grid.nghost += slots;
    first_particle_index
}

// Particles must be at the same cell
fn swap_particles(i: i32, j: i32, grid: &mut Grid) -> () {
    swap_real(i, j, grid.masses_cpu);
    array_2d_swap_vec3(ParticleDataLayout(), grid.positions, i, j);
    array_2d_swap_vec3(ParticleDataLayout(), grid.velocities, i, j);
}

fn crop_empty_region(grid: &mut Grid) -> () {
    let b = AABB {
        xmin: grid.aabb.xmax,
        xmax: grid.aabb.xmin,
        ymin: grid.aabb.ymax,
        ymax: grid.aabb.ymin,
        zmin: grid.aabb.zmax,
        zmax: grid.aabb.zmin
    };

    let red_aabb_fn = @|aabb1: AABB, aabb2: AABB| {
        AABB {
            xmin: select(aabb1.xmin < aabb2.xmin, aabb1.xmin, aabb2.xmin),
            xmax: select(aabb1.xmax > aabb2.xmax, aabb1.xmax, aabb2.xmax),
            ymin: select(aabb1.ymin < aabb2.ymin, aabb1.ymin, aabb2.ymin),
            ymax: select(aabb1.ymax > aabb2.ymax, aabb1.ymax, aabb2.ymax),
            zmin: select(aabb1.zmin < aabb2.zmin, aabb1.zmin, aabb2.zmin),
            zmax: select(aabb1.zmax > aabb2.zmax, aabb1.zmax, aabb2.zmax)
        }
    };

    let const_grid = *grid;
    let aabb = reduce_aabb(grid.nparticles, b, red_aabb_fn, @|i| {
        let pos = get_position(i, const_grid);

        AABB {
            xmin: pos.x,
            xmax: pos.x,
            ymin: pos.y,
            ymax: pos.y,
            zmin: pos.z,
            zmax: pos.z
        }
    });

    let cells_x_beg = real_floor((aabb.xmin - grid.aabb.xmin) / grid.spacing) as i32 - 1;
    let cells_x_end = real_floor((aabb.xmax - grid.aabb.xmin) / grid.spacing) as i32 + 2;
    let cells_y_beg = real_floor((aabb.ymin - grid.aabb.ymin) / grid.spacing) as i32 - 1;
    let cells_y_end = real_floor((aabb.ymax - grid.aabb.ymin) / grid.spacing) as i32 + 2;
    let cells_z_beg = real_floor((aabb.zmin - grid.aabb.zmin) / grid.spacing) as i32 - 1;
    let cells_z_end = real_floor((aabb.zmax - grid.aabb.zmin) / grid.spacing) as i32 + 2;

    grid.nx = cells_x_end - cells_x_beg;
    grid.ny = cells_y_end - cells_y_beg;
    grid.nz = cells_z_end - cells_z_beg;
    grid.ncells = grid.nx * grid.ny * grid.nz;
    grid.cells_offset_x = cells_x_beg;
    grid.cells_offset_y = cells_y_beg;
    grid.cells_offset_z = cells_z_beg;

    if grid.ncells >= grid.ncells_capacity {
        reallocate_ncells_capacity(grid, grid.ncells + 20);
    }
}

fn fill_cells(grid: &mut Grid, @ghost: bool) -> () {
    if sparse_cell_list() {
        crop_empty_region(grid);
    }

    let dev = device();
    let mut resize_cell = 1;

    while resize_cell > 0 {
        let const_grid = *grid;
        reset_resize(const_grid);

        cells(const_grid, |cell_index| {
            let cell_sizes = get_cell_sizes(const_grid);
            cell_sizes(cell_index) = 0;
        });

        particles(ghost, const_grid, |i, _, _, _| {
            let pos = get_position(i, const_grid);
            let cell_particles = get_cell_particles(const_grid);
            let particles_cell = get_particles_cell(const_grid);
            let cell_sizes = get_cell_sizes(const_grid);
            let resize_buf = get_resize_buffer(const_grid);
            let cell_index = flatten_index(compute_cell_position(pos, const_grid), const_grid);

            if cell_index >= 0 && cell_index < const_grid.ncells {
                let cell_particle_index = dev.atomic_add_i32(&mut cell_sizes(cell_index), 1);

                if cell_particle_index >= const_grid.cell_capacity {
                    if resize_buf(0) < cell_particle_index {
                        resize_buf(0) = cell_particle_index;
                    }
                } else {
                    let cell_offset = get_cell_offset(cell_index, const_grid);
                    cell_particles(cell_offset + cell_particle_index) = i;
                    particles_cell(i) = cell_index;
                }
            }
        });

        resize_cell = get_resize(const_grid);

        if resize_cell > 0 {
            reallocate_cell_capacity(grid, resize_cell * 2);
        }
    }
}

fn distribute_particles(grid: &mut Grid) -> () {
    if sort_particles() {
        fill_cells(grid, false);

        let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
        let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
        let mut offset = 0;

        range(0, grid.ncells, |cell_index| {
            let cell_offset = get_cell_offset(cell_index, grid);

            range(0, cell_sizes(cell_index), |cell_particle_index| {
                let old_index = cell_particles(cell_offset + cell_particle_index);
                let new_index = offset + cell_particle_index;
                array_2d_copy_vec3(ParticleDataLayout(), grid.positions, grid.positions_copy, old_index, new_index);
                array_2d_copy_vec3(ParticleDataLayout(), grid.velocities, grid.velocities_copy, old_index, new_index);
            });

            offset += cell_sizes(cell_index);
        });

        range(grid.nparticles, grid.nparticles + grid.nghost, |ghost_index| {
            array_2d_copy_vec3(ParticleDataLayout(), grid.positions, grid.positions_copy, ghost_index, ghost_index);
        });

        let pos_copy = grid.positions;
        let vel_copy = grid.velocities;
        grid.positions = grid.positions_copy;
        grid.velocities = grid.velocities_copy;
        grid.positions_copy = pos_copy;
        grid.velocities_copy = vel_copy;
    }

    fill_cells(grid, true);
}

fn copy_to_accelerator(grid: &Grid) -> () {
    let dev = device();
    dev.transfer(grid.cell_particles_cpu, grid.cell_particles_accelerator);
    dev.transfer(grid.cell_sizes_cpu, grid.cell_sizes_accelerator);
    dev.transfer(grid.particles_cell_cpu, grid.particles_cell_accelerator);
    dev.transfer(grid.masses_cpu, grid.masses_accelerator);
    transfer_array_to_device(grid.positions);
    transfer_array_to_device(grid.velocities);
}

fn copy_from_accelerator(grid: &Grid) -> () {
    device().transfer(grid.masses_accelerator, grid.masses_cpu);
    transfer_array_to_host(grid.positions);
    transfer_array_to_host(grid.velocities);
    transfer_array_to_host(grid.forces);
}

fn write_grid_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    grid: &Grid) -> i32 {

    let grid_masses = get_array_of_reals(grid.masses_cpu);

    range(0, grid.nparticles, |particle_index| {
        masses(particle_index) = grid_masses(particle_index);
        positions(particle_index) = array_2d_get_vec3(array_host, ParticleDataLayout(), grid.positions, particle_index);
        velocities(particle_index) = array_2d_get_vec3(array_host, ParticleDataLayout(), grid.velocities, particle_index);
        forces(particle_index) = array_2d_get_vec3(array_host, ParticleDataLayout(), grid.forces, particle_index);
    });

    grid.nparticles
}

fn write_grid_ghost_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    grid: &Grid) -> i32 {

    let grid_masses = get_array_of_reals(grid.masses_cpu);

    range(grid.nparticles, grid.nparticles + grid.nghost, |particle_index| {
        let index = particle_index - grid.nparticles;
        masses(index) = grid_masses(particle_index);
        positions(index) = array_2d_get_vec3(array_host, ParticleDataLayout(), grid.positions, particle_index);
        velocities(index) = array_2d_get_vec3(array_host, ParticleDataLayout(), grid.velocities, particle_index);
        forces(index) = array_2d_get_vec3(array_host, ParticleDataLayout(), grid.forces, particle_index);
    });

    grid.nparticles
}

fn write_grid_aabb_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    grid: &Grid) -> i32 {

    range(0, 2, |i| {
        range(0, 2, |j| {
            range(0, 2, |k| {
                let index = k * 4 + j * 2 + i;

                masses(index) = 0.0;
                positions(index) = Vector3D {
                    x: select(i == 0, grid.aabb.xmin, grid.aabb.xmax),
                    y: select(j == 0, grid.aabb.ymin, grid.aabb.ymax),
                    z: select(k == 0, grid.aabb.zmin, grid.aabb.zmax)
                };

                velocities(index) = Vector3D { x: 0.0, y: 0.0, z: 0.0 };
                forces(index) = Vector3D { x: 0.0, y: 0.0, z: 0.0 };
            });
        });
    });

    grid.nparticles
}

fn compute_cell_position(position: Vector3D, grid: Grid) -> [i32 * 3] {
    let i = real_floor(((position.x - grid.aabb.xmin) / grid.spacing) as real_t) as i32;
    let j = real_floor(((position.y - grid.aabb.ymin) / grid.spacing) as real_t) as i32;
    let k = real_floor(((position.z - grid.aabb.zmin) / grid.spacing) as real_t) as i32;
    [i, j, k]
}

fn is_within_domain(position: Vector3D, aabb: AABB) -> bool {
    position.x >= aabb.xmin && position.x <= aabb.xmax &&
    position.y >= aabb.ymin && position.y <= aabb.ymax &&
    position.z >= aabb.zmin && position.z <= aabb.zmax
}

fn flatten_index(cell_index: [i32 * 3], grid: &Grid) -> i32 {
    if sparse_cell_list() {
        ((cell_index(2) - grid.cells_offset_z) * grid.ny + (cell_index(1) - grid.cells_offset_y)) * grid.nx +
        cell_index(0) - grid.cells_offset_x
    } else {
        (cell_index(2) * grid.ny + cell_index(1)) * grid.nx + cell_index(0)
    }
}
