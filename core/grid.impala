struct AABB {
    xmin: real_t,
    xmax: real_t,
    ymin: real_t,
    ymax: real_t,
    zmin: real_t,
    zmax: real_t
}

struct Grid {
    aabb: AABB, // grid bounding box
    world_aabb: AABB, // global grid bounding box
    nx: i32, // number of cells in x dimension
    ny: i32, // number of cells in y dimension
    nz: i32, // number of cells in z dimension
    ncells_capacity: i32, // capacity of cell amount in the grid
    particle_capacity: i32, // particle capacity in grid
    cell_capacity: i32, // cell capacity in grid
    neighborlist_capacity: i32, // capacity of the neighborlists arrays
    ncells: i32, // number of cells in the grid
    nparticles: i32, // number of particles in the grid
    nghost: i32, // number of ghost particles in the grid
    xlength: real_t, // grid length in x dimension for PBC correction
    ylength: real_t, // grid length in y dimension for PBC correction
    zlength: real_t, // grid length in z dimension for PBC correction
    spacing: real_t, // cell spacing

    cell_particles_cpu: Buffer, // particles in each cell [i32]
    cell_sizes_cpu: Buffer, // sizes of each cell [i32]
    particles_cell_cpu: Buffer, // cell assigned to particle [i32]
    masses_cpu: Buffer, // masses of all particles on the CPU: [real_t]
    positions_cpu: Array, // positions of all particles on the CPU: [Vector3D]
    velocities_cpu: Array, // velocities of all particles on the CPU: [Vector3D]
    positions_copy_cpu: Array, // copy positions of all particles on the CPU: [Vector3D]
    velocities_copy_cpu: Array, // copy velocities of all particles on the CPU: [Vector3D]
    forces_cpu: Array, // forces of all particles on the CPU: [Vector3D]
    neighbors_sizes_cpu: Buffer, // neighbors per cluster on the CPU: [i32]
    neighborlists_cpu: Buffer, // neighborlists on the CPU: [i32]
    resize_buffer_cpu: Buffer, // resize buffer on the CPU: [i32]
    send_flags_cpu: Buffer, // send flag for particle [i8]

    cell_particles_accelerator: Buffer, // particles in each cell [i32]
    cell_sizes_accelerator: Buffer, // sizes of each cell [i32]
    particles_cell_accelerator: Buffer, // cell assigned to particle on the accelerator [i32]
    masses_accelerator: Buffer, // masses of all particles on the accelerator: [real_t]
    positions_accelerator: Array, // positions of all particles on the accelerator: [Vector3D]
    velocities_accelerator: Array, // velocities of all particles on the accelerator: [Vector3D]
    forces_accelerator: Array, // forces of all particles on the accelerator: [Vector3D]
    neighbors_sizes_accelerator: Buffer, // neighbors per cluster on the accelerator: [i32]
    neighborlists_accelerator: Buffer, // neighborlists on the accelerator: [i32]
    resize_buffer_accelerator: Buffer, // resize buffer on the accelerator: [i32]
    send_flags_accelerator: Buffer //send flag for particle on accelerator [i8]
}

fn @sort_particles() -> bool { false }
fn get_cell_offset(cell_index: i32, grid: &Grid) -> i32 { cell_index * grid.cell_capacity }
fn get_neighborlist_offset(cell_index: i32, cluster_index: i32, grid: &Grid) -> i32 {
    grid.neighborlist_capacity * (cell_index * grid.cell_capacity + cluster_index)
}

fn allocate_grid(world_aabb: AABB, aabb: AABB, cell_spacing: f64, cell_capacity: i32, neighborlist_capacity: i32) -> Grid {
    let nx = real_floor(((aabb.xmax - aabb.xmin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32 + 1;
    let ny = real_floor(((aabb.ymax - aabb.ymin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32 + 1;
    let nz = real_floor(((aabb.zmax - aabb.zmin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32 + 1;

    let ncells = nx * ny * nz;
    let ncells_capacity = ncells * 4;
    let particle_capacity = ncells_capacity * 32;
    let neighbors_capacity = particle_capacity * neighborlist_capacity;

    let null_buf = Buffer {
        device: 0,
        data: 0 as &[i8],
        size: 0 as i64
    };

    let alloc_array = @|alloc_func| { column_major_order_array(particle_capacity, 3, sizeof[real_t](), alloc_func) };

    Grid {
        aabb: aabb,
        world_aabb: world_aabb,
        nx: nx,
        ny: ny,
        nz: nz,
        ncells_capacity: ncells_capacity,
        particle_capacity: particle_capacity,
        cell_capacity: cell_capacity,
        neighborlist_capacity: neighborlist_capacity,
        ncells: ncells,
        nparticles: 0,
        nghost: 0,
        xlength: world_aabb.xmax - world_aabb.xmin,
        ylength: world_aabb.ymax - world_aabb.ymin,
        zlength: world_aabb.zmax - world_aabb.zmin,
        spacing: cell_spacing,

        cell_particles_cpu: alloc_cpu(ncells_capacity * cell_capacity * sizeof[i32]()),
        cell_sizes_cpu: alloc_cpu(ncells_capacity * sizeof[i32]()),
        particles_cell_cpu: alloc_cpu(particle_capacity * sizeof[i32]()),
        masses_cpu: alloc_cpu(particle_capacity * sizeof[real_t]()),
        positions_cpu: alloc_array(alloc_cpu),
        velocities_cpu: alloc_array(alloc_cpu),
        positions_copy_cpu: alloc_array(alloc_cpu),
        velocities_copy_cpu: alloc_array(alloc_cpu),
        forces_cpu: alloc_array(alloc_cpu),
        neighbors_sizes_cpu: alloc_cpu(particle_capacity * sizeof[i32]()),
        neighborlists_cpu: alloc_cpu(neighbors_capacity * sizeof[i32]()),
        send_flags_cpu: alloc_cpu(particle_capacity * sizeof[i8]()),
        resize_buffer_cpu: alloc_cpu(sizeof[i32]()),

        cell_particles_accelerator: accelerator_allocate(ncells_capacity * cell_capacity * sizeof[i32]()),
        cell_sizes_accelerator: accelerator_allocate(ncells_capacity * sizeof[i32]()),
        particles_cell_accelerator: accelerator_allocate(particle_capacity * sizeof[i32]()),
        masses_accelerator: accelerator_allocate(particle_capacity * sizeof[real_t]()),
        positions_accelerator: alloc_array(accelerator_allocate),
        velocities_accelerator: alloc_array(accelerator_allocate),
        forces_accelerator: alloc_array(accelerator_allocate),
        neighbors_sizes_accelerator: accelerator_allocate(particle_capacity * sizeof[i32]()),
        neighborlists_accelerator: accelerator_allocate(neighbors_capacity * sizeof[i32]()),
        send_flags_accelerator: accelerator_allocate(particle_capacity * sizeof[i8]()),
        resize_buffer_accelerator: accelerator_allocate(sizeof[i32]())
    }
}

fn rescale_grid(grid: &mut Grid, aabb: AABB) -> () {
    grid.aabb = aabb;
    grid.nx = real_floor(((aabb.xmax - aabb.xmin + (grid.spacing / (2.0 as real_t))) / grid.spacing)) as i32 + 1;
    grid.ny = real_floor(((aabb.ymax - aabb.ymin + (grid.spacing / (2.0 as real_t))) / grid.spacing)) as i32 + 1;
    grid.nz = real_floor(((aabb.zmax - aabb.zmin + (grid.spacing / (2.0 as real_t))) / grid.spacing)) as i32 + 1;
    grid.ncells = grid.nx * grid.ny * grid.nz;

    if grid.ncells > grid.ncells_capacity {
        reallocate_ncells_capacity(grid, grid.ncells * 4);
    }
}

fn deallocate_grid(grid: &mut Grid) -> () {
    grid.nparticles = 0;
    grid.nghost = 0;

    release(grid.cell_particles_cpu);
    release(grid.cell_sizes_cpu);
    release(grid.particles_cell_cpu);
    release(grid.masses_cpu);
    release_array(grid.positions_cpu);
    release_array(grid.velocities_cpu);
    release_array(grid.positions_copy_cpu);
    release_array(grid.velocities_copy_cpu);
    release_array(grid.forces_cpu);
    release(grid.neighbors_sizes_cpu);
    release(grid.neighborlists_cpu);
    release(grid.send_flags_cpu);
    release(grid.resize_buffer_cpu);

    release(grid.cell_particles_accelerator);
    release(grid.cell_sizes_accelerator);
    release(grid.particles_cell_accelerator);
    release(grid.masses_accelerator);
    release_array(grid.positions_accelerator);
    release_array(grid.velocities_accelerator);
    release_array(grid.forces_accelerator);
    release(grid.send_flags_accelerator);
    release(grid.neighbors_sizes_accelerator);
    release(grid.neighborlists_accelerator);
    release(grid.resize_buffer_accelerator);
}

fn reallocate_buffer(buffer: &mut Buffer, size: i32, elem_size: i32, @preserve: bool, allocate: fn(i32) -> Buffer) -> () {
    let new_buffer = allocate(size * elem_size);

    if preserve {
        copy(*buffer, new_buffer);
    }

    release(*buffer);
    *buffer = new_buffer;
}

fn reallocate_cell_buffer(grid: &Grid, buffer: &mut Buffer, capacity: i32, elem_size: i32, allocate: fn(i32) -> Buffer) -> () {
    let new_buffer = allocate(capacity * grid.ncells_capacity * elem_size);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    range(0, grid.ncells, |cell_index| {
        let cell_offset = get_cell_offset(cell_index, grid);
        let cell_size = cell_sizes(cell_index);
        let new_offset = cell_index * capacity;

        copy_offset(*buffer, cell_offset * elem_size, new_buffer, new_offset * elem_size, cell_size * elem_size);
    });

    release(*buffer);
    *buffer = new_buffer;
}

// Do not preserve data in buffers
fn reallocate_ncells_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_ncells_capacity()", capacity);

    release(grid.cell_particles_cpu);
    release(grid.cell_sizes_cpu);
    release(grid.cell_particles_accelerator);
    release(grid.cell_sizes_accelerator);

    grid.cell_particles_cpu = alloc_cpu(capacity * grid.cell_capacity * sizeof[i32]());
    grid.cell_sizes_cpu = alloc_cpu(capacity * sizeof[i32]());
    grid.cell_particles_accelerator = accelerator_allocate(capacity * grid.cell_capacity * sizeof[i32]());
    grid.cell_sizes_accelerator = accelerator_allocate(capacity * sizeof[i32]());

    grid.ncells_capacity = capacity;
}

fn reallocate_particle_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_particle_capacity()", capacity);

    let neighborlists_capacity = capacity * grid.neighborlist_capacity;
    let realloc_buf = |buf, buf_acc, size, elem_size, preserve| {
        reallocate_buffer(buf, size, elem_size, preserve, alloc_cpu);
        release(*buf_acc);
        *buf_acc = accelerator_allocate(size * elem_size);
    };

    let realloc_arr = |arr, arr_acc| {
        reallocate_array(arr, capacity, 3, sizeof[real_t](), true, alloc_cpu);
        reallocate_array(arr_acc, capacity, 3, sizeof[real_t](), false, accelerator_allocate);
    };

    realloc_buf(&mut grid.particles_cell_cpu, &mut grid.particles_cell_accelerator, capacity, sizeof[i32](), false);
    realloc_buf(&mut grid.masses_cpu, &mut grid.masses_accelerator, capacity, sizeof[real_t](), true);
    realloc_arr(&mut grid.positions_cpu, &mut grid.positions_accelerator);
    realloc_arr(&mut grid.velocities_cpu, &mut grid.velocities_accelerator);
    realloc_arr(&mut grid.forces_cpu, &mut grid.forces_accelerator);
    realloc_buf(&mut grid.neighbors_sizes_cpu, &mut grid.neighbors_sizes_accelerator, capacity, sizeof[i32](), false);
    realloc_buf(&mut grid.send_flags_cpu, &mut grid.send_flags_accelerator, capacity, sizeof[i8](), true);
    realloc_buf(&mut grid.neighborlists_cpu, &mut grid.neighborlists_accelerator, neighborlists_capacity, sizeof[i32](), false);

    grid.particle_capacity = capacity;
}

fn reallocate_cell_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_cell_capacity()", capacity);

    reallocate_cell_buffer(grid, &mut grid.cell_particles_cpu, capacity, sizeof[i32](), alloc_cpu);
    release(grid.cell_particles_accelerator);
    grid.cell_particles_accelerator = accelerator_allocate(capacity * grid.ncells_capacity * sizeof[i32]());

    grid.cell_capacity = capacity;
}

fn reallocate_neighborlist_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_i32_with_rank("reallocate_neighborlist_capacity()", capacity);

    release(grid.neighborlists_cpu);
    release(grid.neighborlists_accelerator);

    grid.neighborlists_cpu = alloc_cpu(capacity * grid.particle_capacity * sizeof[i32]());
    grid.neighborlists_accelerator = accelerator_allocate(capacity * grid.particle_capacity * sizeof[i32]());

    grid.neighborlist_capacity = capacity;
}

fn initialize_grid(
    masses: &[real_t],
    positions: &[Vector3D],
    velocities: &[Vector3D],
    nparticles: i32,
    grid: &mut Grid,
    allocate: fn(i32) -> Buffer) -> () {

    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    range(0, grid.ncells, |cell_index| { cell_sizes(cell_index) = 0; });

    for i in range(0, nparticles) {
        insert_particle(masses(i), positions(i), velocities(i), grid, allocate);
    }
}

fn insert_particle(mass: real_t, position: Vector3D, velocity: Vector3D, grid: &mut Grid, allocate: fn(i32) -> Buffer) -> () {
    let null_vec = Vector3D { x: 0.0 as real_t, y: 0.0 as real_t, z: 0.0 as real_t };
    let particle_index = grid.nparticles;
    let world_aabb = grid.world_aabb;

    if particle_index >= grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + 10;
        reallocate_particle_capacity(grid, new_capacity);
    }

    set_real(particle_index, grid.masses_cpu, mass);
    set_array_value(grid.positions_cpu, particle_index, position);
    set_array_value(grid.velocities_cpu, particle_index, velocity);
    set_array_value(grid.forces_cpu, particle_index, null_vec);
    set_i32(particle_index, grid.neighbors_sizes_cpu, 0);

    grid.nparticles++;
}

fn delete_particle(particle_index: i32, grid: &mut Grid) -> () {
    swap_particles(particle_index, grid.nparticles - 1, grid);
    grid.nparticles--;
}

fn add_local_slots(slots: i32, grid: &mut Grid) -> i32 {
    let first_particle_index = grid.nparticles;

    if grid.nghost > 0 {
        print_string("Problem: adding local slots when there are ghost particles!\n");
    }

    if first_particle_index + slots > grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + slots;
        reallocate_particle_capacity(grid, new_capacity);
    }

    grid.nparticles += slots;
    first_particle_index
}

fn add_ghost_slots(slots: i32, grid: &mut Grid) -> i32 {
    let first_particle_index = grid.nparticles + grid.nghost;

    if first_particle_index + slots > grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + slots;
        reallocate_particle_capacity(grid, new_capacity);
    }

    grid.nghost += slots;
    first_particle_index
}

// Particles must be at the same cell
fn swap_particles(i: i32, j: i32, grid: &mut Grid) -> () {
    swap_real(i, j, grid.masses_cpu);
    swap_array_value(i, j, grid.positions_cpu);
    swap_array_value(i, j, grid.velocities_cpu);
}

fn fill_cells(grid: &mut Grid, nparticles: i32) -> () {
    let mut resize = 1;

    while resize > 0 {
        let const_grid = *grid;

        reset_resize(const_grid);

        iterate_cells(const_grid, |cell_index| {
            let cell_sizes = get_cell_sizes(const_grid);
            cell_sizes(cell_index) = 0;
        });

        loop_accelerator(const_grid, |i, _, _, _| {
            let pos = get_position(i, const_grid);
            let cell_particles = get_cell_particles(const_grid);
            let particles_cell = get_particles_cell(const_grid);
            let cell_sizes = get_cell_sizes(const_grid);
            let resize_buf = get_resize_buffer(const_grid);
            let cell_index = compute_cell_position(pos, true, const_grid);
            let flat_index = flatten_index(cell_index, const_grid);
            let cell_particle_index = atomic_add_i32(&mut cell_sizes(flat_index), 1);

            if cell_particle_index >= const_grid.cell_capacity {
                if resize_buf(0) < cell_particle_index {
                    resize_buf(0) = cell_particle_index;
                }
            } else {
                let cell_offset = get_cell_offset(flat_index, const_grid);
                cell_particles(cell_offset + cell_particle_index) = i;
                particles_cell(i) = flat_index;
            }
        });

        resize = get_resize(const_grid);

        if resize > 0 {
            reallocate_cell_capacity(grid, resize * 2);
        }
    }
}

fn distribute_particles(grid: &mut Grid) -> () {
    if sort_particles() {
        fill_cells(grid, grid.nparticles);

        let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
        let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
        let mut offset = 0;

        range(0, grid.ncells, |cell_index| {
            let cell_offset = get_cell_offset(cell_index, grid);

            range(0, cell_sizes(cell_index), |cell_particle_index| {
                let old_index = cell_particles(cell_offset + cell_particle_index);
                let new_index = offset + cell_particle_index;

                copy_array_value(old_index, new_index, grid.positions_cpu, grid.positions_copy_cpu);
                copy_array_value(old_index, new_index, grid.velocities_cpu, grid.velocities_copy_cpu);
            });

            offset += cell_sizes(cell_index);
        });

        range(grid.nparticles, grid.nparticles + grid.nghost, |ghost_index| {
            copy_array_value(ghost_index, ghost_index, grid.positions_cpu, grid.positions_copy_cpu);
        });

        let pos_copy = grid.positions_cpu;
        let vel_copy = grid.velocities_cpu;

        grid.positions_cpu = grid.positions_copy_cpu;
        grid.velocities_cpu = grid.velocities_copy_cpu;
        grid.positions_copy_cpu = pos_copy;
        grid.velocities_copy_cpu = vel_copy;
    }

    fill_cells(grid, grid.nparticles + grid.nghost);
}

fn copy_to_accelerator(grid: &Grid) -> () {
    transfer(grid.cell_particles_cpu, grid.cell_particles_accelerator);
    transfer(grid.cell_sizes_cpu, grid.cell_sizes_accelerator);
    transfer(grid.particles_cell_cpu, grid.particles_cell_accelerator);
    transfer(grid.masses_cpu, grid.masses_accelerator);
    transfer_array(grid.positions_cpu, grid.positions_accelerator);
    transfer_array(grid.velocities_cpu, grid.velocities_accelerator);
}

fn copy_from_accelerator(grid: &Grid) -> () {
    transfer(grid.masses_accelerator, grid.masses_cpu);
    transfer_array(grid.positions_accelerator, grid.positions_cpu);
    transfer_array(grid.velocities_accelerator, grid.velocities_cpu);
    transfer_array(grid.forces_accelerator, grid.forces_cpu);
}

fn write_grid_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    grid: &Grid) -> i32 {

    range(0, grid.nparticles, |particle_index| {
        masses(particle_index) = get_real(particle_index, grid.masses_cpu);
        positions(particle_index) = get_array_value(grid.positions_cpu, particle_index);
        velocities(particle_index) = get_array_value(grid.velocities_cpu, particle_index);
        forces(particle_index) = get_array_value(grid.forces_cpu, particle_index);
    });

    grid.nparticles
}

fn write_grid_ghost_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    grid: &Grid) -> i32 {

    range(grid.nparticles, grid.nparticles + grid.nghost, |particle_index| {
        let index = particle_index - grid.nparticles;

        masses(index) = get_real(particle_index, grid.masses_cpu);
        positions(index) = get_array_value(grid.positions_cpu, particle_index);
        velocities(index) = get_array_value(grid.velocities_cpu, particle_index);
        forces(index) = get_array_value(grid.forces_cpu, particle_index);
    });

    grid.nparticles
}

fn write_grid_aabb_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    grid: &Grid) -> i32 {

    range(0, 2, |i| {
        range(0, 2, |j| {
            range(0, 2, |k| {
                let index = k * 4 + j * 2 + i;

                masses(index) = 0.0;
                positions(index) = Vector3D {
                    x: select(i == 0, grid.aabb.xmin, grid.aabb.xmax),
                    y: select(j == 0, grid.aabb.ymin, grid.aabb.ymax),
                    z: select(k == 0, grid.aabb.zmin, grid.aabb.zmax)
                };

                velocities(index) = Vector3D { x: 0.0, y: 0.0, z: 0.0 };
                forces(index) = Vector3D { x: 0.0, y: 0.0, z: 0.0 };
            });
        });
    });

    grid.nparticles
}

fn compute_cell_position(position: Vector3D, @local_only: bool, grid: Grid) -> [i32 * 3] {
    let mut i = real_floor(((position.x - grid.aabb.xmin) / grid.spacing) as real_t) as i32;
    let mut j = real_floor(((position.y - grid.aabb.ymin) / grid.spacing) as real_t) as i32;
    let mut k = real_floor(((position.z - grid.aabb.zmin) / grid.spacing) as real_t) as i32;

    if local_only {
        i = math.max(i, 0);
        i = math.min(i, grid.nx - 1);
        j = math.max(j, 0);
        j = math.min(j, grid.ny - 1);
        k = math.max(k, 0);
        k = math.min(k, grid.nz - 1);
    }

    [i, j, k]
}

fn is_within_domain(position: Vector3D, aabb: AABB) -> bool {
    position.x >= aabb.xmin && position.x <= aabb.xmax &&
    position.y >= aabb.ymin && position.y <= aabb.ymax &&
    position.z >= aabb.zmin && position.z <= aabb.zmax
}

fn flatten_index(cell_index: [i32 * 3], grid: &Grid) -> i32 {
    (cell_index(2) * grid.ny + cell_index(1)) * grid.nx + cell_index(0)
}

fn unflatten_index(index: i32, grid: &Grid) -> [i32 * 3] {
    [index % grid.nx, (index / grid.nx) % grid.ny, index / (grid.nx * grid.ny)]
}
