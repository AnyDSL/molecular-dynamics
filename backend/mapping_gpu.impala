fn @is_x86() -> bool { false }
fn @is_sse() -> bool { false }
fn @is_avx() -> bool { false }
fn @is_avx2() -> bool { false }

fn add_iterator(iterator: &mut i64) -> () {}
fn transfer(from: Buffer, to: Buffer) -> () { copy(from, to); }
fn accelerator_allocate(size: i32) -> Buffer { accelerator(device_id).alloc(size) }

fn warmup() -> () {
    let acc = accelerator(device_id);
    let grid_size = (32, 1, 1);
    let block_size = (32, 1, 1);

    acc.exec(grid_size, block_size, |work_item| {});
}

fn loop_accelerator(grid: Grid, body: fn(i32, &mut[1][i32], i32, i32) -> ()) -> () {
    let neighbors_sizes = get_array_of_i32_accelerator(grid.neighbors_sizes_accelerator);
    let neighborlists = get_array_of_i32_accelerator(grid.neighborlists_accelerator);
    let neighborlist_capacity = grid.neighborlist_capacity;
    let nparticles = grid.nparticles;

    let acc = accelerator(device_id);
    let block_size = (64, 1, 1);
    let grid_size  = (round_up(nparticles, block_size(0)), 1, 1);

    if nparticles > 0 {
        acc.exec(grid_size, block_size, |work_item| {
            let particle_index = work_item.bidx() * work_item.bdimx() + work_item.tidx();

            if particle_index < nparticles {
                let nb_list_offset = neighborlist_capacity * particle_index;
                let nb_list_size = neighbors_sizes(particle_index);

                @@body(particle_index, neighborlists, nb_list_size, nb_list_offset);
            }
        });

        acc.sync();
    }
}

fn iterate_cells(grid: Grid, body: fn(i32) -> ()) -> () {
    let ncells = grid.ncells;
    let acc = accelerator(device_id);
    let block_size = (64, 1, 1);
    let grid_size  = (round_up(ncells, block_size(0)), 1, 1);

    if ncells > 0 {
        acc.exec(grid_size, block_size, |work_item| {
            let cell_index = work_item.bidx() * work_item.bdimx() + work_item.tidx();

            if cell_index < ncells {
                @@body(cell_index);
            }
        });

        acc.sync();
    }
}

fn copy_list_iterate(comm_offsets: CommOffsets, ncopy: i32, body: fn(i32, &[1][i32], &[1][i32]) -> ()) -> () {
    let acc = accelerator(device_id);
    let block_size = (64, 1, 1);
    let grid_size = (round_up(ncopy, block_size(0)), 1, 1);
    let send_offsets = get_send_offsets(comm_offsets);
    let copy_list = get_copy_list(comm_offsets);

    if ncopy > 0 {
        acc.exec(grid_size, block_size, |work_item| {
            let index = work_item.bidx() * work_item.bdimx() + work_item.tidx();

            if index < ncopy {
                @@body(index, copy_list, send_offsets);
            }
        });

        acc.sync();
    }
}

fn comm_buffer_iterate(comm_offsets: CommOffsets, noffsets: i32, body: fn(i32, &mut[1][real_t], &[1][real_t]) -> ()) -> () {
    let acc = accelerator(device_id);
    let block_size = (64, 1, 1);
    let grid_size = (round_up(noffsets, block_size(0)), 1, 1);
    let send_data = get_array_of_reals_accelerator(comm_offsets.recv_buffer_accelerator);
    let recv_data = get_array_of_reals_accelerator(comm_offsets.recv_buffer_accelerator);

    if noffsets > 0 {
        acc.exec(grid_size, block_size, |work_item| {
            let index = work_item.bidx() * work_item.bdimx() + work_item.tidx();

            if index < noffsets {
                @@body(index, send_data, recv_data);
            }
        });

        acc.sync();
    }
}

fn atomic_add_i32(ptr: &mut[1]i32, value: i32) -> i32 { nvvm_atomic_add_global(ptr as &mut[1]i32, value) }

fn set_counter(value: i32, comm_offsets: CommOffsets) -> () {
    bitcast[&mut[i32]](comm_offsets.counter_buffer.data)(0) = value;
    copy(comm_offsets.counter_buffer, comm_offsets.counter_buffer_accelerator);
}

fn get_counter(comm_offsets: CommOffsets) -> i32 {
    copy(comm_offsets.counter_buffer_accelerator, comm_offsets.counter_buffer);
    bitcast[&[i32]](comm_offsets.counter_buffer.data)(0)
}

fn add_counter(comm_offsets: CommOffsets) -> i32 {
    let counter = bitcast[&mut[i32]](comm_offsets.counter_buffer_accelerator.data);
    nvvm_atomic_add_global(&mut counter(0) as &mut[1]i32, 1)
}

fn reset_resize(grid: Grid) -> () {
    bitcast[&mut[i32]](grid.resize_buffer_cpu.data)(0) = 0;
    copy(grid.resize_buffer_cpu, grid.resize_buffer_accelerator);
}

fn get_resize(grid: Grid) -> i32 {
    copy(grid.resize_buffer_accelerator, grid.resize_buffer_cpu);
    bitcast[&[i32]](grid.resize_buffer_cpu.data)(0)
}

fn get_resize_buffer(grid: Grid) -> &mut[1][i32] { get_array_of_i32_accelerator(grid.resize_buffer_accelerator) }
fn get_send_flags(grid: Grid) -> &mut[1][i8] { get_array_of_i8_accelerator(grid.send_flags_accelerator) }
fn get_particles_cell(grid: Grid) -> &mut[1][i32] { get_array_of_i32_accelerator(grid.particles_cell_accelerator) }
fn get_cell_particles(grid: Grid) -> &mut[1][i32] { get_array_of_i32_accelerator(grid.cell_particles_accelerator) }
fn get_cell_sizes(grid: Grid) -> &mut[1][i32] { get_array_of_i32_accelerator(grid.cell_sizes_accelerator) }
fn get_neighbors_sizes(grid: Grid) -> &mut[1][i32] { get_array_of_i32_accelerator(grid.neighbors_sizes_accelerator) }
fn get_neighborlists(grid: Grid) -> &mut[1][i32] { get_array_of_i32_accelerator(grid.neighborlists_accelerator) }
fn get_masses(grid: Grid) -> &mut[1][real_t] { get_array_of_reals_accelerator(grid.masses_accelerator) }
fn get_position(i: i32, grid: Grid) -> Vector3D { get_array_value_accelerator(grid.positions_accelerator, i) }
fn set_position(i: i32, grid: Grid, position: Vector3D) -> () { set_array_value_accelerator(grid.positions_accelerator, i, position) }
fn get_velocity(i: i32, grid: Grid) -> Vector3D { get_array_value_accelerator(grid.velocities_accelerator, i) }
fn set_velocity(i: i32, grid: Grid, velocity: Vector3D) -> () { set_array_value_accelerator(grid.velocities_accelerator, i, velocity) }
fn get_force(i: i32, grid: Grid) -> Vector3D { get_array_value_accelerator(grid.forces_accelerator, i) }
fn set_force(i: i32, grid: Grid, force: Vector3D) -> () { set_array_value_accelerator(grid.forces_accelerator, i, force) }
fn get_send_buffer(comm_offsets: CommOffsets) -> &mut[1][real_t] { get_array_of_reals_accelerator(comm_offsets.send_buffer_accelerator) }
fn get_send_offsets(comm_offsets: CommOffsets) -> &mut[1][i32] { get_array_of_i32_accelerator(comm_offsets.send_offsets_accelerator) }
fn get_send_pbc(comm_offsets: CommOffsets) -> &mut[1][i8] { get_array_of_i8_accelerator(comm_offsets.send_pbc_accelerator) }
fn get_copy_list(comm_offsets: CommOffsets) -> &mut[1][i32] { get_array_of_i32_accelerator(comm_offsets.copy_list_accelerator) }

fn get_neighborlist_index(particle_index: i32, neighbor_index: i32, grid: Grid) -> i32 {
    grid.particle_capacity * neighbor_index + particle_index
}
