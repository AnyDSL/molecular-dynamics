fn @is_nvvm() -> bool { false }
fn @is_cuda() -> bool { false }
fn @is_opencl() -> bool { false }
fn @is_amdgpu() -> bool { false }
fn @has_ldg() -> bool { false }
fn @use_unified_memory() -> bool { false }

fn add_iterator(iterator: &mut i64) -> () {
    (*iterator)++;
}

fn cpu_allocate(size: i32) -> Buffer { alloc_cpu(size) }

fn @accelerator_allocate(size: i32) -> Buffer {
    Buffer {
        device: 0,
        data: 0 as &[i8],
        size: 0 as i64
    }
}

fn @accelerator_allocate_3d_arrays(N: i32) -> Array3D {
    null_3d_array()
}

fn @assign_accelerator_buffer(cpu_buffer: &mut Buffer, gpu_buffer: Buffer) -> () {}
fn @transfer_between_devices(source: Buffer, destination: Buffer) -> () {}
fn @transfer_3d_arrays_between_devices(source: Array3D, destination: Array3D) -> () {}

fn warmup() -> () {}

// Vectorizes an arbitrary range
fn @vectorized_range(vector_width: i32, a: i32, b: i32, body: fn (i32, i32) -> ()) -> () {
    if vector_width == 1 {
        for i in range(a, b) {
            body(i, 1);
        }
    } else {
        let n_vec = round_down(b - a, vector_width);
        for i in range_step(a, a + n_vec, vector_width) {
            for j in vectorize(vector_width) {
                @@body(i + j, vector_width)
            }
        }
        for i in range(a + n_vec, b) {
            @@body(i, 1)
        }
    }
}

fn loop_accelerator(grid: Grid, body: fn(i32, &mut[i32], i32, i32) -> ()) -> () {
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
    let neighbors_sizes = get_array_of_i32(grid.neighbors_sizes_cpu);
    let neighborlists = get_array_of_i32(grid.neighborlists_cpu);
    let neighborlist_capacity = grid.neighborlist_capacity;

    vectorized_range(get_vector_width(), 0, grid.nparticles, |particle_index, _| {
        let nb_list_offset = neighborlist_capacity * particle_index;
        let nb_list_size = neighbors_sizes(particle_index);

        @@body(particle_index, neighborlists, nb_list_size, nb_list_offset);
    });
}

fn @get_cell_particles(grid: Grid) -> &mut[i32] {
    get_array_of_i32(grid.cell_particles_cpu)
}

fn @get_cell_sizes(grid: Grid) -> &mut[i32] {
    get_array_of_i32(grid.cell_sizes_cpu)
}

fn @get_particles_cell(grid: Grid) -> &mut[i32] {
    get_array_of_i32(grid.particles_cell_cpu)
}

fn @get_neighborlist_index(particle_index: i32, neighbor_index: i32, grid: Grid) -> i32 {
    grid.neighborlist_capacity * particle_index + neighbor_index
}

fn @get_neighbors_sizes(grid: Grid) -> &mut[i32] {
    get_array_of_i32(grid.neighbors_sizes_cpu)
}

fn @get_number_of_neighbors(cluster_index: i32, grid: Grid) -> i32 {
    get_i32(cluster_index, grid.neighbors_sizes_cpu)
}

fn @get_neighborlists(grid: Grid) -> &mut[i32] {
    get_array_of_i32(grid.neighborlists_cpu)
}

fn @get_masses(grid: Grid) -> &mut[real_t] {
    get_array_of_reals(grid.masses_cpu)
}

fn @get_position(i: i32, grid: Grid) -> Vector3D {
    get_vector_from_3d_arrays(i, grid.positions_cpu)
}

fn @set_position(i: i32, grid: Grid, position: Vector3D) -> () {
    set_3d_arrays(i, grid.positions_cpu, position)
}

fn @get_velocity(i: i32, grid: Grid) -> Vector3D {
    get_vector_from_3d_arrays(i, grid.velocities_cpu)
}

fn @set_velocity(i: i32, grid: Grid, velocity: Vector3D) -> () {
    set_3d_arrays(i, grid.velocities_cpu, velocity)
}

fn @get_force(i: i32, grid: Grid) -> Vector3D {
    get_vector_from_3d_arrays(i, grid.forces_cpu)
}

fn @set_force(i: i32, grid: Grid, force: Vector3D) -> () {
    set_3d_arrays(i, grid.forces_cpu, force)
}

fn @reset_force(i: i32, grid: Grid) -> () {
    set_3d_arrays(i, grid.forces_cpu, Vector3D {x: 0.0 as real_t, y: 0.0 as real_t, z: 0.0 as real_t});
}

fn @add_to_force(i: i32, grid: Grid, dF_x: real_t, dF_y: real_t, dF_z: real_t) -> () {
    let mut force = get_vector_from_3d_arrays(i, grid.forces_cpu);

    force.x += dF_x;
    force.y += dF_y;
    force.z += dF_z;

    set_3d_arrays(i, grid.forces_cpu, force);
}

fn @get_pbc_flags(i: i32, grid: Grid) -> PBCFlags {
    let flags = get_u8(i, grid.pbc_flags_cpu);
    let mut xoff = 0 as i8;
    let mut yoff = 0 as i8;
    let mut zoff = 0 as i8;

    if(flags & 0x1  as u8 != 0 as u8) { xoff =  1 as i8; }
    if(flags & 0x2  as u8 != 0 as u8) { xoff = -1 as i8; }
    if(flags & 0x4  as u8 != 0 as u8) { yoff =  1 as i8; }
    if(flags & 0x8  as u8 != 0 as u8) { yoff = -1 as i8; }
    if(flags & 0x10 as u8 != 0 as u8) { zoff =  1 as i8; }
    if(flags & 0x20 as u8 != 0 as u8) { zoff = -1 as i8; }

    PBCFlags {
        x: xoff,
        y: yoff,
        z: zoff
    }
}

fn @set_pbc_flags(i: i32, grid: Grid, pbc_flags: PBCFlags) -> () {
    let mut flags = 0 as u8;

    if pbc_flags.x != 0 as i8 { flags |= select(pbc_flags.x > 0 as i8, 0x1  as u8, 0x2  as u8); }
    if pbc_flags.y != 0 as i8 { flags |= select(pbc_flags.y > 0 as i8, 0x4  as u8, 0x8  as u8); }
    if pbc_flags.z != 0 as i8 { flags |= select(pbc_flags.z > 0 as i8, 0x10 as u8, 0x20 as u8); }

    set_u8(i, grid.pbc_flags_cpu, flags);
}

fn @get_comm_send_offsets(index: i32, comm_offsets: CommOffsets) -> i32 {
    get_i32(index, comm_offsets.send_offsets)
}

fn @get_comm_recv_offsets(index: i32, comm_offsets: CommOffsets) -> i32 {
    get_i32(index, comm_offsets.recv_offsets)
}

fn gather_data(grid: Grid, comm_offsets: CommOffsets) -> () {
    let buffer = comm_offsets.send_buffer;
    let noffsets = comm_offsets.send_noffsets;
    let mut index = 0;

    outer_loop_cpu(0, noffsets, |i| {
        let offset = get_comm_send_offsets(i, comm_offsets);
        @@copy_3d_array_to_buffer(grid.positions_cpu, offset, buffer, &mut index);
    });
}

fn scatter_data(grid: Grid, comm_offsets: CommOffsets) -> () {
    let buffer = comm_offsets.recv_buffer;
    let noffsets = comm_offsets.recv_noffsets;
    let mut index = 0;

    outer_loop_cpu(0, noffsets, |i| {
        let offset = get_comm_recv_offsets(i, comm_offsets);
        @@copy_buffer_to_3d_array(buffer, &mut index, grid.positions_cpu, offset);
    });
}
