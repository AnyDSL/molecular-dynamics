fn @is_nvvm() -> bool { false }
fn @is_cuda() -> bool { false }
fn @is_opencl() -> bool { false }
fn @is_amdgpu() -> bool { false }
fn @has_ldg() -> bool { false }

type dev_i8_arr       = &[i8];
type dev_mut_i8_arr   = &[i8];
type dev_i32_arr      = &[i32];
type dev_mut_i32_arr  = &mut [i32];
type dev_i32_ptr      = &mut i32;
type dev_real_arr     = &[real_t];
type dev_mut_real_arr = &mut[real_t];
type dev_f32_ptr      = &mut f32;
type dev_f64_ptr      = &mut f64;

fn @device() -> Device {
    Device {
        cpu_target: @|| { true },
        init: |grid| {},
        shutdown: || {},
        alloc: |size| { alloc_cpu(size) },
        alloc_mirror: |buf, size| { buf },
        transfer: |from, to| {},
        sqrt: @|a| { cpu_intrinsics.sqrt(a) },
        get_array_i8: |buffer| { bitcast[&[i8]](buffer.data) },
        get_mut_array_i8: |buffer| { bitcast[&mut[i8]](buffer.data) },
        get_array_i32: |buffer| { bitcast[&[i32]](buffer.data) },
        get_mut_array_i32: |buffer| { bitcast[&mut[i32]](buffer.data) },
        get_array_real: |buffer| { bitcast[&[real_t]](buffer.data) },
        get_mut_array_real: |buffer| { bitcast[&mut[real_t]](buffer.data) },
        add_iterator: |iterator| { (*iterator)++; },
        atomic_add_i32: @|ptr, value| {
            *ptr += value;
            *ptr - value
        }
    }
}

// Vectorizes an arbitrary range
fn @vectorized_range(@vector_width: i32, a: i32, b: i32, body: fn (i32, i32) -> ()) -> () {
    if vector_width == 1 {
        for i in range(a, b) {
            body(i, 1);
        }
    } else {
        let n_vec = round_down(b - a, vector_width);
        for i in range_step(a, a + n_vec, vector_width) {
            for j in vectorize(vector_width) {
                @@body(i + j, vector_width)
            }
        }
        for i in range(a + n_vec, b) {
            @@body(i, 1)
        }
    }
}

fn @particles_gen(@vec: bool, @ghost: bool, grid: Grid, body: fn(i32, &mut[i32], i32, i32) -> ()) -> () {
    let dev = device();
    let neighbors_sizes = dev.get_array_i32(grid.neighbors_sizes_cpu);
    let neighborlists = dev.get_mut_array_i32(grid.neighborlists_cpu);
    let vec_width = select(vec, get_vector_width(), 1);
    let n = select(ghost, grid.nparticles + grid.nghost, grid.nparticles);

    vectorized_range(vec_width, 0, n, |particle_index, _| {
        @@body(particle_index, neighborlists, neighbors_sizes(particle_index), grid.neighborlist_capacity * particle_index);
    });
}

fn @particles(@ghost: bool, grid: Grid, f: fn(i32, &mut[i32], i32, i32) -> ()) -> () { particles_gen(false, ghost, grid, f); }
fn @particles_vec(@ghost: bool, grid: Grid, f: fn(i32, &mut[i32], i32, i32) -> ()) -> () { particles_gen(true, ghost, grid, f); }
fn @cells(grid: Grid, body: fn(i32) -> ()) -> () { range(0, grid.ncells, body); }
fn copy_list_iterate(comm_offsets: &CommOffsets, ncopy: i32, body: fn(i32, &[i32], &[i32]) -> ()) -> () {
    let send_offsets = get_send_offsets(comm_offsets);
    let copy_list = get_copy_list(comm_offsets);

    range(0, ncopy, |index| {
        @@body(index, copy_list, send_offsets);
    });
}

fn comm_buffer_iterate(comm_offsets: &CommOffsets, noffsets: i32, body: fn(i32, &mut [real_t], &[real_t]) -> ()) -> () {
    let send_data = get_array_of_reals(comm_offsets.send_buffer);
    let recv_data = get_array_of_reals(comm_offsets.recv_buffer);

    range(0, noffsets, |index| {
        @@body(index, send_data, recv_data);
    });
}

fn @reduce_i32(n: i32, b: i32, reduce: fn(i32, i32) -> i32, body: fn(i32) -> i32) -> i32 {
    let mut red = b;

    range(0, n, |i| {
        red = reduce(red, body(i));
    });

    red
}

fn @reduce_aabb(n: i32, b: AABB, reduce: fn(AABB, AABB) -> AABB, body: fn(i32) -> AABB) -> AABB {
    let mut red = b;

    range(0, n, |i| {
        red = reduce(red, body(i));
    });

    red
}

fn set_counter(value: i32, grid: Grid) -> () { bitcast[&mut[i32]](grid.counter_buffer_cpu.data)(0) = value; }
fn get_counter(grid: Grid) -> i32 { bitcast[&[i32]](grid.counter_buffer_cpu.data)(0) }
fn add_counter(grid: Grid) -> i32 { bitcast[&mut[i32]](grid.counter_buffer_cpu.data)(0)++ }
fn reset_resize(grid: Grid) -> () { bitcast[&mut[i32]](grid.resize_buffer_cpu.data)(0) = 0; }
fn get_resize(grid: Grid) -> i32 { bitcast[&[i32]](grid.resize_buffer_cpu.data)(0) }
fn get_send_flags(grid: Grid) -> &mut[i8] { get_array_of_i8(grid.send_flags_cpu) }
fn get_resize_buffer(grid: Grid) -> &mut[i32] { get_array_of_i32(grid.resize_buffer_cpu) }
fn get_cell_list(grid: Grid) -> &mut[i32] { get_array_of_i32(grid.cell_list_cpu) }
fn get_cell_particles(grid: Grid) -> &mut[i32] { get_array_of_i32(grid.cell_particles_cpu) }
fn get_cell_sizes(grid: Grid) -> &mut[i32] { get_array_of_i32(grid.cell_sizes_cpu) }
fn get_particles_cell(grid: Grid) -> &mut[i32] { get_array_of_i32(grid.particles_cell_cpu) }
fn get_neighbors_sizes(grid: Grid) -> &mut[i32] { get_array_of_i32(grid.neighbors_sizes_cpu) }
fn get_neighborlists(grid: Grid) -> &mut[i32] { get_array_of_i32(grid.neighborlists_cpu) }
fn get_masses(grid: Grid) -> &mut[real_t] { get_array_of_reals(grid.masses_cpu) }
fn get_send_buffer(comm_offsets: &CommOffsets) -> &mut[real_t] { get_array_of_reals(comm_offsets.send_buffer) }
fn get_send_offsets(comm_offsets: &CommOffsets) -> &mut[i32] { get_array_of_i32(comm_offsets.send_offsets) }
fn get_send_pbc(comm_offsets: &CommOffsets) -> &mut[i8] { get_array_of_i8(comm_offsets.send_pbc) }
fn get_copy_list(comm_offsets: &CommOffsets) -> &mut[i32] { get_array_of_i32(comm_offsets.copy_list) }
fn @get_neighborhood_aabb_buffer(nbh: Neighborhood) -> &[real_t] { device().get_array_real(nbh.aabbs_cpu) }

fn @get_neighborlist_index(particle_index: i32, neighbor_index: i32, grid: Grid) -> i32 {
    grid.neighborlist_capacity * particle_index + neighbor_index
}
