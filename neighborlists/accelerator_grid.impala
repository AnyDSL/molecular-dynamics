struct AcceleratorGrid {
    cluster_size: i32, // size of one cluster on the accelerator
    total_number_of_clusters: i32, // equals the size of neighbors_per_cluster
    capacity_neighbors_per_cluster: i32, // capacity of the array neighbors_per_cluster
    total_number_of_neighbors: i32, // equals the size of the neighborlists arrays
    capacity_neighborlists: i32, // capacity of the neighborlists arrays
    cell_offsets: Buffer, // offsets of the data stored in each cell within data array

    masses_cpu: Buffer, // masses of all particles on the CPU: [real_t]
    positions_cpu: Array3D, // positions of all particles on the CPU: [Vector3D]
    velocities_cpu: Array3D, // velocities of all particles on the CPU: [Vector3D]
    forces_cpu: Array3D, // forces of all particles on the CPU: [Vector3D]
    interaction_mask_cpu: Buffer, // interaction mask on the CPU: [bool]
    neighbors_per_cluster_cpu: Buffer, // neighbors per cluster on the CPU: [i32]
    neighborlist_offsets_cpu: Buffer, // offsets to the data stored in each neighbor list on the CPU: [i32]
    neighborlists_cpu: Buffer, // neighborlists on the CPU: [i32]

    masses_accelerator: Buffer, // masses of all particles on the accelerator: [real_t]
    positions_accelerator: Array3D, // positions of all particles on the accelerator: [Vector3D]
    velocities_accelerator: Array3D, // velocities of all particles on the accelerator: [Vector3D]
    forces_accelerator: Array3D, // forces of all particles on the accelerator: [Vector3D]
    interaction_mask_accelerator: Buffer, // interaction mask on the accelerator: [bool]
    neighbors_per_cluster_accelerator: Buffer, // neighbors per cluster on the accelerator: [i32]
    neighborlist_offsets_accelerator: Buffer, // offsets to the data stored in each neighbor list on the accelerator: [i32] 
    neighborlists_accelerator: Buffer // neighborlists on the accelerator: [i32]
    
}

struct SimulationData { 
    cluster_size: i32, // size of one cluster on the accelerator
    total_number_of_clusters: i32, // equals the size of neighbors_per_cluster
    capacity_neighbors_per_cluster: i32, // capacity of the array neighbors_per_cluster
    total_number_of_neighbors: i32, // equals the size of the neighborlists arrays
    capacity_neighborlists: i32, // capacity of the neighborlists arrays
    cell_offsets: Buffer, // offsets of the data stored in each cell within data array

    masses_cpu: Buffer, // masses of all particles on the CPU: [real_t]
    positions_cpu: Array3D, // positions of all particles on the CPU: [Vector3D]
    velocities_cpu: Array3D, // velocities of all particles on the CPU: [Vector3D]
    forces_cpu: Array3D, // forces of all particles on the CPU: [Vector3D]
    interaction_mask_cpu: Buffer, // interaction mask on the CPU: [bool]
    neighbors_per_cluster_cpu: Buffer, // neighbors per cluster on the CPU: [i32]
    neighborlist_offsets_cpu: Buffer, // offsets to the data stored in each neighbor list on the CPU: [i32]
    neighborlists_cpu: Buffer // neighborlists on the CPU: [i32]
}

fn allocate_accelerator_grid(
    nx: i32, ny: i32, nz: i32, capacity_neighbors_per_cluster: i32, @cluster_size: i32, neighbor_lists_capacity: i32) -> AcceleratorGrid {

    let capacity_particles = capacity_neighbors_per_cluster * cluster_size;

    add_accelerator_grid_allocation(nx * ny * nz * sizeof[i32]());
    add_accelerator_grid_allocation(capacity_particles * 10 * sizeof[real_t]());
    add_accelerator_grid_allocation(capacity_particles * sizeof[i8]());
    add_accelerator_grid_allocation(capacity_neighbors_per_cluster * sizeof[i32]() * 2);
    add_accelerator_grid_allocation(neighbor_lists_capacity * sizeof[i32]());

    AcceleratorGrid {
        cluster_size: cluster_size,
        total_number_of_clusters: 0,
        capacity_neighbors_per_cluster: capacity_neighbors_per_cluster,
        total_number_of_neighbors: 0,
        capacity_neighborlists: neighbor_lists_capacity,
        cell_offsets: alloc_cpu(nx * ny * nz * sizeof[i32]()), // only needed for cpu-accelerator transfer

        masses_cpu: alloc_cpu(capacity_particles * sizeof[real_t]()),
        positions_cpu: allocate_3d_arrays(capacity_particles, alloc_cpu),
        velocities_cpu: allocate_3d_arrays(capacity_particles, alloc_cpu),
        forces_cpu: allocate_3d_arrays(capacity_particles, alloc_cpu),
        interaction_mask_cpu: alloc_cpu(capacity_particles * sizeof[i8]()),
        neighbors_per_cluster_cpu: alloc_cpu(capacity_neighbors_per_cluster * sizeof[i32]()),
        neighborlist_offsets_cpu: alloc_cpu(capacity_neighbors_per_cluster * sizeof[i32]()),
        neighborlists_cpu: alloc_cpu(neighbor_lists_capacity * sizeof[i32]()),

        masses_accelerator: accelerator_allocate(capacity_particles * sizeof[real_t]()),
        positions_accelerator: accelerator_allocate_3d_arrays(capacity_particles),
        velocities_accelerator: accelerator_allocate_3d_arrays(capacity_particles),
        forces_accelerator: accelerator_allocate_3d_arrays(capacity_particles),
        interaction_mask_accelerator: accelerator_allocate(capacity_particles * sizeof[i8]()),
        neighbors_per_cluster_accelerator: accelerator_allocate(capacity_neighbors_per_cluster * sizeof[i32]()),
        neighborlist_offsets_accelerator: accelerator_allocate(capacity_neighbors_per_cluster * sizeof[i32]()),
        neighborlists_accelerator: accelerator_allocate(neighbor_lists_capacity * sizeof[i32]())
    }
}

fn deallocate_accelerator_grid(accelerator_grid: AcceleratorGrid) -> () {
    release(accelerator_grid.cell_offsets);
    release(accelerator_grid.masses_cpu);
    deallocate_3d_arrays(accelerator_grid.positions_cpu);
    deallocate_3d_arrays(accelerator_grid.velocities_cpu);
    deallocate_3d_arrays(accelerator_grid.forces_cpu);
    release(accelerator_grid.interaction_mask_cpu);
    release(accelerator_grid.neighbors_per_cluster_cpu);
    release(accelerator_grid.neighborlist_offsets_cpu);
    release(accelerator_grid.neighborlists_cpu);

    release(accelerator_grid.masses_accelerator);
    deallocate_3d_arrays(accelerator_grid.positions_accelerator);
    deallocate_3d_arrays(accelerator_grid.velocities_accelerator);
    deallocate_3d_arrays(accelerator_grid.forces_accelerator);
    release(accelerator_grid.interaction_mask_accelerator);
    release(accelerator_grid.neighbors_per_cluster_accelerator);
    release(accelerator_grid.neighborlist_offsets_accelerator);
    release(accelerator_grid.neighborlists_accelerator);
}

fn copy_to_accelerator(grid: &Grid, accelerator_grid: &mut AcceleratorGrid) -> () {
    // count the total number of clusters and neighbors within all cells
    let counts = grid_count_clusters_and_neighbors(grid);
    let number_of_clusters = counts(0);
    let number_of_neighbors = counts(1);

    // if the total number of clusters exceeds the capacity of the accelerator arrays 
    // reallocate a sufficient amount of memory
    if(number_of_clusters > accelerator_grid.capacity_neighbors_per_cluster) {
        release(accelerator_grid.masses_cpu);
        deallocate_3d_arrays(accelerator_grid.positions_cpu);
        deallocate_3d_arrays(accelerator_grid.velocities_cpu);
        deallocate_3d_arrays(accelerator_grid.forces_cpu);
        release(accelerator_grid.interaction_mask_cpu);
        release(accelerator_grid.neighbors_per_cluster_cpu);
        release(accelerator_grid.neighborlist_offsets_cpu);

        release(accelerator_grid.masses_accelerator);
        deallocate_3d_arrays(accelerator_grid.positions_accelerator);
        deallocate_3d_arrays(accelerator_grid.velocities_accelerator);
        deallocate_3d_arrays(accelerator_grid.forces_accelerator);
        release(accelerator_grid.interaction_mask_accelerator);
        release(accelerator_grid.neighbors_per_cluster_accelerator);
        release(accelerator_grid.neighborlist_offsets_accelerator);

        let new_capacity = number_of_clusters + accelerator_grid.capacity_neighbors_per_cluster / 10;
        accelerator_grid.capacity_neighbors_per_cluster = new_capacity;

        accelerator_grid.masses_cpu = alloc_cpu(new_capacity * accelerator_grid.cluster_size * sizeof[real_t]());
        accelerator_grid.positions_cpu = allocate_3d_arrays(new_capacity * accelerator_grid.cluster_size, alloc_cpu);
        accelerator_grid.velocities_cpu = allocate_3d_arrays(new_capacity * accelerator_grid.cluster_size, alloc_cpu);
        accelerator_grid.forces_cpu = allocate_3d_arrays(new_capacity * accelerator_grid.cluster_size, alloc_cpu);
        accelerator_grid.interaction_mask_cpu = alloc_cpu(new_capacity * accelerator_grid.cluster_size * sizeof[i8]());
        accelerator_grid.neighbors_per_cluster_cpu = alloc_cpu(new_capacity * sizeof[i32]());
        accelerator_grid.neighborlist_offsets_cpu = alloc_cpu(new_capacity * sizeof[i32]());

        accelerator_grid.masses_accelerator = accelerator_allocate(new_capacity * accelerator_grid.cluster_size * sizeof[real_t]());
        accelerator_grid.positions_accelerator = accelerator_allocate_3d_arrays(new_capacity * accelerator_grid.cluster_size);
        accelerator_grid.velocities_accelerator = accelerator_allocate_3d_arrays(new_capacity * accelerator_grid.cluster_size);
        accelerator_grid.forces_accelerator = accelerator_allocate_3d_arrays(new_capacity * accelerator_grid.cluster_size);
        accelerator_grid.interaction_mask_accelerator = accelerator_allocate(new_capacity * accelerator_grid.cluster_size * sizeof[i8]());
        accelerator_grid.neighbors_per_cluster_accelerator = accelerator_allocate(new_capacity * sizeof[i32]());
        accelerator_grid.neighborlist_offsets_accelerator = accelerator_allocate(new_capacity * sizeof[i32]());
    }

    accelerator_grid.total_number_of_clusters = number_of_clusters;

    // if the total number neighbors exceeds the capacity in the neighborlists cpu and accelerator array 
    // reallocate a sufficient amount of memory
    if(number_of_neighbors > accelerator_grid.capacity_neighborlists) {
        release(accelerator_grid.neighborlists_cpu);
        release(accelerator_grid.neighborlists_accelerator);

        let new_capacity = number_of_neighbors + accelerator_grid.capacity_neighborlists / 10;
        accelerator_grid.capacity_neighborlists = new_capacity;

        accelerator_grid.neighborlists_cpu = alloc_cpu(new_capacity * sizeof[i32]());
        accelerator_grid.neighborlists_accelerator = accelerator_allocate(new_capacity * sizeof[i32]());
    }

    let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
    let neighbors_per_cluster = get_array_of_i32(accelerator_grid.neighbors_per_cluster_cpu);
    let neighborlist_offsets = get_array_of_i32(accelerator_grid.neighborlist_offsets_cpu);
    let neighborlists_cpu = get_array_of_i32(accelerator_grid.neighborlists_cpu);
    let mut offset_cells = 0;
    let mut offset_clusters = 0;
    let mut offset_neighbors = 0;

    // copy cell data to accelerator
    for cell, index in map_over_grid(grid, range, range, range) {
        if(cell.cluster_size != accelerator_grid.cluster_size) {
            print_string("Cluster sizes on CPU and accelerator are not equal!\n");
        } else {
            // first compute the offset for each cell within the accelerator arrays
            // the offset for the next cell is obtained by adding the size of the last cell to the old offset value
            let total_cell_size = cell.size + cell.padding;
            let flat_index = flatten_index(index, grid); 

            cell_offsets(flat_index) = offset_cells;

            if(cell.size > 0) {
                let clusters_in_cell = get_array_of_clusters(cell.clusters);

                copy_offset(cell.masses, 0, accelerator_grid.masses_cpu, offset_cells * sizeof[real_t](), cell.size * sizeof[real_t]());
                copy_offset_3d_arrays(cell.positions, 0, accelerator_grid.positions_cpu, offset_cells, cell.size);
                copy_offset_3d_arrays(cell.velocities, 0, accelerator_grid.velocities_cpu, offset_cells, cell.size);

                for i in range(0, cell.size) {
                    set_bool(offset_cells + i, accelerator_grid.interaction_mask_cpu, true);
                }

                for i in range(cell.size, total_cell_size) { 
                    let infinity_vector = Vector3D {
                        x: -INFINITY,
                        y: -INFINITY,
                        z: -INFINITY
                    };

                    set_3d_arrays(offset_cells + i, accelerator_grid.positions_cpu, infinity_vector);
                    set_bool(offset_cells + i, accelerator_grid.interaction_mask_cpu, false);
                }

                for i in range(0, cell.nclusters) {
                    let nb_list_size = clusters_in_cell(i).nb_list_size;

                    neighbors_per_cluster(offset_clusters + i) = nb_list_size;
                    neighborlist_offsets(offset_clusters + i) = offset_neighbors;
                    offset_neighbors += nb_list_size;
                }

                offset_clusters += cell.nclusters; 
                offset_cells += total_cell_size;
            }
        }
    }

    offset_neighbors = 0;

    for cell, index in map_over_grid(grid, range, range, range) {
        if(cell.cluster_size != accelerator_grid.cluster_size) {
            print_string("Cluster sizes on CPU and accelerator are not equal!\n");
        } else if(cell.size > 0) {
            let clusters_in_cell = get_array_of_clusters(cell.clusters); 
            let mut buffer_offset = 0;

            for i in range(0, cell.nclusters) {
                let nb_list_size = clusters_in_cell(i).nb_list_size;
                let neighboring_cells = get_array_of_cell_pointers(cell.neighbor_cells);
                let neighboring_indices = get_array_of_i32(cell.neighbor_indices);

                for j in range(0, nb_list_size) {
                    let neighboring_cell = neighboring_cells(buffer_offset + j);

                    neighborlists_cpu(offset_neighbors + j) =
                        cell_offsets(neighboring_cell.index) +
                        neighboring_indices(buffer_offset + j) * accelerator_grid.cluster_size;
                }

                buffer_offset += cell.neighbor_list_capacity;
                offset_neighbors += nb_list_size;
            }
        }
    }

    let total_number_of_particles = accelerator_grid.total_number_of_clusters * accelerator_grid.cluster_size;
    let masses_bytes = total_number_of_particles * sizeof[real_t]();
    let interaction_mask_bytes = total_number_of_particles * sizeof[i8]();
    let neighbors_per_cluster_bytes = accelerator_grid.total_number_of_clusters * sizeof[i32]();

    transfer_between_devices(
        accelerator_grid.masses_cpu, accelerator_grid.masses_accelerator, masses_bytes);
    transfer_3d_arrays_between_devices(
        accelerator_grid.positions_cpu, accelerator_grid.positions_accelerator, total_number_of_particles);
    transfer_3d_arrays_between_devices(
        accelerator_grid.velocities_cpu, accelerator_grid.velocities_accelerator, total_number_of_particles);
    transfer_between_devices(
        accelerator_grid.interaction_mask_cpu, accelerator_grid.interaction_mask_accelerator, interaction_mask_bytes);
    transfer_between_devices(
        accelerator_grid.neighbors_per_cluster_cpu, accelerator_grid.neighbors_per_cluster_accelerator, neighbors_per_cluster_bytes);
    transfer_between_devices(
        accelerator_grid.neighborlist_offsets_cpu, accelerator_grid.neighborlist_offsets_accelerator, neighbors_per_cluster_bytes);
    transfer_between_devices(
        accelerator_grid.neighborlists_cpu, accelerator_grid.neighborlists_accelerator, offset_neighbors * sizeof[i32]());

    accelerator_grid.total_number_of_neighbors = offset_neighbors;
}

fn copy_from_accelerator(accelerator_grid: &AcceleratorGrid, grid: &Grid) -> () { 
    let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
    let total_number_of_particles = accelerator_grid.total_number_of_clusters * accelerator_grid.cluster_size;

    transfer_3d_arrays_between_devices(
        accelerator_grid.positions_accelerator, accelerator_grid.positions_cpu, total_number_of_particles);
    transfer_3d_arrays_between_devices(
        accelerator_grid.velocities_accelerator, accelerator_grid.velocities_cpu, total_number_of_particles);
    transfer_3d_arrays_between_devices(
        accelerator_grid.forces_accelerator, accelerator_grid.forces_cpu, total_number_of_particles);

    for cell, index in map_over_grid(grid, range, range, range) {
        if(cell.cluster_size != accelerator_grid.cluster_size) {
            print_string("Cluster sizes on CPU and accelerator are not equal!\n");
        } else if(cell.size > 0) {
            let flat_index = flatten_index(index, grid);
            let offset = cell_offsets(flat_index);

            copy_offset_3d_arrays(accelerator_grid.positions_cpu, offset, cell.positions, 0, cell.size);
            copy_offset_3d_arrays(accelerator_grid.velocities_cpu, offset, cell.velocities, 0, cell.size);
            copy_offset_3d_arrays(accelerator_grid.forces_cpu, offset, cell.forces, 0, cell.size);
        }
    }
}
