struct AcceleratorGrid {
    ncells: i32, // number of cells in the grid
    cell_capacity: i32, // cell capacity in accelerator grid
    cell_sizes: Buffer, // sizes of the data stored in each cell within data array

    cluster_size: i32, // size of one cluster on the accelerator
    neighborlist_capacity: i32, // capacity of the neighborlists arrays
    total_number_of_clusters: i32, // equals the size of neighbors_per_cluster

    masses_cpu: Buffer, // masses of all particles on the CPU: [real_t]
    positions_cpu: Array3D, // positions of all particles on the CPU: [Vector3D]
    velocities_cpu: Array3D, // velocities of all particles on the CPU: [Vector3D]
    forces_cpu: Array3D, // forces of all particles on the CPU: [Vector3D]
    interaction_mask_cpu: Buffer, // interaction mask on the CPU: [bool]
    neighbors_per_cluster_cpu: Buffer, // neighbors per cluster on the CPU: [i32]
    neighborlist_offsets_cpu: Buffer, // offsets to the data stored in each neighbor list on the CPU: [i32]
    neighborlists_cpu: Buffer, // neighborlists on the CPU: [i32]

    masses_accelerator: Buffer, // masses of all particles on the accelerator: [real_t]
    positions_accelerator: Array3D, // positions of all particles on the accelerator: [Vector3D]
    velocities_accelerator: Array3D, // velocities of all particles on the accelerator: [Vector3D]
    forces_accelerator: Array3D, // forces of all particles on the accelerator: [Vector3D]
    interaction_mask_accelerator: Buffer, // interaction mask on the accelerator: [bool]
    neighbors_per_cluster_accelerator: Buffer, // neighbors per cluster on the accelerator: [i32]
    neighborlist_offsets_accelerator: Buffer, // offsets to the data stored in each neighbor list on the accelerator: [i32] 
    neighborlists_accelerator: Buffer // neighborlists on the accelerator: [i32]
    
}

fn @get_accelerator_cell_offset(cell_index: i32, accelerator_grid: &AcceleratorGrid) -> i32 { cell_index * accelerator_grid.cell_capacity }

fn @get_accelerator_neighborlist_offset(cell_index: i32, cluster_index: i32, accelerator_grid: &AcceleratorGrid) -> i32 {
    accelerator_grid.neighborlist_capacity * (cell_index * accelerator_grid.cell_capacity + cluster_index)
}

fn allocate_accelerator_grid(
    nx: i32, ny: i32, nz: i32, @cluster_size: i32, cell_capacity: i32, neighborlist_capacity: i32) -> AcceleratorGrid {

    let ncells = nx * ny * nz;
    let capacity_particles = ncells * cell_capacity;
    let capacity_clusters = capacity_particles; // TODO: adapt when cluster_size > 1
    let capacity_neighbors = capacity_clusters * neighborlist_capacity;

    AcceleratorGrid {
        ncells: ncells,
        cell_capacity: cell_capacity,
        cell_sizes: alloc_cpu(ncells * sizeof[i32]()),

        cluster_size: cluster_size,
        neighborlist_capacity: neighborlist_capacity,
        total_number_of_clusters: 0,

        masses_cpu: alloc_cpu(capacity_particles * sizeof[real_t]()),
        positions_cpu: allocate_3d_arrays(capacity_particles, alloc_cpu),
        velocities_cpu: allocate_3d_arrays(capacity_particles, alloc_cpu),
        forces_cpu: allocate_3d_arrays(capacity_particles, alloc_cpu),
        interaction_mask_cpu: alloc_cpu(capacity_particles * sizeof[mask_t]()),
        neighbors_per_cluster_cpu: alloc_cpu(capacity_clusters * sizeof[i32]()),
        neighborlist_offsets_cpu: alloc_cpu(capacity_clusters * sizeof[i32]()),
        neighborlists_cpu: alloc_cpu(capacity_neighbors * sizeof[i32]()),

        masses_accelerator: accelerator_allocate(capacity_particles * sizeof[real_t]()),
        positions_accelerator: accelerator_allocate_3d_arrays(capacity_particles),
        velocities_accelerator: accelerator_allocate_3d_arrays(capacity_particles),
        forces_accelerator: accelerator_allocate_3d_arrays(capacity_particles),
        interaction_mask_accelerator: accelerator_allocate(capacity_particles * sizeof[mask_t]()),
        neighbors_per_cluster_accelerator: accelerator_allocate(capacity_clusters * sizeof[i32]()),
        neighborlist_offsets_accelerator: accelerator_allocate(capacity_clusters * sizeof[i32]()),
        neighborlists_accelerator: accelerator_allocate(capacity_neighbors * sizeof[i32]())
    }
}

fn deallocate_accelerator_grid(accelerator_grid: AcceleratorGrid) -> () {
    release(accelerator_grid.cell_sizes);

    release(accelerator_grid.masses_cpu);
    deallocate_3d_arrays(accelerator_grid.positions_cpu);
    deallocate_3d_arrays(accelerator_grid.velocities_cpu);
    deallocate_3d_arrays(accelerator_grid.forces_cpu);
    release(accelerator_grid.interaction_mask_cpu);
    release(accelerator_grid.neighbors_per_cluster_cpu);
    release(accelerator_grid.neighborlist_offsets_cpu);
    release(accelerator_grid.neighborlists_cpu);

    release(accelerator_grid.masses_accelerator);
    deallocate_3d_arrays(accelerator_grid.positions_accelerator);
    deallocate_3d_arrays(accelerator_grid.velocities_accelerator);
    deallocate_3d_arrays(accelerator_grid.forces_accelerator);
    release(accelerator_grid.interaction_mask_accelerator);
    release(accelerator_grid.neighbors_per_cluster_accelerator);
    release(accelerator_grid.neighborlist_offsets_accelerator);
    release(accelerator_grid.neighborlists_accelerator);
}

fn accelerator_reallocate_cell_buffer(
    accelerator_grid: &AcceleratorGrid,
    buffer: &mut Buffer,
    size: i32,
    cell_capacity: i32,
    elem_size: i32,
    allocate: fn(i32) -> Buffer) -> () {

    let new_buffer = allocate(size * elem_size);
    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);

    range(0, accelerator_grid.ncells, |cell_index| {
        let cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);
        let cell_size = cell_sizes(cell_index);
        let new_offset = cell_index * cell_capacity;

        copy_offset(*buffer, cell_offset * elem_size, new_buffer, new_offset * elem_size, cell_size * elem_size);
    });

    release(*buffer);
    *buffer = new_buffer;
}

fn accelerator_reallocate_cell_3d_arrays(
    accelerator_grid: &AcceleratorGrid,
    array: &mut Array3D,
    size: i32,
    cell_capacity: i32,
    allocate: fn(i32) -> Buffer) -> () {

    let new_array = allocate_3d_arrays(size, allocate);
    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);

    range(0, accelerator_grid.ncells, |cell_index| {
        let cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);
        let cell_size = cell_sizes(cell_index);
        let new_offset = cell_index * cell_capacity;

        copy_offset_3d_arrays(*array, cell_offset, new_array, new_offset, cell_size);
    });

    deallocate_3d_arrays(*array);
    *array = new_array;
}

fn reallocate_accelerator_cell_capacity(accelerator_grid: &mut AcceleratorGrid, capacity: i32) -> () {
    let mut adjusted_capacity = capacity;

    print_string("begin reallocate_cell_capacity(");
    print_i32(capacity);
    print_string(")\n");
    print_flush();

    if capacity % accelerator_grid.cluster_size != 0 {
        adjusted_capacity = capacity + accelerator_grid.cluster_size - (capacity % accelerator_grid.cluster_size);
    }

    let size_particles = adjusted_capacity * accelerator_grid.ncells;
    let size_clusters = size_particles; // TODO: adapt when cluster_size > 1
    let capacity_neighbors = size_clusters * accelerator_grid.neighborlist_capacity;

    accelerator_reallocate_cell_buffer(
        accelerator_grid, &mut accelerator_grid.masses_cpu, size_particles, adjusted_capacity, sizeof[real_t](), alloc_cpu);
    accelerator_reallocate_cell_3d_arrays(
        accelerator_grid, &mut accelerator_grid.positions_cpu, size_particles, adjusted_capacity, alloc_cpu);
    accelerator_reallocate_cell_3d_arrays(
        accelerator_grid, &mut accelerator_grid.velocities_cpu, size_particles, adjusted_capacity, alloc_cpu);
    accelerator_reallocate_cell_3d_arrays(
        accelerator_grid, &mut accelerator_grid.forces_cpu, size_particles, adjusted_capacity, alloc_cpu);
    accelerator_reallocate_cell_buffer(
        accelerator_grid, &mut accelerator_grid.interaction_mask_cpu, size_particles, adjusted_capacity, sizeof[mask_t](), alloc_cpu);
    accelerator_reallocate_cell_buffer(
        accelerator_grid, &mut accelerator_grid.neighbors_per_cluster_cpu, size_clusters, adjusted_capacity, sizeof[i32](), alloc_cpu);
    accelerator_reallocate_cell_buffer(
        accelerator_grid, &mut accelerator_grid.neighborlist_offsets_cpu, size_clusters, adjusted_capacity, sizeof[i32](), alloc_cpu);

    release(accelerator_grid.masses_accelerator);
    deallocate_3d_arrays(accelerator_grid.positions_accelerator);
    deallocate_3d_arrays(accelerator_grid.velocities_accelerator);
    deallocate_3d_arrays(accelerator_grid.forces_accelerator);
    release(accelerator_grid.interaction_mask_accelerator);
    release(accelerator_grid.neighbors_per_cluster_accelerator);
    release(accelerator_grid.neighborlist_offsets_accelerator);
    release(accelerator_grid.neighborlists_cpu);
    release(accelerator_grid.neighborlists_accelerator);

    accelerator_grid.masses_accelerator = accelerator_allocate(size_particles * sizeof[real_t]());
    accelerator_grid.positions_accelerator = accelerator_allocate_3d_arrays(size_particles);
    accelerator_grid.velocities_accelerator = accelerator_allocate_3d_arrays(size_particles);
    accelerator_grid.forces_accelerator = accelerator_allocate_3d_arrays(size_particles);
    accelerator_grid.interaction_mask_accelerator = accelerator_allocate(size_particles * sizeof[mask_t]());
    accelerator_grid.neighbors_per_cluster_accelerator = accelerator_allocate(size_clusters * sizeof[i32]());
    accelerator_grid.neighborlist_offsets_accelerator = accelerator_allocate(size_clusters * sizeof[i32]());

    accelerator_grid.neighborlists_cpu = alloc_cpu(capacity_neighbors * sizeof[i32]());
    accelerator_grid.neighborlists_accelerator = accelerator_allocate(capacity_neighbors * sizeof[i32]());
    accelerator_grid.cell_capacity = adjusted_capacity;

    print_string("end reallocate_cell_capacity\n");
    print_flush();
}

fn reallocate_accelerator_neighborlist_capacity(accelerator_grid: &mut AcceleratorGrid, capacity: i32) -> () {
    let size = capacity * accelerator_grid.ncells * accelerator_grid.cell_capacity;
    let elem_size = sizeof[i32]();
    let new_buffer = alloc_cpu(size * elem_size);
    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);
    let neighbors_per_cluster = get_array_of_i32(accelerator_grid.neighbors_per_cluster_cpu);

    print_string("begin reallocate_neighborlist_capacity(");
    print_i32(capacity);
    print_string(")\n");
    print_flush();

    range(0, accelerator_grid.ncells, |cell_index| {
        let cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);
        let cell_size = cell_sizes(cell_index);

        range(0, cell_size, |cluster| {
            let cluster_index = cell_offset + cluster;
            let nb_list_size = neighbors_per_cluster(cluster_index);

            if nb_list_size > 0 {
                let nb_list_offset = accelerator_grid.neighborlist_capacity * cluster_index;
                let new_offset = capacity * cluster_index;

                copy_offset(
                    accelerator_grid.neighborlists_cpu, nb_list_offset * elem_size,
                    new_buffer, new_offset * elem_size, nb_list_size * elem_size);
            }
        });
    });

    release(accelerator_grid.neighborlists_cpu);
    release(accelerator_grid.neighborlists_accelerator);

    accelerator_grid.neighborlists_cpu = new_buffer;
    accelerator_grid.neighborlists_accelerator = accelerator_allocate(size * elem_size);
    accelerator_grid.neighborlist_capacity = capacity;

    print_string("end reallocate_neighborlist_capacity\n");
    print_flush();
}

fn initialize_accelerator_grid(
    masses: &[real_t],
    positions: &[Vector3D],
    velocities: &[Vector3D],
    nparticles: i32,
    grid: &mut Grid,
    accelerator_grid: &mut AcceleratorGrid,
    allocate: fn(i32) -> Buffer) -> () {

    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);
    let neighbors_per_cluster = get_array_of_i32(accelerator_grid.neighbors_per_cluster_cpu);
    let mut particles = 0;

    range(0, accelerator_grid.ncells, |cell_index| { cell_sizes(cell_index) = 0; });

    for i in range(0, nparticles) {
        if(is_within_domain(positions(i), grid)) {
            insert_particle_accelerator(masses(i), positions(i), velocities(i), grid, accelerator_grid, allocate);
            particles++;
        }
    }

    grid.nparticles = particles;
}

fn insert_particle_accelerator(
    mass: real_t,
    position: Vector3D,
    velocity: Vector3D,
    grid: &Grid,
    accelerator_grid: &mut AcceleratorGrid,
    allocate: fn(i32) -> Buffer) -> () {

    let cell_index = compute_cell_position(position, grid);
    let flat_index = flatten_index(cell_index, grid);

    append_particle_accelerator(flat_index, mass, position, velocity, accelerator_grid, allocate);
}

fn append_particle_accelerator(
    cell_index: i32,
    mass: real_t,
    position: Vector3D,
    velocity: Vector3D,
    accelerator_grid: &mut AcceleratorGrid,
    allocate: fn(i32) -> Buffer) -> () {

    let null_vec = Vector3D { x: 0.0 as real_t, y: 0.0 as real_t, z: 0.0 as real_t };
    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);
    let index = cell_sizes(cell_index);
    let mut cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);

    if index >= accelerator_grid.cell_capacity {
        let new_capacity = accelerator_grid.cell_capacity + accelerator_grid.cell_capacity / 10 + 1;
        reallocate_accelerator_cell_capacity(accelerator_grid, new_capacity);
        cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);
    }

    cell_sizes(cell_index) += 1;

    let particle_index = cell_offset + index;

    set_real(particle_index, accelerator_grid.masses_cpu, mass);
    set_3d_arrays(particle_index, accelerator_grid.positions_cpu, position);
    set_3d_arrays(particle_index, accelerator_grid.velocities_cpu, velocity);
    set_3d_arrays(particle_index, accelerator_grid.forces_cpu, null_vec);
    set_mask_t(particle_index, accelerator_grid.interaction_mask_cpu, MASK_TRUE);
    set_i32(particle_index, accelerator_grid.neighbors_per_cluster_cpu, 0);
}

fn swap_particles_accelerator(cell_offset: i32, pos1: i32, pos2: i32, accelerator_grid: &mut AcceleratorGrid) -> () {
    let i = cell_offset + pos1;
    let j = cell_offset + pos2;

    swap_real(i, j, accelerator_grid.masses_cpu);
    swap_3d_arrays(i, j, accelerator_grid.positions_cpu);
    swap_3d_arrays(i, j, accelerator_grid.velocities_cpu);
}

fn remove_particle_accelerator(cell_index: i32, cell_offset: i32, index: i32, accelerator_grid: &mut AcceleratorGrid) -> () {
    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);

    swap_particles_accelerator(cell_offset, index, cell_sizes(cell_index) - 1, accelerator_grid);
    cell_sizes(cell_index) -= 1;
}

fn redistribute_particles_accelerator(grid: Grid, accelerator_grid: &mut AcceleratorGrid, allocate: fn(i32) -> Buffer) -> () {
    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);

    range(0, accelerator_grid.ncells, |cell_index| {
        let mut cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);
        let mut cell_size = cell_sizes(cell_index);
        let mut i = 0;

        while i < cell_size {
            let position = get_vector_from_3d_arrays(cell_offset + i, accelerator_grid.positions_cpu);

            if is_within_domain(position, grid) {
                let cur_index = flatten_index(compute_cell_position(position, grid), grid);

                if cur_index != cell_index {
                    let mass = get_real(cell_offset + i, accelerator_grid.masses_cpu);
                    let velocity = get_vector_from_3d_arrays(cell_offset + i, accelerator_grid.velocities_cpu);

                    remove_particle_accelerator(cell_index, cell_offset, i, accelerator_grid);
                    append_particle_accelerator(cur_index, mass, position, velocity, accelerator_grid, allocate);

                    cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);
                    cell_size -= 1;
                } else {
                    ++i;
                }
            } else {
                ++i;
            }
        }
    });
}

fn transfer_grid_to_accelerator_buffers(grid: &Grid, accelerator_grid: &mut AcceleratorGrid) -> () {
    // Count the total number of clusters and neighbors within all cells
    let counts = grid_count_clusters_and_neighbors(grid);
    let number_of_clusters = counts(0);
    let number_of_neighbors = counts(1);

    accelerator_grid.total_number_of_clusters = number_of_clusters;

    let neighbors_per_cluster = get_array_of_i32(accelerator_grid.neighbors_per_cluster_cpu);
    let neighborlist_offsets = get_array_of_i32(accelerator_grid.neighborlist_offsets_cpu);
    let neighborlists_cpu = get_array_of_i32(accelerator_grid.neighborlists_cpu);
    let mut offset_cells = 0;
    let mut offset_clusters = 0;
    let mut offset_neighbors = 0;

    // Copy cell data to accelerator
    for cell, index in map_over_grid(grid, range, range, range) {
        if(cell.cluster_size != accelerator_grid.cluster_size) {
            print_string("Cluster sizes on CPU and accelerator are not equal!\n");
        } else {
            // First compute the offset for each cell within the accelerator arrays, the offset for the next
            // cell is obtained by adding the size of the last cell to the old offset value
            let total_cell_size = cell.size + cell.padding;
            let flat_index = flatten_index(index, grid); 

            if(cell.size > 0) {
                let clusters_in_cell = get_array_of_clusters(cell.clusters);

                copy_offset(cell.masses, 0, accelerator_grid.masses_cpu, offset_cells * sizeof[real_t](), cell.size * sizeof[real_t]());
                copy_offset_3d_arrays(cell.positions, 0, accelerator_grid.positions_cpu, offset_cells, cell.size);
                copy_offset_3d_arrays(cell.velocities, 0, accelerator_grid.velocities_cpu, offset_cells, cell.size);

                for i in range(0, cell.size) {
                    set_mask_t(offset_cells + i, accelerator_grid.interaction_mask_cpu, MASK_TRUE);
                }

                for i in range(cell.size, total_cell_size) { 
                    set_mask_t(offset_cells + i, accelerator_grid.interaction_mask_cpu, MASK_FALSE);
                }

                for i in range(0, cell.nclusters) {
                    let nb_list_size = clusters_in_cell(i).nb_list_size;

                    neighbors_per_cluster(offset_clusters + i) = nb_list_size;
                    neighborlist_offsets(offset_clusters + i) = offset_neighbors;
                    offset_neighbors += nb_list_size;
                }

                offset_clusters += cell.nclusters; 
                offset_cells += total_cell_size;
            }
        }
    }

    offset_neighbors = 0;

    for cell, index in map_over_grid(grid, range, range, range) {
        if(cell.cluster_size != accelerator_grid.cluster_size) {
            print_string("Cluster sizes on CPU and accelerator are not equal!\n");
        } else if(cell.size > 0) {
            let clusters_in_cell = get_array_of_clusters(cell.clusters); 
            let mut buffer_offset = 0;

            for i in range(0, cell.nclusters) {
                let nb_list_size = clusters_in_cell(i).nb_list_size;
                let neighboring_cells = get_array_of_cell_pointers(cell.neighbor_cells);
                let neighboring_indices = get_array_of_i32(cell.neighbor_indices);

                for j in range(0, nb_list_size) {
                    let neighboring_cell = neighboring_cells(buffer_offset + j);

                    neighborlists_cpu(offset_neighbors + j) =
                        get_accelerator_cell_offset(neighboring_cell.index, accelerator_grid) +
                        neighboring_indices(buffer_offset + j) * accelerator_grid.cluster_size;
                }

                buffer_offset += cell.neighbor_list_capacity;
                offset_neighbors += nb_list_size;
            }
        }
    }
}

fn transfer_accelerator_buffers_to_grid(accelerator_grid: &AcceleratorGrid, grid: &Grid) -> () {
    for cell, index in map_over_grid(grid, range, range, range) {
        if(cell.cluster_size != accelerator_grid.cluster_size) {
            print_string("Cluster sizes on CPU and accelerator are not equal!\n");
        } else if(cell.size > 0) {
            let flat_index = flatten_index(index, grid);
            let offset = get_accelerator_cell_offset(flat_index, accelerator_grid);

            copy_offset_3d_arrays(accelerator_grid.positions_cpu, offset, cell.positions, 0, cell.size);
            copy_offset_3d_arrays(accelerator_grid.velocities_cpu, offset, cell.velocities, 0, cell.size);
            copy_offset_3d_arrays(accelerator_grid.forces_cpu, offset, cell.forces, 0, cell.size);
        }
    }
}

fn copy_to_accelerator(accelerator_grid: &AcceleratorGrid) -> () {
    transfer_between_devices(accelerator_grid.masses_cpu, accelerator_grid.masses_accelerator);
    transfer_3d_arrays_between_devices(accelerator_grid.positions_cpu, accelerator_grid.positions_accelerator);
    transfer_3d_arrays_between_devices(accelerator_grid.velocities_cpu, accelerator_grid.velocities_accelerator);
    transfer_between_devices(accelerator_grid.interaction_mask_cpu, accelerator_grid.interaction_mask_accelerator);
    transfer_between_devices(accelerator_grid.neighbors_per_cluster_cpu, accelerator_grid.neighbors_per_cluster_accelerator);
    transfer_between_devices(accelerator_grid.neighborlist_offsets_cpu, accelerator_grid.neighborlist_offsets_accelerator);
    transfer_between_devices(accelerator_grid.neighborlists_cpu, accelerator_grid.neighborlists_accelerator);
}

fn copy_from_accelerator(accelerator_grid: &AcceleratorGrid) -> () {
    transfer_3d_arrays_between_devices(accelerator_grid.positions_accelerator, accelerator_grid.positions_cpu);
    transfer_3d_arrays_between_devices(accelerator_grid.velocities_accelerator, accelerator_grid.velocities_cpu);
    transfer_3d_arrays_between_devices(accelerator_grid.forces_accelerator, accelerator_grid.forces_cpu);
}

fn write_accelerator_grid_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    accelerator_grid: &AcceleratorGrid) -> i32 {

    let cell_sizes = get_array_of_i32(accelerator_grid.cell_sizes);
    let mut array_index = 0;

    range(0, accelerator_grid.ncells, |cell_index| {
        let cell_offset = get_accelerator_cell_offset(cell_index, accelerator_grid);
        let cell_size = cell_sizes(cell_index);

        range(0, cell_size, |cluster| {
            let cluster_index = cell_offset + cluster;

            masses(array_index) = get_real(cluster_index, accelerator_grid.masses_cpu);
            positions(array_index) = get_vector_from_3d_arrays(cluster_index, accelerator_grid.positions_cpu);
            velocities(array_index) = get_vector_from_3d_arrays(cluster_index, accelerator_grid.velocities_cpu);
            forces(array_index) = get_vector_from_3d_arrays(cluster_index, accelerator_grid.forces_cpu);

            ++array_index;
        });
    });

    array_index
}

