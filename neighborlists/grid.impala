struct AABB {
    xmin: real_t,
    xmax: real_t,
    ymin: real_t,
    ymax: real_t,
    zmin: real_t,
    zmax: real_t
}

struct Grid {
    aabb: AABB, // grid bounding box
    nx: i32, // number of cells in x dimension
    ny: i32, // number of cells in y dimension
    nz: i32, // number of cells in z dimension
    particle_capacity: i32, // particle capacity in grid
    cell_capacity: i32, // cell capacity in grid
    neighborlist_capacity: i32, // capacity of the neighborlists arrays
    ncells: i32, // number of cells in the grid
    nparticles: i32, // number of particles in the grid
    nghost: i32, // number of ghost particles in the grid
    spacing: real_t, // cell spacing

    cell_particles_cpu: Buffer, // particles in each cell [i32]
    cell_sizes_cpu: Buffer, // sizes of each cell [i32]
    particles_cell_cpu: Buffer, // cell assigned to particle [i32]
    masses_cpu: Buffer, // masses of all particles on the CPU: [real_t]
    positions_cpu: Array3D, // positions of all particles on the CPU: [Vector3D]
    velocities_cpu: Array3D, // velocities of all particles on the CPU: [Vector3D]
    forces_cpu: Array3D, // forces of all particles on the CPU: [Vector3D]
    ghost_mask_cpu: Buffer, // ghost mask on the CPU: [bool]
    neighbors_sizes_cpu: Buffer, // neighbors per cluster on the CPU: [i32]
    neighborlists_cpu: Buffer, // neighborlists on the CPU: [i32]

    cell_particles_accelerator: Buffer, // particles in each cell [i32]
    cell_sizes_accelerator: Buffer, // sizes of each cell [i32]
    particles_cell_accelerator: Buffer, // cell assigned to particle on the accelerator [i32]
    masses_accelerator: Buffer, // masses of all particles on the accelerator: [real_t]
    positions_accelerator: Array3D, // positions of all particles on the accelerator: [Vector3D]
    velocities_accelerator: Array3D, // velocities of all particles on the accelerator: [Vector3D]
    forces_accelerator: Array3D, // forces of all particles on the accelerator: [Vector3D]
    ghost_mask_accelerator: Buffer, // ghost mask on the accelerator: [bool]
    neighbors_sizes_accelerator: Buffer, // neighbors per cluster on the accelerator: [i32]
    neighborlists_accelerator: Buffer // neighborlists on the accelerator: [i32]
}

fn @get_cell_offset(cell_index: i32, grid: &Grid) -> i32 { cell_index * grid.cell_capacity }

fn @get_neighborlist_offset(cell_index: i32, cluster_index: i32, grid: &Grid) -> i32 {
    grid.neighborlist_capacity * (cell_index * grid.cell_capacity + cluster_index)
}

fn allocate_grid(
    aabb: AABB,
    cell_spacing: f64,
    cell_capacity: i32,
    neighborlist_capacity: i32) -> Grid {

    let lastx = last_dimension_node(0);
    let lasty = last_dimension_node(1);
    let lastz = last_dimension_node(2);

    let mut nx = real_floor(((aabb.xmax - aabb.xmin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32;
    let mut ny = real_floor(((aabb.ymax - aabb.ymin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32;
    let mut nz = real_floor(((aabb.zmax - aabb.zmin + (cell_spacing / (2.0 as real_t))) / cell_spacing)) as i32;

    if lastx {
        nx++;
    }

    if lasty {
        ny++;
    }

    if lastz {
        nz++;
    }

    let ncells = nx * ny * nz;
    let particle_capacity = ncells * 32;
    let neighbors_capacity = particle_capacity * neighborlist_capacity;

    Grid {
        aabb: aabb,
        nx: nx,
        ny: ny,
        nz: nz,
        particle_capacity: particle_capacity,
        cell_capacity: cell_capacity,
        neighborlist_capacity: neighborlist_capacity,
        ncells: ncells,
        nparticles: 0,
        nghost: 0,
        spacing: cell_spacing,

        cell_particles_cpu: alloc_cpu(ncells * cell_capacity * sizeof[i32]()),
        cell_sizes_cpu: alloc_cpu(ncells * sizeof[i32]()),
        particles_cell_cpu: alloc_cpu(particle_capacity * sizeof[i32]()),
        masses_cpu: alloc_cpu(particle_capacity * sizeof[real_t]()),
        positions_cpu: allocate_3d_arrays(particle_capacity, alloc_cpu),
        velocities_cpu: allocate_3d_arrays(particle_capacity, alloc_cpu),
        forces_cpu: allocate_3d_arrays(particle_capacity, alloc_cpu),
        ghost_mask_cpu: alloc_cpu(particle_capacity * sizeof[mask_t]()),
        neighbors_sizes_cpu: alloc_cpu(particle_capacity * sizeof[i32]()),
        neighborlists_cpu: alloc_cpu(neighbors_capacity * sizeof[i32]()),

        cell_particles_accelerator: accelerator_allocate(ncells * cell_capacity * sizeof[i32]()),
        cell_sizes_accelerator: accelerator_allocate(ncells * sizeof[i32]()),
        particles_cell_accelerator: accelerator_allocate(particle_capacity * sizeof[i32]()),
        masses_accelerator: accelerator_allocate(particle_capacity * sizeof[real_t]()),
        positions_accelerator: accelerator_allocate_3d_arrays(particle_capacity),
        velocities_accelerator: accelerator_allocate_3d_arrays(particle_capacity),
        forces_accelerator: accelerator_allocate_3d_arrays(particle_capacity),
        ghost_mask_accelerator: accelerator_allocate(particle_capacity * sizeof[mask_t]()),
        neighbors_sizes_accelerator: accelerator_allocate(particle_capacity * sizeof[i32]()),
        neighborlists_accelerator: accelerator_allocate(neighbors_capacity * sizeof[i32]())
    }
}

fn deallocate_grid(grid: Grid) -> () {
    release(grid.cell_particles_cpu);
    release(grid.cell_sizes_cpu);
    release(grid.particles_cell_cpu);
    release(grid.masses_cpu);
    deallocate_3d_arrays(grid.positions_cpu);
    deallocate_3d_arrays(grid.velocities_cpu);
    deallocate_3d_arrays(grid.forces_cpu);
    release(grid.ghost_mask_cpu);
    release(grid.neighbors_sizes_cpu);
    release(grid.neighborlists_cpu);

    release(grid.cell_particles_accelerator);
    release(grid.cell_sizes_accelerator);
    release(grid.particles_cell_accelerator);
    release(grid.masses_accelerator);
    deallocate_3d_arrays(grid.positions_accelerator);
    deallocate_3d_arrays(grid.velocities_accelerator);
    deallocate_3d_arrays(grid.forces_accelerator);
    release(grid.ghost_mask_accelerator);
    release(grid.neighbors_sizes_accelerator);
    release(grid.neighborlists_accelerator);
}

fn reallocate_particle_buffer(buffer: &mut Buffer, size: i32, elem_size: i32, allocate: fn(i32) -> Buffer) -> () {
    let new_buffer = allocate(size * elem_size);

    copy(*buffer, new_buffer);
    release(*buffer);

    *buffer = new_buffer;
}

fn reallocate_particle_3d_arrays(array: &mut Array3D, size: i32, particle_capacity: i32, allocate: fn(i32) -> Buffer) -> () {
    let new_array = allocate_3d_arrays(size, allocate);

    copy_offset_3d_arrays(*array, 0, new_array, 0, particle_capacity);
    deallocate_3d_arrays(*array);

    *array = new_array;
}

fn reallocate_cell_buffer(
    grid: &Grid,
    buffer: &mut Buffer,
    size: i32,
    cell_capacity: i32,
    elem_size: i32,
    allocate: fn(i32) -> Buffer) -> () {

    let new_buffer = allocate(size * elem_size);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    range(0, grid.ncells, |cell_index| {
        let cell_offset = get_cell_offset(cell_index, grid);
        let cell_size = cell_sizes(cell_index);
        let new_offset = cell_index * cell_capacity;

        copy_offset(*buffer, cell_offset * elem_size, new_buffer, new_offset * elem_size, cell_size * elem_size);
    });

    release(*buffer);
    *buffer = new_buffer;
}

fn reallocate_cell_3d_arrays(
    grid: &Grid,
    array: &mut Array3D,
    size: i32,
    cell_capacity: i32,
    allocate: fn(i32) -> Buffer) -> () {

    let new_array = allocate_3d_arrays(size, allocate);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    range(0, grid.ncells, |cell_index| {
        let cell_offset = get_cell_offset(cell_index, grid);
        let cell_size = cell_sizes(cell_index);
        let new_offset = cell_index * cell_capacity;

        copy_offset_3d_arrays(*array, cell_offset, new_array, new_offset, cell_size);
    });

    deallocate_3d_arrays(*array);
    *array = new_array;
}

fn reallocate_particle_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_string("begin reallocate_particle_capacity(");
    print_i32(capacity);
    print_string(")\n");
    print_flush();

    reallocate_particle_buffer(&mut grid.particles_cell_cpu, capacity, sizeof[i32](), alloc_cpu);
    reallocate_particle_buffer(&mut grid.masses_cpu, capacity, sizeof[real_t](), alloc_cpu);
    reallocate_particle_3d_arrays(&mut grid.positions_cpu, capacity, grid.particle_capacity, alloc_cpu);
    reallocate_particle_3d_arrays(&mut grid.velocities_cpu, capacity, grid.particle_capacity, alloc_cpu);
    reallocate_particle_3d_arrays(&mut grid.forces_cpu, capacity, grid.particle_capacity, alloc_cpu);
    reallocate_particle_buffer(&mut grid.ghost_mask_cpu, capacity, sizeof[mask_t](), alloc_cpu);
    reallocate_particle_buffer(&mut grid.neighbors_sizes_cpu, capacity, sizeof[i32](), alloc_cpu);

    release(grid.particles_cell_accelerator);
    release(grid.masses_accelerator);
    deallocate_3d_arrays(grid.positions_accelerator);
    deallocate_3d_arrays(grid.velocities_accelerator);
    deallocate_3d_arrays(grid.forces_accelerator);
    release(grid.ghost_mask_accelerator);
    release(grid.neighbors_sizes_accelerator);
    release(grid.neighborlists_cpu);
    release(grid.neighborlists_accelerator);

    grid.particles_cell_accelerator = accelerator_allocate(capacity * sizeof[i32]());
    grid.masses_accelerator = accelerator_allocate(capacity * sizeof[real_t]());
    grid.positions_accelerator = accelerator_allocate_3d_arrays(capacity);
    grid.velocities_accelerator = accelerator_allocate_3d_arrays(capacity);
    grid.forces_accelerator = accelerator_allocate_3d_arrays(capacity);
    grid.ghost_mask_accelerator = accelerator_allocate(capacity * sizeof[mask_t]());
    grid.neighbors_sizes_accelerator = accelerator_allocate(capacity * sizeof[i32]());

    grid.neighborlists_cpu = alloc_cpu(capacity * grid.neighborlist_capacity * sizeof[i32]());
    grid.neighborlists_accelerator = accelerator_allocate(capacity * grid.neighborlist_capacity * sizeof[i32]());
    grid.particle_capacity = capacity;

    print_string("end reallocate_particle_capacity\n");
    print_flush();
}

fn reallocate_cell_capacity(grid: &mut Grid, capacity: i32) -> () {
    print_string("begin reallocate_cell_capacity(");
    print_i32(capacity);
    print_string(")\n");
    print_flush();

    reallocate_cell_buffer(grid, &mut grid.cell_particles_cpu, capacity * grid.ncells, grid.cell_capacity, sizeof[i32](), alloc_cpu);

    release(grid.cell_particles_accelerator);
    grid.cell_particles_accelerator = accelerator_allocate(capacity * grid.ncells * sizeof[i32]());

    grid.cell_capacity = capacity;

    print_string("end reallocate_cell_capacity\n");
    print_flush();
}

fn reallocate_neighborlist_capacity(grid: &mut Grid, capacity: i32) -> () {
    let size = capacity * grid.particle_capacity;
    let elem_size = sizeof[i32]();
    let new_buffer = alloc_cpu(size * elem_size);
    let neighbors_sizes = get_array_of_i32(grid.neighbors_sizes_cpu);

    print_string("begin reallocate_neighborlist_capacity(");
    print_i32(capacity);
    print_string(")\n");
    print_flush();

    range(0, grid.nparticles, |particle_index| {
        let nb_list_size = neighbors_sizes(particle_index);
        let nb_list_offset = grid.neighborlist_capacity * particle_index;
        let new_offset = capacity * particle_index;

        copy_offset(
            grid.neighborlists_cpu, nb_list_offset * elem_size,
            new_buffer, new_offset * elem_size, nb_list_size * elem_size);
    });

    release(grid.neighborlists_cpu);
    release(grid.neighborlists_accelerator);

    grid.neighborlists_cpu = new_buffer;
    grid.neighborlists_accelerator = accelerator_allocate(size * elem_size);
    grid.neighborlist_capacity = capacity;

    print_string("end reallocate_neighborlist_capacity\n");
    print_flush();
}

fn initialize_grid(
    masses: &[real_t],
    positions: &[Vector3D],
    velocities: &[Vector3D],
    nparticles: i32,
    grid: &mut Grid,
    allocate: fn(i32) -> Buffer) -> () {

    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    range(0, grid.ncells, |cell_index| { cell_sizes(cell_index) = 0; });

    for i in range(0, nparticles) {
        if(is_within_domain(positions(i), grid)) {
            insert_particle(masses(i), positions(i), velocities(i), grid, allocate);
        }
    }
}

fn insert_particle(
    mass: real_t,
    position: Vector3D,
    velocity: Vector3D,
    grid: &mut Grid,
    allocate: fn(i32) -> Buffer) -> () {

    let cell_index = compute_cell_position(position, grid);
    let flat_index = flatten_index(cell_index, grid);

    if is_local_cell(cell_index(0), cell_index(1), cell_index(2), grid) {
        append_particle(flat_index, mass, position, velocity, MASK_TRUE, grid, allocate);
    }
}

fn append_particle(
    cell_index: i32,
    mass: real_t,
    position: Vector3D,
    velocity: Vector3D,
    ghost_mask: mask_t,
    grid: &mut Grid,
    allocate: fn(i32) -> Buffer) -> () {

    let null_vec = Vector3D { x: 0.0 as real_t, y: 0.0 as real_t, z: 0.0 as real_t };
    let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
    let particles_cell = get_array_of_i32(grid.particles_cell_cpu);
    let particle_index = grid.nparticles;
    let cell_particle_index = cell_sizes(cell_index);

    if particle_index >= grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + 10;
        reallocate_particle_capacity(grid, new_capacity);
    }

    if cell_particle_index >= grid.cell_capacity {
        let new_capacity = grid.cell_capacity + grid.cell_capacity / 10 + 1;
        reallocate_cell_capacity(grid, new_capacity);
    }

    let cell_offset = get_cell_offset(cell_index, grid);

    particles_cell(particle_index) = cell_index;
    cell_particles(cell_offset + cell_particle_index) = particle_index;
    cell_sizes(cell_index)++;

    set_real(particle_index, grid.masses_cpu, mass);
    set_3d_arrays(particle_index, grid.positions_cpu, position);
    set_3d_arrays(particle_index, grid.velocities_cpu, velocity);
    set_3d_arrays(particle_index, grid.forces_cpu, null_vec);
    set_mask_t(particle_index, grid.ghost_mask_cpu, ghost_mask);
    set_i32(particle_index, grid.neighbors_sizes_cpu, 0);

    grid.nparticles++;
}

fn add_ghost_cell_slots(cell_index: i32, slots: i32, first_index: i32, grid: &mut Grid) -> () {
    let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
    let particles_cell = get_array_of_i32(grid.particles_cell_cpu);
    let first_particle_index = grid.nparticles + grid.nghost;

    if first_particle_index + slots > grid.particle_capacity {
        let new_capacity = grid.particle_capacity + grid.particle_capacity / 10 + slots;
        reallocate_particle_capacity(grid, new_capacity);
    }

    if first_index + slots > grid.cell_capacity {
        let new_capacity = grid.cell_capacity + grid.cell_capacity / 10 + slots;
        reallocate_cell_capacity(grid, new_capacity);
    }

    let cell_offset = get_cell_offset(cell_index, grid);

    range(0, slots, |slot| {
        particles_cell(first_particle_index + slot) = cell_index;
        cell_particles(cell_offset + first_index + slot) = first_particle_index + slot;
    });

    cell_sizes(cell_index) += slots;
    grid.nghost += slots;
}

// Particles must be at the same cell
fn swap_particles(i: i32, j: i32, grid: &mut Grid) -> () {
    swap_real(i, j, grid.masses_cpu);
    swap_3d_arrays(i, j, grid.positions_cpu);
    swap_3d_arrays(i, j, grid.velocities_cpu);
}

fn move_particle(particle_index: i32, source_cell: i32, dest_cell: i32, grid: &mut Grid) -> () {
    let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
    let particles_cell = get_array_of_i32(grid.particles_cell_cpu);
    let source_cell_size = cell_sizes(source_cell);
    let dest_cell_size = cell_sizes(dest_cell);

    if dest_cell_size + 1 >= grid.cell_capacity {
        reallocate_cell_capacity(grid, grid.cell_capacity + 10);
    }

    let source_cell_offset = get_cell_offset(source_cell, grid);
    let dest_cell_offset = get_cell_offset(dest_cell, grid);
    let last_source_particle = cell_particles(source_cell_offset + source_cell_size - 1);

    swap_particles(particle_index, last_source_particle, grid);
    cell_particles(dest_cell_offset + dest_cell_size) = last_source_particle;
    particles_cell(last_source_particle) = dest_cell;

    cell_sizes(source_cell)--;
    cell_sizes(dest_cell)++;
}

fn promote_particle(particle_index: i32, cell_particle_index: i32, grid: &mut Grid) -> i32 {
    let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
    let particles_cell = get_array_of_i32(grid.particles_cell_cpu);
    let cell = particles_cell(particle_index);
    let cell_offset = get_cell_offset(cell, grid);
    let first_ghost_index = grid.nparticles;
    let first_ghost_cell = particles_cell(first_ghost_index);
    let first_ghost_cell_offset = get_cell_offset(cell, grid);

    swap_particles(particle_index, first_ghost_index, grid);
    cell_particles(cell_offset + cell_particle_index) = first_ghost_index;
    cell_particles(first_ghost_cell_offset) = particle_index; // assume first index
    particles_cell(particle_index) = first_ghost_cell;
    particles_cell(first_ghost_index) = cell;

    grid.nparticles++;
    grid.nghost--;

    first_ghost_index
}

fn demote_particle(particle_index: i32, cell_particle_index: i32, grid: &mut Grid) -> i32 {
    let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
    let particles_cell = get_array_of_i32(grid.particles_cell_cpu);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
    let cell = particles_cell(particle_index);
    let cell_offset = get_cell_offset(cell, grid);
    let last_local_index = grid.nparticles - 1;
    let last_local_cell = particles_cell(last_local_index);
    let last_local_cell_size = cell_sizes(last_local_cell);
    let last_local_cell_offset = get_cell_offset(last_local_cell, grid);

    swap_particles(particle_index, last_local_index, grid);
    cell_particles(cell_offset + cell_particle_index) = last_local_index;
    cell_particles(last_local_cell_offset + last_local_cell_size - 1) = particle_index; // assume last index
    particles_cell(particle_index) = last_local_cell;
    particles_cell(last_local_index) = cell;

    grid.nparticles--;
    grid.nghost++;

    last_local_index
}

fn redistribute_particles(grid: &mut Grid, allocate: fn(i32) -> Buffer) -> () {
    let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    range(0, grid.ncells, |cell_index| {
        let mut cell_size = cell_sizes(cell_index);
        let mut cell_offset = get_cell_offset(cell_index, grid);
        let mut i = 0;

        let spatial_index = unflatten_index(cell_index, grid);

        while i < cell_size {
            let particle_index = cell_particles(cell_offset + i);
            let position = get_vector_from_3d_arrays(particle_index, grid.positions_cpu);

            if is_within_domain(position, grid) {
                let mut new_spatial_index = compute_cell_position(position, grid);

                new_spatial_index(0) = math.max(new_spatial_index(0), 0);
                new_spatial_index(0) = math.min(new_spatial_index(0), grid.nx - 1);
                new_spatial_index(1) = math.max(new_spatial_index(1), 0);
                new_spatial_index(1) = math.min(new_spatial_index(1), grid.ny - 1);
                new_spatial_index(2) = math.max(new_spatial_index(2), 0);
                new_spatial_index(2) = math.min(new_spatial_index(2), grid.nz - 1);

                let cur_index = flatten_index(new_spatial_index, grid);

                if cur_index != cell_index {
                    let from_local = is_local_cell(spatial_index(0), spatial_index(1), spatial_index(2), grid);
                    let to_local = is_local_cell(new_spatial_index(0), new_spatial_index(1), new_spatial_index(2), grid);

                    if from_local && to_local {
                        move_particle(particle_index, cell_index, cur_index, grid);
                        cell_offset = get_cell_offset(cell_index, grid);
                        cell_size--;
                    } else {
                        ++i;
                    }
                } else {
                    ++i;
                }
            } else {
                ++i;
            }
        }
    });
}

fn copy_to_accelerator(grid: &Grid) -> () {
    transfer_between_devices(grid.cell_particles_cpu, grid.cell_particles_accelerator);
    transfer_between_devices(grid.cell_sizes_cpu, grid.cell_sizes_accelerator);
    transfer_between_devices(grid.particles_cell_cpu, grid.particles_cell_accelerator);
    transfer_between_devices(grid.masses_cpu, grid.masses_accelerator);
    transfer_3d_arrays_between_devices(grid.positions_cpu, grid.positions_accelerator);
    transfer_3d_arrays_between_devices(grid.velocities_cpu, grid.velocities_accelerator);
    transfer_between_devices(grid.ghost_mask_cpu, grid.ghost_mask_accelerator);
}

fn copy_from_accelerator(grid: &Grid) -> () {
    transfer_3d_arrays_between_devices(grid.positions_accelerator, grid.positions_cpu);
    transfer_3d_arrays_between_devices(grid.velocities_accelerator, grid.velocities_cpu);
    transfer_3d_arrays_between_devices(grid.forces_accelerator, grid.forces_cpu);
}

fn write_grid_data_to_arrays(
    masses: &mut[real_t],
    positions: &mut [Vector3D],
    velocities: &mut [Vector3D],
    forces: &mut [Vector3D],
    grid: &Grid) -> i32 {

    range(0, grid.nparticles, |particle_index| {
        masses(particle_index) = get_real(particle_index, grid.masses_cpu);
        positions(particle_index) = get_vector_from_3d_arrays(particle_index, grid.positions_cpu);
        velocities(particle_index) = get_vector_from_3d_arrays(particle_index, grid.velocities_cpu);
        forces(particle_index) = get_vector_from_3d_arrays(particle_index, grid.forces_cpu);
    });

    grid.nparticles
}

fn @compute_cell_position(position: Vector3D, grid: &Grid) -> [i32 * 3] {
    let i = real_floor(((position.x - grid.aabb.xmin) / grid.spacing) as real_t) as i32;
    let j = real_floor(((position.y - grid.aabb.ymin) / grid.spacing) as real_t) as i32;
    let k = real_floor(((position.z - grid.aabb.zmin) / grid.spacing) as real_t) as i32;

    [i, j, k]
}

fn is_within_domain(position: Vector3D, grid: &Grid) -> bool {
    let aabb = (*grid).aabb;

    position.x >= aabb.xmin && position.x <= aabb.xmax &&
    position.y >= aabb.ymin && position.y <= aabb.ymax &&
    position.z >= aabb.zmin && position.z <= aabb.zmax
}

fn map_over_grid_particles(grid: &Grid, iterate: fn(i32, i32, fn(i32) -> ()) -> (), body: fn(i32) -> ()) -> () {
    iterate(0, grid.nparticles, |particle_index| {
        body(particle_index)
    });
}

fn map_over_cell_particles(grid: &Grid, cell_index: i32, iterate: fn(i32, i32, fn(i32) -> ()) -> (), body: fn(i32) -> ()) -> () {
    let cell_particles = get_array_of_i32(grid.cell_particles_cpu);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);
    let cell_offset = get_cell_offset(cell_index, grid);

    iterate(0, cell_sizes(cell_index), |cell_particle_index| {
        body(cell_particles(cell_offset + cell_particle_index))
    });
}

fn map_over_grid_cells(
    grid: &Grid,
    iterate_outer: fn(i32, i32, fn(i32) -> ()) -> (),
    iterate_middle: fn(i32, i32, fn(i32) -> ()) -> (),
    iterate_inner: fn(i32, i32, fn(i32) -> ()) -> (),
    body: fn(i32, [i32 * 3]) -> ()) -> () {

    iterate_outer(0, grid.nx, |i| {
        iterate_middle(0, grid.ny, |j| {
            iterate_inner(0, grid.nz, |k| {
                let cell_index = [i, j, k];
                body(flatten_index(cell_index, grid), cell_index)
            });
        });
    });
}

fn map_over_grid_subdomain(
    grid: &Grid,
    xbegin: i32,
    ybegin: i32,
    zbegin: i32,
    xend: i32,
    yend: i32,
    zend: i32,
    iterate_outer: fn(i32, i32, fn(i32) -> ()) -> (),
    iterate_middle: fn(i32, i32, fn(i32) -> ()) -> (),
    iterate_inner: fn(i32, i32, fn(i32) -> ()) -> (),
    body: fn(i32, [i32 * 3]) -> ()) -> () {

    iterate_outer(xbegin, xend, |i| {
        iterate_middle(ybegin, yend, |j| {
            iterate_inner(zbegin, zend, |k| {
                let cell_index = [i, j, k];
                body(flatten_index(cell_index, grid), cell_index)
            });
        });
    });
}

fn @flatten_index(cell_index: [i32 * 3], grid: &Grid) -> i32 {
    (cell_index(2) * grid.ny + cell_index(1)) * grid.nx + cell_index(0)
}

fn @unflatten_index(index: i32, grid: &Grid) -> [i32 * 3] {
    [index % grid.nx, (index / grid.nx) % grid.ny, index / (grid.nx * grid.ny)]
}
