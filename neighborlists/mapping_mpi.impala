fn @get_comm_time_steps() -> i32 { 1 }

fn mpi_initialize(world_size: &mut i32, world_rank: &mut i32) -> () {
  let mpih = mpi();

  mpih.init();

  mpih.comm_size(mpih.comms.world, world_size);
  mpih.comm_rank(mpih.comms.world, world_rank);
}

fn mpi_finalize() -> () {
  let mpih = mpi();

  mpih.finalize();
}

fn mpi_send_subdomains(
  world_size: i32,
  rank: i32,
  grid: Grid,
  body: fn(i32, [i32 * 3], [i32 * 3]) -> ()) -> () {

  if(rank > 0) {
    body(
      rank - 1,
      [0, 0, get_comm_time_steps()],
      [grid.nx, grid.ny, get_comm_time_steps() * 2]
    );
  }

  if(rank < world_size - 1) {
    body(
      rank + 1,
      [0, 0, grid.nz - get_comm_time_steps() * 2],
      [grid.nx, grid.ny, grid.nz - get_comm_time_steps()]
    );
  }
}

fn mpi_receive_subdomains(
  world_size: i32,
  rank: i32,
  grid: Grid,
  body: fn(i32, [i32 * 3], [i32 * 3]) -> ()) -> () {

  if(rank > 0) {
    body(
      rank - 1,
      [0, 0, 0],
      [grid.nx, grid.ny, get_comm_time_steps()]
    );
  }

  if(rank < world_size - 1) {
    body(
      rank + 1,
      [0, 0, grid.nz - get_comm_time_steps()],
      [grid.nx, grid.ny, grid.nz]
    );
  }
}

fn @mpi_get_rank_bounding_box(
  world_size: i32,
  rank: i32,
  cell_spacing: f64,
  grid_aabb: AABB) -> AABB {

  let zlength = (grid_aabb.max(2) - grid_aabb.min(2)) / (world_size as f64);
  let mut zmin = grid_aabb.min(2) + zlength * (rank as f64);
  let mut zmax = grid_aabb.min(2) + zlength * ((rank + 1) as f64);

  if(rank > 0) {
    zmin -= (get_comm_time_steps() as f64) * cell_spacing;
  }

  if(rank < world_size - 1) {
    zmax += (get_comm_time_steps() as f64) * cell_spacing;
  }

  AABB {
    min: [grid_aabb.min(0), grid_aabb.min(1), zmin],
    max: [grid_aabb.max(0), grid_aabb.max(1), zmax],
  }
}

fn mpi_send_ghostzone(
  grid: &mut Grid,
  accelerator_grid: &mut AcceleratorGrid,
  world_size: i32,
  world_rank: i32) -> () {

  let mpih = mpi();

  for dest_rank, begin, end in
      mpi_send_subdomains(world_size, world_rank, *grid) {
    for cell, index in
        map_over_grid_subdomain(grid, begin, end, range, range, range) {
      let flat_index = flatten_index(index, grid);
      let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
      let offset = cell_offsets(flat_index);
      let nparticles = cell.size + cell.padding;

      mpih.send(
        &accelerator_grid.positions_cpu.x.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);
      mpih.send(
        &accelerator_grid.positions_cpu.y.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);
      mpih.send(
        &accelerator_grid.positions_cpu.z.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);

      mpih.send(
        &accelerator_grid.velocities_cpu.x.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);
      mpih.send(
        &accelerator_grid.velocities_cpu.y.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);
      mpih.send(
        &accelerator_grid.velocities_cpu.z.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);

      mpih.send(
        &accelerator_grid.forces_cpu.x.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);
      mpih.send(
        &accelerator_grid.forces_cpu.y.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);
      mpih.send(
        &accelerator_grid.forces_cpu.z.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, dest_rank, 0, mpih.comms.world);
    }
  }
}

fn mpi_recv_ghostzone(
  grid: &mut Grid,
  accelerator_grid: &mut AcceleratorGrid,
  world_size: i32,
  world_rank: i32) -> () {

  let mpih = mpi();
  let mut status : MPIStatus;

  for source_rank, begin, end in
      mpi_receive_subdomains(world_size, world_rank, *grid) {
    for cell, index in
        map_over_grid_subdomain(grid, begin, end, range, range, range) {
      let flat_index = flatten_index(index, grid);
      let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
      let offset = cell_offsets(flat_index);
      let nparticles = cell.size + cell.padding;

      mpih.recv(
        &accelerator_grid.positions_cpu.x.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);
      mpih.recv(
        &accelerator_grid.positions_cpu.y.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);
      mpih.recv(
        &accelerator_grid.positions_cpu.z.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);

      mpih.recv(
        &accelerator_grid.velocities_cpu.x.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);
      mpih.recv(
        &accelerator_grid.velocities_cpu.y.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);
      mpih.recv(
        &accelerator_grid.velocities_cpu.z.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);

      mpih.recv(
        &accelerator_grid.forces_cpu.x.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);
      mpih.recv(
        &accelerator_grid.forces_cpu.y.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);
      mpih.recv(
        &accelerator_grid.forces_cpu.z.data(offset) as MPI_MutBuf,
        nparticles, mpih.double_t, source_rank, 0, mpih.comms.world, &mut status);
    }
  }
}

fn mpi_synchronize_ghost_zone(
  grid: &mut Grid,
  accelerator_grid: &mut AcceleratorGrid,
  world_size: i32,
  world_rank: i32) -> () {

  let total_number_of_particles =
    accelerator_grid.total_number_of_clusters *
    accelerator_grid.cluster_size;

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.positions_accelerator,
    accelerator_grid.positions_cpu,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.velocities_accelerator,
    accelerator_grid.velocities_cpu,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.forces_accelerator,
    accelerator_grid.forces_cpu,
    total_number_of_particles);

  if(world_rank % 2 == 0) {
    mpi_send_ghostzone(grid, accelerator_grid, world_size, world_rank);
    mpi_recv_ghostzone(grid, accelerator_grid, world_size, world_rank);
  } else {
    mpi_recv_ghostzone(grid, accelerator_grid, world_size, world_rank);
    mpi_send_ghostzone(grid, accelerator_grid, world_size, world_rank);
  }

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.positions_cpu,
    accelerator_grid.positions_accelerator,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.velocities_cpu,
    accelerator_grid.velocities_accelerator,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.forces_cpu,
    accelerator_grid.forces_accelerator,
    total_number_of_particles);
}
