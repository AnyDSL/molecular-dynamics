// Communication offsets (for gather and scatter kernels)
struct CommOffsets {
    // Host send data
    send_buffer: Buffer,
    send_rank_offsets: Buffer,
    send_rank_lengths: Buffer,
    send_offsets: Buffer,
    send_capacity: i32,
    send_noffsets: i32,

    // Host receive data
    recv_buffer: Buffer,
    recv_rank_offsets: Buffer,
    recv_rank_lengths: Buffer,
    recv_offsets: Buffer,
    recv_capacity: i32,
    recv_noffsets: i32,

    // Exchange data
    send_exchg_buffer: Buffer,
    recv_exchg_buffer: Buffer,
    send_rank_exchgs: Buffer,
    recv_rank_exchgs: Buffer,
    exchg_rank_offsets: Buffer,
    exchg_rank_status: Buffer,

    // Accelerator send data
    send_buffer_accelerator: Buffer,
    send_offsets_accelerator: Buffer,

    // Accelerator receive data
    recv_buffer_accelerator: Buffer,
    recv_offsets_accelerator: Buffer,

    // Number of neighbor ranks
    neighs: i32
};

// Number of nodes in each dimension
static mut gx: i32;
static mut gy: i32;
static mut gz: i32;

// Lookup table for ghost layer ranges
static mut grid_transfer_ranges: [[i32 * 4] * 9];

// Timesteps to perform cell synchronization (ghost layer width)
fn @get_sync_timesteps() -> i32 { 1 }

// Must synchronize diagonals (true/false)
fn @synchronize_diagonals() -> bool { false }

// Flatten index for ranks (3D cartesian mapping)
fn @flat_index(index: [i32 * 3], nx: i32, ny: i32) -> i32 { (index(2) * ny + index(1)) * nx + index(0) }

// Unflatten index for ranks (3D cartesian mapping)
fn @unflat_index(index: i32, nx: i32, ny: i32, nz: i32, rx: &mut i32, ry: &mut i32, rz: &mut i32) -> () {
    *rx = index % nx;
    *ry = (index / nx) % ny;
    *rz = index / (nx * ny);
}

// MPI barrier
fn barrier() -> () {
    let mpih = mpi();
    let mut request: MPI_Request;

    mpih.barrier(mpih.comms.world, &mut request);
}

// Print string with rank
fn print_string_with_rank(string: &[u8]) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(string);
    print_string("\n");
    print_flush();
}

// Print i32 value with rank
fn print_i32_with_rank(field: &[u8], value: i32) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(field);
    print_string(": ");
    print_i32(value);
    print_string("\n");
    print_flush();
}

// Print real value with rank
fn print_real_with_rank(field: &[u8], value: real_t) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(field);
    print_string(": ");
    print_f64(value);
    print_string("\n");
    print_flush();
}

// Print real buffer with rank
fn print_real_buffer_with_rank(field: &[u8], buffer: Buffer, offset: i32, length: i32) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(field);
    print_string(": ");

    range(0, length, |i| {
        print_f64(get_real(i + offset, buffer));
        print_string(", ");
    });

    print_string("\n");
}

// Print i32 buffer with rank
fn print_i32_buffer_with_rank(field: &[u8], buffer: Buffer, offset: i32, length: i32) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(field);
    print_string(": ");

    range(0, length, |i| {
        print_i32(get_i32(i + offset, buffer));
        print_string(", ");
    });

    print_string("\n");
}

// Print [i32 * 3] value with rank
fn print_i32_vector_with_rank(field: &[u8], value: [i32 * 3]) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(field);
    print_string(": ");
    print_i32(value(0));
    print_string(", ");
    print_i32(value(1));
    print_string(", ");
    print_i32(value(2));
    print_string("\n");
    print_flush();
}

// Print Vector3D value with rank
fn print_real_vector_with_rank(field: &[u8], value: Vector3D) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(field);
    print_string(": ");
    print_f64(value.x);
    print_string(", ");
    print_f64(value.y);
    print_string(", ");
    print_f64(value.z);
    print_string("\n");
    print_flush();
}

// Print AABB with rank
fn print_aabb_with_rank(field: &[u8], value: AABB) -> () {
    let mpih = mpi();
    let mut rank: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);

    print_i32(rank);
    print_string("> ");
    print_string(field);
    print_string(": xrange = <");
    print_f64(value.xmin);
    print_string(", ");
    print_f64(value.xmax);
    print_string("> yrange = <");
    print_f64(value.ymin);
    print_string(", ");
    print_f64(value.ymax);
    print_string("> zrange = <");
    print_f64(value.zmin);
    print_string(", ");
    print_f64(value.zmax);
    print_string(">\n");
    print_flush();
}

// Mirrored communication (avoid deadlocks)
fn @mirror_comm(
    xoffset: i32,
    yoffset: i32,
    zoffset: i32,
    body: fn(i32, i32, i32) -> ()) -> () {

    @@body(xoffset, yoffset, zoffset);
    @@body(-xoffset, -yoffset, -zoffset);
}

// Initialize MPI and defined data structures for communication
fn mpi_initialize(world_size: &mut i32, world_rank: &mut i32) -> () {
    let mpih = mpi();

    mpih.init();
    mpih.comm_size(mpih.comms.world, world_size);
    mpih.comm_rank(mpih.comms.world, world_rank);
}

// Finalize MPI and free data structures for communication
fn mpi_finalize() -> () {
    let mpih = mpi();

    release_comm_offsets(comm_offsets_);
    mpih.finalize();
}

// Allocate communication buffers
fn alloc_comm_offsets(comm_offsets: &mut CommOffsets, world_size: i32, neighs: i32, send_capacity: i32, recv_capacity: i32) -> () {
    let null_buf = Buffer {
        device: 0,
        data: 0 as &[i8],
        size: 0 as i64
    };

    if world_size > 1 && neighs > 0 && send_capacity > 0 && recv_capacity > 0 {
        *comm_offsets = CommOffsets {
            // Host send data
            send_buffer: cpu_allocate(neighs * send_capacity * 7 * sizeof[real_t]()),
            send_rank_offsets: alloc_cpu(world_size * sizeof[i32]()),
            send_rank_lengths: alloc_cpu(world_size * sizeof[i32]()),
            send_offsets: cpu_allocate(neighs * send_capacity * sizeof[i32]()),
            send_capacity: send_capacity,
            send_noffsets: 0,

            // Host receive data
            recv_buffer: cpu_allocate(neighs * recv_capacity * 7 * sizeof[real_t]()),
            recv_rank_offsets: alloc_unaligned_cpu(world_size * sizeof[i32]()),
            recv_rank_lengths: alloc_unaligned_cpu(world_size * sizeof[i32]()),
            recv_offsets: cpu_allocate(neighs * recv_capacity * sizeof[i32]()),
            recv_capacity: recv_capacity,
            recv_noffsets: 0,

            send_exchg_buffer: alloc_unaligned_cpu(neighs * send_capacity * 7 * sizeof[real_t]()),
            recv_exchg_buffer: alloc_unaligned_cpu(neighs * recv_capacity * 7 * sizeof[real_t]()),
            send_rank_exchgs: alloc_unaligned_cpu(world_size * sizeof[i32]()),
            recv_rank_exchgs: alloc_unaligned_cpu(world_size * sizeof[i32]()),
            exchg_rank_offsets: alloc_unaligned_cpu(world_size * sizeof[i32]()),
            exchg_rank_status: alloc_unaligned_cpu(world_size * sizeof[i32]()),

            // Accelerator send data
            send_buffer_accelerator: accelerator_allocate(neighs * send_capacity * 3 * sizeof[real_t]()),
            send_offsets_accelerator: accelerator_allocate(neighs * send_capacity * sizeof[i32]()),

            // Accelerator receive data
            recv_buffer_accelerator: accelerator_allocate(neighs * recv_capacity * 3 * sizeof[real_t]()),
            recv_offsets_accelerator: accelerator_allocate(neighs * recv_capacity * sizeof[i32]()),

            // Number of neighbor ranks
            neighs: neighs
        };

        assign_accelerator_buffer(&mut comm_offsets.send_buffer, comm_offsets.send_buffer_accelerator);
        assign_accelerator_buffer(&mut comm_offsets.recv_buffer, comm_offsets.recv_buffer_accelerator);
        assign_accelerator_buffer(&mut comm_offsets.send_offsets, comm_offsets.send_offsets_accelerator);
        assign_accelerator_buffer(&mut comm_offsets.recv_offsets, comm_offsets.recv_offsets_accelerator);
    }
}

// Release communication buffers
fn release_comm_offsets(comm_offsets: CommOffsets) -> () {
    if comm_offsets.send_capacity > 0 {
        release(comm_offsets.send_buffer);
        release(comm_offsets.send_rank_offsets);
        release(comm_offsets.send_rank_lengths);
        release(comm_offsets.send_offsets);
        release(comm_offsets.send_buffer_accelerator);
        release(comm_offsets.send_offsets_accelerator);
        release(comm_offsets.send_exchg_buffer);
        release(comm_offsets.send_rank_exchgs);
    }

    if comm_offsets.recv_capacity > 0 {
        release(comm_offsets.recv_buffer);
        release(comm_offsets.recv_rank_offsets);
        release(comm_offsets.recv_rank_lengths);
        release(comm_offsets.recv_offsets);
        release(comm_offsets.recv_buffer_accelerator);
        release(comm_offsets.recv_offsets_accelerator);
        release(comm_offsets.recv_exchg_buffer);
        release(comm_offsets.recv_rank_exchgs);
    }

    release(comm_offsets.exchg_rank_offsets);
    release(comm_offsets.exchg_rank_status);
}

fn resize_comm_offsets(comm_offsets: &mut CommOffsets, world_size: i32, send_capacity: i32, recv_capacity: i32) -> () {
    if send_capacity > comm_offsets.send_capacity || recv_capacity > comm_offsets.recv_capacity {
        let neighs = comm_offsets.neighs;
        let new_send_capacity = math.max(send_capacity, comm_offsets.send_capacity);
        let new_recv_capacity = math.max(recv_capacity, comm_offsets.recv_capacity);

        release_comm_offsets(*comm_offsets);
        alloc_comm_offsets(comm_offsets, world_size, neighs, new_send_capacity, new_recv_capacity);
    }
}

// Get current node bounding box for 1D domain partitioning
fn @get_node_bounding_box_1d(
    world_size: i32,
    rank: i32,
    cell_spacing: real_t,
    grid_aabb: AABB) -> AABB {

    let mut zmin: real_t;
    let mut zmax: real_t;

    if world_size > 1 {
        // Number of cells in z axis
        let zcells = real_floor((grid_aabb.zmax - grid_aabb.zmin) / cell_spacing) as i32;

        // Total length for cells in z axis
        let zlength = (zcells / world_size) as real_t * cell_spacing;

        // Calculate zmin and zmax based on rank value
        zmin = grid_aabb.zmin + zlength * (rank as real_t);
        zmax = grid_aabb.zmin + zlength * ((rank + 1) as real_t);

        // If this is not the first node, include ghost layer for lower z ranks
        if rank > 0 {
            zmin -= (get_sync_timesteps() as real_t) * cell_spacing;
        }

        // If this is not the last node, include ghost layer for upper z ranks
        if rank < world_size - 1 {
            zmax += (get_sync_timesteps() as real_t) * cell_spacing;
        // Otherwise, just increase cell spacing to maximum delimiter to
        // reach any possible missing cells in the original bounding box
        } else {
            zmax += cell_spacing;
        }
    // Otherwise, just use original bounding box
    } else {
        zmin = grid_aabb.zmin;
        zmax = grid_aabb.zmax;
    }

    AABB {
        xmin: grid_aabb.xmin,
        xmax: grid_aabb.xmax,
        ymin: grid_aabb.ymin,
        ymax: grid_aabb.ymax,
        zmin: grid_aabb.zmin,
        zmax: grid_aabb.zmax
    }
}

// Get send and receive transfer ranges for communications
fn transfer_ranges(offset: i32, ncells: i32, body: fn(i32, i32, i32, i32) -> ()) -> () {
    let mut send_begin: i32;
    let mut send_end: i32;
    let mut recv_begin: i32;
    let mut recv_end: i32;

    // If offset is zero (same position), communication must comprise all
    // cells in this axis (adjacent nodes)
    if offset == 0 {
        send_begin = 0;
        send_end = ncells;
        recv_begin = 0;
        recv_end = ncells;
    // If offset is less than zero (lower position), communication must
    // comprise only last cells in this axis
    } else if offset < 0 {
        send_begin = ncells - get_sync_timesteps() * 2;
        send_end = ncells - get_sync_timesteps();
        recv_begin = ncells - get_sync_timesteps();
        recv_end = ncells;
    // If offset is greater than zero (lower position), communication must
    // comprise only first cells in this axis
    } else {
        send_begin = get_sync_timesteps();
        send_end = get_sync_timesteps() * 2;
        recv_begin = 0;
        recv_end = get_sync_timesteps();
    }

    @@body(send_begin, send_end, recv_begin, recv_end)
}

// Build lookup table for transferring ranges in all dimensions
fn initialize_grid_transfer_ranges(grid: &Grid) -> () {
    // Go through all offsets (-1, 0, +1)
    for i in range(-1, 2) {
        transfer_ranges(i, grid.nx, |send_begin, send_end, recv_begin, recv_end| {
            grid_transfer_ranges(i + 1)(0) = send_begin;
            grid_transfer_ranges(i + 1)(1) = send_end;
            grid_transfer_ranges(i + 1)(2) = recv_begin;
            grid_transfer_ranges(i + 1)(3) = recv_end;
        });

        transfer_ranges(i, grid.ny, |send_begin, send_end, recv_begin, recv_end| {
            grid_transfer_ranges(i + 4)(0) = send_begin;
            grid_transfer_ranges(i + 4)(1) = send_end;
            grid_transfer_ranges(i + 4)(2) = recv_begin;
            grid_transfer_ranges(i + 4)(3) = recv_end;
        });

        transfer_ranges(i, grid.nz, |send_begin, send_end, recv_begin, recv_end| {
            grid_transfer_ranges(i + 7)(0) = send_begin;
            grid_transfer_ranges(i + 7)(1) = send_end;
            grid_transfer_ranges(i + 7)(2) = recv_begin;
            grid_transfer_ranges(i + 7)(3) = recv_end;
        });
    }
}

// Generic communication pattern (including diagonals)
fn communication_nodes_generic(
    world_size: i32,
    rank: i32,
    grid: &Grid,
    body: fn(i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32) -> ()) -> () {

    let mut rx: i32;
    let mut ry: i32;
    let mut rz: i32;

    // Index of rank in the 3D cartesian grid
    unflat_index(rank, gx, gy, gz, &mut rx, &mut ry, &mut rz);

    // Has previous node in x axis?
    let xprev = rx > 0;
    // Has successor node in x axis?
    let xnext = rx < gx - 1;
    // Has previous node in y axis?
    let yprev = ry > 0;
    // Has successor node in y axis?
    let ynext = ry < gy - 1;
    // Has previous node in z axis?
    let zprev = rz > 0;
    // Has successor node in z axis?
    let znext = rz < gz - 1;

    // Go through possible offsets
    for xoffset in range(-1, 1) {
        for yoffset in range(-1, 1 - xoffset) {
            for zoffset in range(-1, 2) {
                // Number of zero offsets (diagonals include zero or one)
                let nzeros = (xoffset == 0) as i32 +
                             (yoffset == 0) as i32 +
                             (zoffset == 0) as i32;

                //if(nzeros == 2 || (synchronize_diagonals() && nzeros < 3)) {

                // If number of zeros is two, not a diagonal (adjacent node)
                if nzeros == 2 {
                    // Perform for original and mirrored offsets to avoid deadlocks
                    for xoff, yoff, zoff in mirror_comm(xoffset, yoffset, zoffset) {
                      // Check if node for communication is valid
                      if(
                          ((xoff < 0 && xprev) || (xoff > 0 && xnext) || (xoff == 0)) &&
                          ((yoff < 0 && yprev) || (yoff > 0 && ynext) || (yoff == 0)) &&
                          ((zoff < 0 && zprev) || (zoff > 0 && znext) || (zoff == 0))
                      ) {
                        // Exchange rank based on offsets
                        let exchange_rank = flat_index(
                            [rx + xoff, ry + yoff, rz + zoff], gx, gy
                        );

                        // Get x, y and z ranges on lookup table
                        let xranges = grid_transfer_ranges(xoff + 1);
                        let yranges = grid_transfer_ranges(yoff + 4);
                        let zranges = grid_transfer_ranges(zoff + 7);

                        // Build ranges based on vectors obtained from the lookup table
                        let send_begin = [xranges(0), yranges(0), zranges(0)];
                        let send_end   = [xranges(1), yranges(1), zranges(1)];
                        let recv_begin = [xranges(2), yranges(2), zranges(2)];
                        let recv_end   = [xranges(3), yranges(3), zranges(3)];

                        // Performs communication with rank using the obtained ranges
                        @@body( exchange_rank,
                                xranges(0), yranges(0), zranges(0),
                                xranges(1), yranges(1), zranges(1),
                                xranges(2), yranges(2), zranges(2),
                                xranges(3), yranges(3), zranges(3)  );
                      }
                  }
              }
          }
      }
    }
}

// Is this a local cell?
fn is_local_cell(cx: i32, cy: i32, cz: i32, grid: &Grid) -> bool {
    let mpih = mpi();
    let mut rank: i32;
    let mut rx: i32;
    let mut ry: i32;
    let mut rz: i32;

    let mut local_cond = true;

    mpih.comm_rank(mpih.comms.world, &mut rank);
    unflat_index(rank, gx, gy, gz, &mut rx, &mut ry, &mut rz);

    local_cond =               (rx == 0      || cx > get_sync_timesteps() - 1);
    local_cond = local_cond && (rx == gx - 1 || cx < grid.nx - get_sync_timesteps());
    local_cond = local_cond && (ry == 0      || cy > get_sync_timesteps() - 1);
    local_cond = local_cond && (ry == gy - 1 || cy < grid.ny - get_sync_timesteps());
    local_cond = local_cond && (rz == 0      || cz > get_sync_timesteps() - 1);
    local_cond = local_cond && (rz == gz - 1 || cz < grid.nz - get_sync_timesteps());

    local_cond
}

// Adjust cell index to closest local one
fn closest_local_cell(cx: i32, cy: i32, cz: i32, grid: &Grid) -> [i32 * 3] {
    let mpih = mpi();
    let mut rank: i32;
    let mut rx: i32;
    let mut ry: i32;
    let mut rz: i32;
    let mut resx = cx;
    let mut resy = cy;
    let mut resz = cz;

    mpih.comm_rank(mpih.comms.world, &mut rank);
    unflat_index(rank, gx, gy, gz, &mut rx, &mut ry, &mut rz);

    resx = select(rx > 0      && resx < get_sync_timesteps(),            get_sync_timesteps(), resx);
    resx = select(rx < gx - 1 && resx >= grid.nx - get_sync_timesteps(), grid.nx - get_sync_timesteps() - 1, resx);
    resy = select(ry > 0      && resy < get_sync_timesteps(),            get_sync_timesteps(), resy);
    resy = select(ry < gy - 1 && resy >= grid.ny - get_sync_timesteps(), grid.ny - get_sync_timesteps() - 1, resy);
    resz = select(rz > 0      && resz < get_sync_timesteps(),            get_sync_timesteps(), resz);
    resz = select(rz < gz - 1 && resz >= grid.nz - get_sync_timesteps(), grid.nz - get_sync_timesteps() - 1, resz);

    [resx, resy, resz]
}

// Check if cells are inside the same ghost layer (rank region)
fn inside_same_ghost_layer(c1x: i32, c1y: i32, c1z: i32, c2x: i32, c2y: i32, c2z: i32, grid: &Grid) -> bool {
    let mut equal_cond = false;

    equal_cond =               (c1x < get_sync_timesteps()            && c2x < get_sync_timesteps());
    equal_cond = equal_cond || (c1x >= grid.nx - get_sync_timesteps() && c2x >= grid.nx - get_sync_timesteps());
    equal_cond = equal_cond || (c1y < get_sync_timesteps()            && c2y < get_sync_timesteps());
    equal_cond = equal_cond || (c1y >= grid.ny - get_sync_timesteps() && c2y >= grid.ny - get_sync_timesteps());
    equal_cond = equal_cond || (c1z < get_sync_timesteps()            && c2z < get_sync_timesteps());
    equal_cond = equal_cond || (c1z >= grid.nz - get_sync_timesteps() && c2z >= grid.nz - get_sync_timesteps());

    equal_cond
}

// Is this the last node in the dimension?
fn last_dimension_node(@dim: i32) -> bool {
    let mpih = mpi();
    let mut rank: i32;
    let mut rx: i32;
    let mut ry: i32;
    let mut rz: i32;

    mpih.comm_rank(mpih.comms.world, &mut rank);
    unflat_index(rank, gx, gy, gz, &mut rx, &mut ry, &mut rz);

    if dim == 0 {
        rx == gx - 1
    } else if dim == 1 {
        ry == gy - 1
    } else if dim == 2 {
        rz == gz - 1
    } else {
        false
    }
}

// Not perfect but works for our cases
fn int_mod(value: i32, divisor: i32) -> i32 {
    if value < 0 {
        value + divisor
    } else if value >= divisor {
        value - divisor
    } else {
        value
    }
}

fn xnext_adjust_pbc(pos: &mut Vector3D, grid: &Grid) { pos.x -= grid.xlength; }
fn xprev_adjust_pbc(pos: &mut Vector3D, grid: &Grid) { pos.x += grid.xlength; }
fn ynext_adjust_pbc(pos: &mut Vector3D, grid: &Grid) { pos.y -= grid.ylength; }
fn yprev_adjust_pbc(pos: &mut Vector3D, grid: &Grid) { pos.y += grid.ylength; }
fn znext_adjust_pbc(pos: &mut Vector3D, grid: &Grid) { pos.z -= grid.zlength; }
fn zprev_adjust_pbc(pos: &mut Vector3D, grid: &Grid) { pos.z += grid.zlength; }

fn xnext_send_condition(pos: Vector3D, grid: &Grid) -> bool { pos.x > grid.aabb.xmax - grid.spacing * 2.0 }
fn xprev_send_condition(pos: Vector3D, grid: &Grid) -> bool { pos.x < grid.aabb.xmin + grid.spacing * 2.0 }
fn ynext_send_condition(pos: Vector3D, grid: &Grid) -> bool { pos.y > grid.aabb.ymax - grid.spacing * 2.0 }
fn yprev_send_condition(pos: Vector3D, grid: &Grid) -> bool { pos.y < grid.aabb.ymin + grid.spacing * 2.0 }
fn znext_send_condition(pos: Vector3D, grid: &Grid) -> bool { pos.z > grid.aabb.zmax - grid.spacing * 2.0 }
fn zprev_send_condition(pos: Vector3D, grid: &Grid) -> bool { pos.z < grid.aabb.zmin + grid.spacing * 2.0 }

type PBCFunc = fn(&mut Vector3D, &Grid) -> ();
type CondFunc = fn(Vector3D, &Grid) -> bool;
type CommFunc = fn(i32, bool, PBCFunc, CondFunc) -> ();

// Mirror communication to avoid deadlocks
fn mirror(
    body: CommFunc, condition: bool,
    next_rank: i32, next_pbc_cond: bool, next_pbc_func: PBCFunc, next_send_cond: CondFunc,
    prev_rank: i32, prev_pbc_cond: bool, prev_pbc_func: PBCFunc, prev_send_cond: CondFunc) -> () {

    if condition {
        @@body(next_rank, next_pbc_cond, next_pbc_func, next_send_cond);
        @@body(prev_rank, prev_pbc_cond, prev_pbc_func, prev_send_cond);
    } else {
        @@body(prev_rank, prev_pbc_cond, prev_pbc_func, prev_send_cond);
        @@body(next_rank, next_pbc_cond, next_pbc_func, next_send_cond);
    }
}

// Communication pattern using 6-stencil neighbors
fn communication_nodes(world_size: i32, rank: i32, grid: &Grid, body: CommFunc) -> () {
    let mut rx: i32;
    let mut ry: i32;
    let mut rz: i32;

    // Index of rank in the 3D cartesian grid
    unflat_index(rank, gx, gy, gz, &mut rx, &mut ry, &mut rz);

    if gx > 1 {
        @@mirror( body, rx % 2 == 0,
                  flat_index([int_mod(rx + 1, gx), ry, rz], gx, gy), rx == gx - 1, xnext_adjust_pbc, xnext_send_condition,
                  flat_index([int_mod(rx - 1, gx), ry, rz], gx, gy), rx == 0,      xprev_adjust_pbc, xprev_send_condition );
    }

    if gy > 1 {
        @@mirror( body, ry % 2 == 0,
                  flat_index([rx, int_mod(ry + 1, gy), rz], gx, gy), ry == gy - 1, ynext_adjust_pbc, ynext_send_condition,
                  flat_index([rx, int_mod(ry - 1, gy), rz], gx, gy), ry == 0,      yprev_adjust_pbc, yprev_send_condition );
    }

    if gz > 1 {
        @@mirror( body, rz % 2 == 0,
                  flat_index([rx, ry, int_mod(rz + 1, gz)], gx, gy), rz == gz - 1, znext_adjust_pbc, znext_send_condition,
                  flat_index([rx, ry, int_mod(rz - 1, gz)], gx, gy), rz == 0,      zprev_adjust_pbc, zprev_send_condition );
    }
}

// Get configuration for nodes according to world size and number of
// cells in each dimension
fn get_node_config(
    world_size: i32,
    rank: i32,
    xlength: real_t,
    ylength: real_t,
    zlength: real_t,
    destx: &mut i32,
    desty: &mut i32,
    destz: &mut i32) -> () {

    // We want to find the configuration with the minimum missing factor,
    // i.e. the configuration that requires less extension of the edge
    // nodes (extension is required when number of cells is not multiple
    // of the number of nodes in a dimension)
    //let mut min_missing_factor = xcells * ycells * zcells;

    *destx = 1;
    *desty = 1;
    *destz = 1;

    // Go through all possibilities of node configurations, update only
    // when missing factor is lower than the current one

    /*
    for i in range(1, world_size) {
        if world_size % i == 0 {
            let rem_yz = world_size / i;

            for j in range(1, rem_yz) {
                if rem_yz % j == 0 {
                    let k = rem_yz / j;
                    let missing_factor = xcells % i + ycells % j + zcells % k;

                    if min_missing_factor > missing_factor {
                        *destx = i;
                        *desty = j;
                        *destz = k;
                        min_missing_factor = missing_factor;
                    }
                }
            }
        }
    }
    */

    let areax = xlength * ylength;
    let areay = xlength * zlength;
    let areaz = ylength * zlength;

    let mut bestsurf = 2.0 * (areax + areay + areaz) as f64;

    for i in range(1, world_size) {
        if world_size % i == 0 {
            let rem_yz = world_size / i;

            for j in range(1, rem_yz) {
                if rem_yz % j == 0 {
                    let k = rem_yz / j;
                    let surf = areax / i as f64 / j as f64 + areay / i as f64 / k as f64 + areaz / j as f64 / k as f64;

                    if surf < bestsurf {
                        *destx = i;
                        *desty = j;
                        *destz = k;
                        bestsurf = surf;
                    }
                }
            }
        }
    }
}

// Get bounding box for current node
fn @get_node_bounding_box(
    world_size: i32,
    rank: i32,
    cell_spacing: real_t,
    aabb: AABB) -> AABB {

    let mut xmin: real_t;
    let mut xmax: real_t;
    let mut ymin: real_t;
    let mut ymax: real_t;
    let mut zmin: real_t;
    let mut zmax: real_t;

    if world_size > 1 {
        let mut rx: i32;
        let mut ry: i32;
        let mut rz: i32;

        // Number of cells in each dimension
        let xtotallength = aabb.xmax - aabb.xmin;
        let ytotallength = aabb.ymax - aabb.ymin;
        let ztotallength = aabb.zmax - aabb.zmin;

        // Get configuration of nodes
        get_node_config(world_size, rank, xtotallength, ytotallength, ztotallength, &mut gx, &mut gy, &mut gz);

        // Dimensions length for each rank
        let xlength = xtotallength / (gx as real_t);
        let ylength = ytotallength / (gy as real_t);
        let zlength = ztotallength / (gz as real_t);

        // 3D cartesian position of current rank
        unflat_index(rank, gx, gy, gz, &mut rx, &mut ry, &mut rz);

        // Calculate boundaries using lengths in each dimension
        xmin = aabb.xmin + xlength * (rx as real_t);
        xmax = xmin + xlength;
        ymin = aabb.ymin + ylength * (ry as real_t);
        ymax = ymin + ylength;
        zmin = aabb.zmin + zlength * (rz as real_t);
        zmax = zmin + zlength;
    } else {
        gx = 1;
        gy = 1;
        gz = 1;

        xmin = aabb.xmin;
        xmax = aabb.xmax;
        ymin = aabb.ymin;
        ymax = aabb.ymax;
        zmin = aabb.zmin;
        zmax = aabb.zmax;
    }

    AABB {
        xmin: xmin,
        xmax: xmax,
        ymin: ymin,
        ymax: ymax,
        zmin: zmin,
        zmax: zmax
    }
}

// Extend domain to include cells for ghost particles
fn extend_rank_domain(aabb: &mut AABB, cell_spacing: real_t) -> () {
    if gx > 1 {
        aabb.xmin -= cell_spacing;
        aabb.xmax += cell_spacing;
    }

    if gy > 1 {
        aabb.ymin -= cell_spacing;
        aabb.ymax += cell_spacing;
    }

    if gz > 1 {
        aabb.zmin -= cell_spacing;
        aabb.zmax += cell_spacing;
    }
}

// Check if position is inside local domain (exclude ghost layer)
fn is_within_local_domain(position: Vector3D, grid: &Grid) -> bool {
    let mut aabb = AABB {
        xmin: grid.aabb.xmin,
        xmax: grid.aabb.xmax,
        ymin: grid.aabb.ymin,
        ymax: grid.aabb.ymax,
        zmin: grid.aabb.zmin,
        zmax: grid.aabb.zmax
    };

    if gx > 1 {
        aabb.xmin += grid.spacing;
        aabb.xmax -= grid.spacing;
    }

    if gy > 1 {
        aabb.ymin += grid.spacing;
        aabb.ymax -= grid.spacing;
    }

    if gz > 1 {
        aabb.zmin += grid.spacing;
        aabb.zmax -= grid.spacing;
    }

    is_within_domain(position, aabb)
}

// Initialize grid communication
fn initialize_comm(
    grid: &Grid,
    comm_offsets: &mut CommOffsets,
    world_size: i32,
    world_rank: i32) -> () {

    let max_faces_dim = math.max(math.max(grid.nx * grid.ny, grid.nx * grid.nz), grid.ny * grid.nz);
    let mut neighs = 0;

    communication_nodes(world_size, world_rank, grid, |_, _, _, _| { neighs++; });
    alloc_comm_offsets(comm_offsets, world_size, neighs, max_faces_dim * 100, max_faces_dim * 100);
}

// Synchronize ghost layer cells with neighbor ranks
fn synchronize_ghost_layer_cells(
    grid: Grid,
    comm_offsets: CommOffsets,
    world_size: i32,
    world_rank: i32) -> () {

    let mpih = mpi();
    let mut request: MPI_Request;
    let mut status: MPIStatus;

    let send_rank_offsets = get_array_of_i32(comm_offsets.send_rank_offsets);
    let recv_rank_offsets = get_array_of_i32(comm_offsets.recv_rank_offsets);
    let send_rank_lengths = get_array_of_i32(comm_offsets.send_rank_lengths);
    let recv_rank_lengths = get_array_of_i32(comm_offsets.recv_rank_lengths);

    gather_data(grid, comm_offsets);

    communication_nodes(world_size, world_rank, grid, |exchange_rank, pbc, _, _| {
        if !pbc {
            let send_offset = send_rank_offsets(exchange_rank) * 3 * sizeof[real_t]();
            let recv_offset = recv_rank_offsets(exchange_rank) * 3 * sizeof[real_t]();

            mpih.irecv(
                bitcast[&mut[real_t]](&comm_offsets.recv_buffer.data(recv_offset)) as MPI_MutBuf,
                recv_rank_lengths(exchange_rank) * 3,
                mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);

            mpih.send(
                bitcast[&mut[real_t]](&comm_offsets.send_buffer.data(send_offset)) as MPI_MutBuf,
                send_rank_lengths(exchange_rank) * 3,
                mpih.double_t, exchange_rank, 0, mpih.comms.world);

            mpih.wait(&mut request, &mut status);
        }
    });

    scatter_data(grid, comm_offsets);
}

fn copy_particle_data_to_buffer(mass: real_t, pos: Vector3D, vel: Vector3D, buffer: Buffer, index: i32) -> i32 {
    let mut buffer_index = index;

    bitcast[&mut[real_t]](buffer.data)(buffer_index++) = mass;
    bitcast[&mut[real_t]](buffer.data)(buffer_index++) = pos.x;
    bitcast[&mut[real_t]](buffer.data)(buffer_index++) = pos.y;
    bitcast[&mut[real_t]](buffer.data)(buffer_index++) = pos.z;
    bitcast[&mut[real_t]](buffer.data)(buffer_index++) = vel.x;
    bitcast[&mut[real_t]](buffer.data)(buffer_index++) = vel.y;
    bitcast[&mut[real_t]](buffer.data)(buffer_index++) = vel.z;

    buffer_index
}

fn copy_buffer_data_to_grid(buffer: Buffer, buffer_index: i32, grid: &Grid, offset: i32) -> i32 {
    let mut index = buffer_index;

    copy_offset(buffer, index * sizeof[real_t](), grid.masses_cpu, offset * sizeof[real_t](), sizeof[real_t]());
    index++;

    copy_buffer_to_3d_arrays(buffer, index * sizeof[real_t](), grid.positions_cpu, offset * sizeof[real_t](), sizeof[real_t]());
    index += 3;

    copy_buffer_to_3d_arrays(buffer, index * sizeof[real_t](), grid.velocities_cpu, offset * sizeof[real_t](), sizeof[real_t]());
    index + 3
}

// Exchange ghost layer particles with neighbor ranks (here the number of
// particles is also updated)
fn exchange_ghost_layer_particles(
    grid: &mut Grid,
    comm_offsets: &mut CommOffsets,
    world_size: i32,
    world_rank: i32) -> () {

    let mpih = mpi();
    let mut request: MPI_Request;
    let mut status: MPIStatus;

    let send_rank_offsets = get_array_of_i32(comm_offsets.send_rank_offsets);
    let recv_rank_offsets = get_array_of_i32(comm_offsets.recv_rank_offsets);
    let exchg_rank_offsets = get_array_of_i32(comm_offsets.exchg_rank_offsets);
    let exchg_rank_status = get_array_of_i32(comm_offsets.exchg_rank_status);
    let send_rank_lengths = get_array_of_i32(comm_offsets.send_rank_lengths);
    let recv_rank_lengths = get_array_of_i32(comm_offsets.recv_rank_lengths);
    let send_rank_exchgs =  get_array_of_i32(comm_offsets.send_rank_exchgs);
    let recv_rank_exchgs =  get_array_of_i32(comm_offsets.recv_rank_exchgs);
    let send_offsets = get_array_of_i32(comm_offsets.send_offsets);
    let recv_offsets = get_array_of_i32(comm_offsets.recv_offsets);
    let cell_sizes = get_array_of_i32(grid.cell_sizes_cpu);

    let mut isend = 0;
    let mut irecv = 0;
    let mut iexchg = 0;
    let mut buffer_index = 0;
    let mut exchg_index = 0;

    communication_nodes(world_size, world_rank, grid, |exchange_rank, _, _, _| {
        send_rank_offsets(exchange_rank) = -1;
        recv_rank_offsets(exchange_rank) = -1;
        exchg_rank_offsets(exchange_rank) = -1;
        exchg_rank_status(exchange_rank) = 0;
    });

    grid.nghost = 0;

    // Pack particles in each direction to exchange
    communication_nodes(world_size, world_rank, grid, |exchange_rank, pbc, pbc_adjust, check_send_condition| {
        if exchg_rank_offsets(exchange_rank) == -1 {
            exchg_rank_offsets(exchange_rank) = iexchg;
        }

        let mut particle_index = 0;

        while particle_index < grid.nparticles {
            let mut pos = get_vector_from_3d_arrays(particle_index, grid.positions_cpu);

            if check_send_condition(pos, grid) && !is_within_local_domain(pos, grid) {
                let mass = get_real(particle_index, grid.masses_cpu);
                let velocity = get_vector_from_3d_arrays(particle_index, grid.velocities_cpu);

                if pbc {
                    pbc_adjust(&mut pos, grid);
                }

                exchg_index = copy_particle_data_to_buffer(mass, pos, velocity, comm_offsets.send_exchg_buffer, exchg_index);
                delete_particle(particle_index, grid);
                particle_index--;
                iexchg++;
            }

            particle_index++;
        }

        send_rank_exchgs(exchange_rank) = iexchg - exchg_rank_offsets(exchange_rank);
    });

    // Pack particles in each direction to send at other iterations
    communication_nodes(world_size, world_rank, grid, |exchange_rank, pbc, _, check_send_condition| {
        if send_rank_offsets(exchange_rank) == -1 {
            send_rank_offsets(exchange_rank) = isend;
        }

        if !pbc {
            range(0, grid.nparticles, |particle_index| {
                let pos = get_vector_from_3d_arrays(particle_index, grid.positions_cpu);

                if check_send_condition(pos, grid) {
                    let mass = get_real(particle_index, grid.masses_cpu);
                    let velocity = get_vector_from_3d_arrays(particle_index, grid.velocities_cpu);
                    buffer_index = copy_particle_data_to_buffer(mass, pos, velocity, comm_offsets.send_buffer, buffer_index);
                    send_offsets(isend++) = particle_index;
                }
            });
        }

        send_rank_lengths(exchange_rank) = isend - send_rank_offsets(exchange_rank);
    });

    iexchg = 0;

    // Exchange particles with other ranks
    communication_nodes(world_size, world_rank, grid, |exchange_rank, _, _, _| {
        if exchg_rank_status(exchange_rank) == 0 {
            // Rank receive offset
            recv_rank_offsets(exchange_rank) = irecv;

            // Offsets to send and receive
            let send_offset = send_rank_offsets(exchange_rank) * 7 * sizeof[real_t]();
            let recv_offset = recv_rank_offsets(exchange_rank) * 7 * sizeof[real_t]();
            let exchg_send_offset = exchg_rank_offsets(exchange_rank) * 7 * sizeof[real_t]();
            let exchg_recv_offset = iexchg * 7 * sizeof[real_t]();

            // Send sizes
            mpih.send(&mut send_rank_lengths(exchange_rank) as MPI_MutBuf, 1, mpih.int_t, exchange_rank, 0, mpih.comms.world);
            mpih.recv(&mut recv_rank_lengths(exchange_rank) as MPI_MutBuf, 1, mpih.int_t, exchange_rank, 0, mpih.comms.world, &mut status);
            // Send data
            mpih.irecv(
                bitcast[&mut[real_t]](&comm_offsets.recv_buffer.data(recv_offset)) as MPI_MutBuf,
                recv_rank_lengths(exchange_rank) * 7,
                mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);

            mpih.send(
                bitcast[&mut[real_t]](&comm_offsets.send_buffer.data(send_offset)) as MPI_MutBuf,
                send_rank_lengths(exchange_rank) * 7,
                mpih.double_t, exchange_rank, 0, mpih.comms.world);

            mpih.wait(&mut request, &mut status);

            // Exchange sizes
            mpih.send(&mut send_rank_exchgs(exchange_rank) as MPI_MutBuf, 1, mpih.int_t, exchange_rank, 0, mpih.comms.world);
            mpih.recv(&mut recv_rank_exchgs(exchange_rank) as MPI_MutBuf, 1, mpih.int_t, exchange_rank, 0, mpih.comms.world, &mut status);

            mpih.irecv(
                bitcast[&mut[real_t]](&comm_offsets.recv_exchg_buffer.data(exchg_recv_offset)) as MPI_MutBuf,
                recv_rank_exchgs(exchange_rank) * 7,
                mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);

            // Exchange data
            mpih.send(
                bitcast[&mut[real_t]](&comm_offsets.send_exchg_buffer.data(exchg_send_offset)) as MPI_MutBuf,
                send_rank_exchgs(exchange_rank) * 7,
                mpih.double_t, exchange_rank, 0, mpih.comms.world);

            mpih.wait(&mut request, &mut status);

            // Adjust receive offset data
            range(irecv, irecv + recv_rank_lengths(exchange_rank), |i| { recv_offsets(i) = grid.nparticles + i; });
            irecv += recv_rank_lengths(exchange_rank);
            iexchg += recv_rank_exchgs(exchange_rank);
        }

        exchg_rank_status(exchange_rank) = 1;
    });

    // Unpack received particles
    let exchg_start = grid.nparticles;

    if iexchg > 0 { add_local_slots(iexchg, grid); }
    if irecv > 0 { add_ghost_slots(irecv, grid); }

    exchg_index = 0;
    buffer_index = 0;

    range(0, iexchg, |i| {
        exchg_index = copy_buffer_data_to_grid(comm_offsets.recv_exchg_buffer, exchg_index, grid, exchg_start + i);
    });

    range(0, irecv, |i| {
        recv_offsets(i) += iexchg;
        buffer_index = copy_buffer_data_to_grid(comm_offsets.recv_buffer, buffer_index, grid, recv_offsets(i));
    });

    comm_offsets.send_noffsets = isend;
    comm_offsets.recv_noffsets = irecv;
    transfer_between_devices(comm_offsets.send_offsets, comm_offsets.send_offsets_accelerator);
    transfer_between_devices(comm_offsets.recv_offsets, comm_offsets.recv_offsets_accelerator);
}

fn reduce_time(local_time: f64, global_time: &mut f64) -> () {
    let mpih = mpi();
    let mut local = local_time;

    mpih.allreduce(&mut local as MPI_MutBuf, global_time as MPI_MutBuf, 1, mpih.double_t, mpih.ops.max, mpih.comms.world);
}

fn reduce_i32_sum(local_value: i32, global_value: &mut i32) -> () {
    let mpih = mpi();
    let mut local = local_value;

    mpih.allreduce(&mut local as MPI_MutBuf, global_value as MPI_MutBuf, 1, mpih.int_t, mpih.ops.sum, mpih.comms.world);
}

fn reduce_i64_sum(local_value: i64, global_value: &mut i64) -> () {
    let mpih = mpi();
    let mut local = local_value;

    mpih.allreduce(&mut local as MPI_MutBuf, global_value as MPI_MutBuf, 1, mpih.int64_t, mpih.ops.sum, mpih.comms.world);
}
