static mut max_send_particles: i32;
static mut max_recv_particles: i32;
static mut mpi_send_buffer_size: i32;
static mut mpi_recv_buffer_size: i32;
static mut rank_send_particles: Buffer;
static mut rank_recv_particles: Buffer;
static mut mpi_send_buffer: Buffer;
static mut mpi_recv_buffer: Buffer;
static mut node_dims: [i32 * 3];

fn @get_comm_time_steps() -> i32 { 1 }

fn @flat_index(index: [i32 * 3], nx: i32, ny: i32) -> i32 {
  (index(2) * ny + index(1)) * nx + index(0)
}

fn @unflat_index(index: i32, nx: i32, ny: i32, nz: i32) -> [i32 * 3] {
  [index % nx, (index / nx) % ny, index / (nx * ny)]
}

fn mpi_initialize(world_size: &mut i32, world_rank: &mut i32) -> () {
  let mpih = mpi();

  mpih.init();

  mpi_send_buffer_size = 0;
  mpi_recv_buffer_size = 0;

  mpih.comm_size(mpih.comms.world, world_size);
  mpih.comm_rank(mpih.comms.world, world_rank);

  rank_send_particles = alloc_cpu(sizeof[i32]() * *world_size);
  rank_recv_particles = alloc_cpu(sizeof[i32]() * *world_size);
}

fn mpi_finalize() -> () {
  let mpih = mpi();

  if(mpi_send_buffer_size > 0) {
    release(mpi_send_buffer);
  }

  if(mpi_recv_buffer_size > 0) {
    release(mpi_recv_buffer);
  }

  release(rank_send_particles);
  release(rank_recv_particles);

  mpih.finalize();
}

fn resize_mpi_buffers(send_size: i32, recv_size: i32) -> () {
  if(send_size > mpi_send_buffer_size) {
    if(mpi_send_buffer_size > 0) {
      release(mpi_send_buffer);
    }

    mpi_send_buffer = alloc_cpu(sizeof[real_t]() * send_size);
    mpi_send_buffer_size = send_size;
  }

  if(recv_size > mpi_recv_buffer_size) {
    if(mpi_recv_buffer_size > 0) {
      release(mpi_recv_buffer);
    }

    mpi_recv_buffer = alloc_cpu(sizeof[real_t]() * recv_size);
    mpi_recv_buffer_size = recv_size;
  }
}

fn mpi_exchange_subdomains_1d(
  world_size: i32,
  rank: i32,
  grid: Grid,
  body: fn(i32, [i32 * 3], [i32 * 3], [i32 * 3], [i32 * 3]) -> ()) -> () {

  if(rank < world_size - 1) {
    @@body(
      rank + 1,
      [0, 0, grid.nz - get_comm_time_steps() * 2],
      [grid.nx, grid.ny, grid.nz - get_comm_time_steps()],
      [0, 0, grid.nz - get_comm_time_steps()],
      [grid.nx, grid.ny, grid.nz]
    );
  }

  if(rank > 0) {
    @@body(
      rank - 1,
      [0, 0, get_comm_time_steps()],
      [grid.nx, grid.ny, get_comm_time_steps() * 2],
      [0, 0, 0],
      [grid.nx, grid.ny, get_comm_time_steps()]
    );
  }
}

fn @mpi_get_rank_bounding_box_1d(
  world_size: i32,
  rank: i32,
  cell_spacing: f64,
  grid_aabb: AABB) -> AABB {

  let mut zmin: f64;
  let mut zmax: f64;

  if(world_size > 1) {
    let zcells = math.floor(
      (grid_aabb.max(2) - grid_aabb.min(2)) / cell_spacing
    ) as i32;

    let zlength = (zcells / world_size) as f64 * cell_spacing;

    zmin = grid_aabb.min(2) + zlength * (rank as f64);
    zmax = grid_aabb.min(2) + zlength * ((rank + 1) as f64);

    if(rank > 0) {
      zmin -= (get_comm_time_steps() as f64) * cell_spacing;
    }

    if(rank < world_size - 1) {
      zmax += (get_comm_time_steps() as f64) * cell_spacing;
    } else {
      zmax += cell_spacing;
    }

    /*
    print_i32(rank);
    print_string("- zmin = ");
    print_f64(zmin);
    print_string(", zmax = ");
    print_f64(zmax);
    print_string(", cell_spacing = ");
    print_f64(cell_spacing);
    print_string("\n");
    */
  } else {
    zmin = grid_aabb.min(2);
    zmax = grid_aabb.max(2);
  }

  AABB {
    min: [grid_aabb.min(0), grid_aabb.min(1), zmin],
    max: [grid_aabb.max(0), grid_aabb.max(1), zmax]
  }
}

fn mpi_exchange_subdomains(
  world_size: i32,
  rank: i32,
  grid: Grid,
  body: fn(i32, [i32 * 3], [i32 * 3], [i32 * 3], [i32 * 3]) -> ()) -> () {

  let rank_index = unflat_index(rank, node_dims(0), node_dims(1), node_dims(2));

  if(rank_index(0) < node_dims(0) - 1) {
    @@body(
      flat_index(
        [rank_index(0) + 1, rank_index(1), rank_index(2)],
        node_dims(0), node_dims(1)),
      [grid.nx - get_comm_time_steps() * 2, 0, 0],
      [grid.nx - get_comm_time_steps(), grid.ny, grid.nz],
      [grid.nx - get_comm_time_steps(), 0, 0],
      [grid.nx, grid.ny, grid.nz]
    );
  }

  if(rank_index(0) > 0) {
    @@body(
      flat_index(
        [rank_index(0) - 1, rank_index(1), rank_index(2)],
        node_dims(0), node_dims(1)),
      [get_comm_time_steps(), 0, 0],
      [get_comm_time_steps() * 2, grid.ny, grid.nz],
      [0, 0, 0],
      [get_comm_time_steps(), grid.ny, grid.nz]
    );
  }

  if(rank_index(1) < node_dims(1) - 1) {
    @@body(
      flat_index(
        [rank_index(0), rank_index(1) + 1, rank_index(2)],
        node_dims(0), node_dims(1)),
      [0, grid.ny - get_comm_time_steps() * 2, 0],
      [grid.nx, grid.ny - get_comm_time_steps(), grid.nz],
      [0, grid.ny - get_comm_time_steps(), 0],
      [grid.nx, grid.ny, grid.nz]
    );
  }

  if(rank_index(1) > 0) {
    @@body(
      flat_index(
        [rank_index(0), rank_index(1) - 1, rank_index(2)],
        node_dims(0), node_dims(1)),
      [0, get_comm_time_steps(), 0],
      [grid.nx, get_comm_time_steps() * 2, grid.nz],
      [0, 0, 0],
      [grid.nx, get_comm_time_steps(), grid.nz]
    );
  }

  if(rank_index(2) < node_dims(2) - 1) {
    @@body(
      flat_index(
        [rank_index(0), rank_index(1), rank_index(2) + 1],
        node_dims(0), node_dims(1)),
      [0, 0, grid.nz - get_comm_time_steps() * 2],
      [grid.nx, grid.ny, grid.nz - get_comm_time_steps()],
      [0, 0, grid.nz - get_comm_time_steps()],
      [grid.nx, grid.ny, grid.nz]
    );
  }

  if(rank_index(2) > 0) {
    @@body(
      flat_index(
        [rank_index(0), rank_index(1), rank_index(2) - 1],
        node_dims(0), node_dims(1)),
      [0, 0, get_comm_time_steps()],
      [grid.nx, grid.ny, get_comm_time_steps() * 2],
      [0, 0, 0],
      [grid.nx, grid.ny, get_comm_time_steps()]
    );
  }
}

fn get_node_config(
  world_size: i32,
  rank: i32,
  xcells: i32,
  ycells: i32,
  zcells: i32) -> [i32 * 3] {

  let mut gx = 0;
  let mut gy = 0;
  let mut gz = 0;
  let mut min_missing_factor = xcells * ycells * zcells;

  /*
  print_string("Cells = ");
  print_i32(xcells);
  print_string(", ");
  print_i32(ycells);
  print_string(", ");
  print_i32(zcells);
  print_string("\n");
  */

  for i in range(1, world_size) {
    if(world_size % i == 0) {
      let rem_yz = world_size / i;

      for j in range(1, rem_yz) {
        if(rem_yz % j == 0) {
          let k = rem_yz / j;
          let missing_factor = xcells % i + ycells % j + zcells % k;

          if(min_missing_factor > missing_factor) {
            gx = i;
            gy = j;
            gz = k;
            min_missing_factor = missing_factor;
          }
        }
      }
    }
  }

  /*
  print_string("Found config: (");
  print_i32(gx);
  print_string(", ");
  print_i32(gy);
  print_string(", ");
  print_i32(gz);
  print_string(")\n");

  let uidx = unflat_index(rank, gx, gy, gz);

  print_string("Rank index(");
  print_i32(rank);
  print_string(") = (");
  print_i32(uidx(0));
  print_string(", ");
  print_i32(uidx(1));
  print_string(", ");
  print_i32(uidx(2));
  print_string(") = ");
  print_i32(flat_index(uidx, gx, gy));
  print_string("\n");
  */

  [gx, gy, gz]
}

fn @mpi_get_rank_bounding_box(
  world_size: i32,
  rank: i32,
  cell_spacing: f64,
  aabb: AABB) -> AABB {

  let mut xmin: f64;
  let mut xmax: f64;
  let mut ymin: f64;
  let mut ymax: f64;
  let mut zmin: f64;
  let mut zmax: f64;

  if(world_size > 1) {
    let xcells = math.floor((aabb.max(0) - aabb.min(0)) / cell_spacing) as i32;
    let ycells = math.floor((aabb.max(1) - aabb.min(1)) / cell_spacing) as i32;
    let zcells = math.floor((aabb.max(2) - aabb.min(2)) / cell_spacing) as i32;

    node_dims = get_node_config(world_size, rank, xcells, ycells, zcells);

    let xlength = (xcells / node_dims(0)) as f64 * cell_spacing;
    let ylength = (ycells / node_dims(1)) as f64 * cell_spacing;
    let zlength = (zcells / node_dims(2)) as f64 * cell_spacing;
    let rank_index = unflat_index(rank, node_dims(0), node_dims(1), node_dims(2));

    xmin = aabb.min(0) + zlength * (rank_index(0) as f64);
    xmax = aabb.min(0) + zlength * ((rank_index(0) + 1) as f64);
    ymin = aabb.min(1) + zlength * (rank_index(1) as f64);
    ymax = aabb.min(1) + zlength * ((rank_index(1) + 1) as f64);
    zmin = aabb.min(2) + zlength * (rank_index(2) as f64);
    zmax = aabb.min(2) + zlength * ((rank_index(2) + 1) as f64);

    if(rank_index(0) > 0) {
      xmin -= (get_comm_time_steps() as f64) * cell_spacing;
    }

    if(rank_index(0) < node_dims(0) - 1) {
      xmax += (get_comm_time_steps() as f64) * cell_spacing;
    } else {
      xmax += cell_spacing;
    }

    if(rank_index(1) > 0) {
      ymin -= (get_comm_time_steps() as f64) * cell_spacing;
    }

    if(rank_index(1) < node_dims(1) - 1) {
      ymax += (get_comm_time_steps() as f64) * cell_spacing;
    } else {
      ymax += cell_spacing;
    }

    if(rank_index(2) > 0) {
      zmin -= (get_comm_time_steps() as f64) * cell_spacing;
    }

    if(rank_index(2) < node_dims(2) - 1) {
      zmax += (get_comm_time_steps() as f64) * cell_spacing;
    } else {
      zmax += cell_spacing;
    }

    /*
    print_i32(rank);
    print_string("> xmin = ");
    print_f64(xmin);
    print_string(", xmax = ");
    print_f64(xmax);
    print_string(", ymin = ");
    print_f64(ymin);
    print_string(", ymax = ");
    print_f64(ymax);
    print_string(", zmin = ");
    print_f64(zmin);
    print_string(", zmax = ");
    print_f64(zmax);
    print_string(", cell_spacing = ");
    print_f64(cell_spacing);
    print_string("\n");
    */
  } else {
    xmin = aabb.min(0);
    xmax = aabb.max(0);
    ymin = aabb.min(1);
    ymax = aabb.max(1);
    zmin = aabb.min(2);
    zmax = aabb.max(2);
  }

  AABB {
    min: [xmin, ymin, zmin],
    max: [xmax, ymax, zmax]
  }
}

fn mpi_initialize_grid_comm(
  grid: Grid,
  world_size: i32,
  world_rank: i32) -> () {

  let rank_send_ptr = bitcast[&mut[i32]](rank_send_particles.data);
  let rank_recv_ptr = bitcast[&mut[i32]](rank_recv_particles.data);

  max_send_particles = 0;
  max_recv_particles = 0;

  for exchange_rank, send_begin, send_end, recv_begin, recv_end in
      mpi_exchange_subdomains(world_size, world_rank, grid) {

    rank_send_ptr(exchange_rank) = 0;
    rank_recv_ptr(exchange_rank) = 0;

    for cell, index in
        map_over_grid_subdomain(grid, send_begin, send_end, range, range, range) {
      rank_send_ptr(exchange_rank) += cell.size + cell.padding;
    }

    for cell, index in
        map_over_grid_subdomain(grid, recv_begin, recv_end, range, range, range) {
      rank_recv_ptr(exchange_rank) += cell.size + cell.padding;
    }

    if(max_send_particles < rank_send_ptr(exchange_rank)) {
      max_send_particles = rank_send_ptr(exchange_rank);
    }

    if(max_recv_particles < rank_recv_ptr(exchange_rank)) {
      max_recv_particles = rank_recv_ptr(exchange_rank);
    }
  }
}

fn mpi_pack_ghost_zone(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  accelerator_grid: AcceleratorGrid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> () {

  let mut buffer_ptr = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {
    let flat_index = flatten_index(index, grid);
    let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
    let offset = cell_offsets(flat_index);
    let nparticles = cell.size;

    if(nparticles > 0) {
      buffer_ptr += copy_struct_of_arrays_to_buffer(
        accelerator_grid.positions_cpu, offset,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        accelerator_grid.velocities_cpu, offset,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        accelerator_grid.forces_cpu, offset,
        mpi_buffer, buffer_ptr, nparticles);
    }
  }
}

fn mpi_unpack_ghost_zone(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  accelerator_grid: AcceleratorGrid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> () {

  let mut buffer_ptr = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {
    let flat_index = flatten_index(index, grid);
    let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
    let offset = cell_offsets(flat_index);
    let nparticles = cell.size;

    if(nparticles > 0) {
      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        accelerator_grid.positions_cpu, offset, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        accelerator_grid.velocities_cpu, offset, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        accelerator_grid.forces_cpu, offset, nparticles);
    }
  }
}

fn copy_struct_of_arrays_to_buffer(
  source: StructOfArrays3D,
  offset_source: i32,
  dest: Buffer,
  offset_dest: i32,
  size: i32) -> i32 {

  let offset_ptr = offset_dest * sizeof[real_t]();
  let nbytes = size * sizeof[real_t]();

  copy_offset(
    source.x, offset_source * sizeof[real_t](),
    dest, offset_ptr, nbytes);

  copy_offset(
    source.y, offset_source * sizeof[real_t](),
    dest, offset_ptr + nbytes, nbytes);

  copy_offset(
    source.z, offset_source * sizeof[real_t](),
    dest, offset_ptr + nbytes * 2, nbytes);

  size * 3
}

fn copy_buffer_to_struct_of_arrays(
  source: Buffer,
  offset_source: i32,
  dest: StructOfArrays3D,
  offset_dest: i32,
  size: i32) -> i32 {

  let offset_ptr = offset_source * sizeof[real_t]();
  let nbytes = size * sizeof[real_t]();

  copy_offset(
    source, offset_ptr,
    dest.x, offset_dest * sizeof[real_t](), nbytes);

  copy_offset(
    source, offset_ptr + nbytes,
    dest.y, offset_dest * sizeof[real_t](), nbytes);

  copy_offset(
    source, offset_ptr + nbytes * 2,
    dest.z, offset_dest * sizeof[real_t](), nbytes);

  size * 3
}

fn mpi_synchronize_ghost_zone(
  grid: &mut Grid,
  accelerator_grid: AcceleratorGrid,
  world_size: i32,
  world_rank: i32) -> () {

  let mpih = mpi();
  let mut request: MPI_Request;
  let mut status: MPIStatus;

  let rank_send_ptr = bitcast[&mut[i32]](rank_send_particles.data);
  let rank_recv_ptr = bitcast[&mut[i32]](rank_recv_particles.data);

  let total_number_of_particles =
    accelerator_grid.total_number_of_clusters *
    accelerator_grid.cluster_size;

  resize_mpi_buffers(max_send_particles * 3 * 3, max_recv_particles * 3 * 3);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.positions_accelerator,
    accelerator_grid.positions_cpu,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.velocities_accelerator,
    accelerator_grid.velocities_cpu,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.forces_accelerator,
    accelerator_grid.forces_cpu,
    total_number_of_particles);

  for exchange_rank, send_begin, send_end, recv_begin, recv_end in
      mpi_exchange_subdomains(world_size, world_rank, *grid) {

    if(rank_send_ptr(exchange_rank) > 0) {
      mpi_pack_ghost_zone(
        mpi_send_buffer, grid, accelerator_grid, send_begin, send_end);
    }

    if(rank_recv_ptr(exchange_rank) > 0) {
      mpih.irecv(
        bitcast[&mut[real_t]](mpi_recv_buffer.data) as MPI_MutBuf,
        rank_recv_ptr(exchange_rank) * 3 * 3,
        mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);
    }

    if(rank_send_ptr(exchange_rank) > 0) {
      mpih.send(
        bitcast[&mut[real_t]](mpi_send_buffer.data) as MPI_MutBuf,
        rank_send_ptr(exchange_rank) * 3 * 3,
        mpih.double_t, exchange_rank, 0, mpih.comms.world);
    }

    if(rank_recv_ptr(exchange_rank) > 0) {
      mpih.wait(&mut request, &mut status);

      mpi_unpack_ghost_zone(
        mpi_recv_buffer, grid, accelerator_grid, recv_begin, recv_end);
    }
  }

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.positions_cpu,
    accelerator_grid.positions_accelerator,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.velocities_cpu,
    accelerator_grid.velocities_accelerator,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.forces_cpu,
    accelerator_grid.forces_accelerator,
    total_number_of_particles);
}

fn mpi_pack_exchange_cells(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> i32 {

  let buffer_data = get_array_of_reals(mpi_buffer);
  let mut buffer_ptr = 0;
  let mut particle_counter = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {

    buffer_data(buffer_ptr) = cell.size as real_t;
    buffer_data(buffer_ptr + 1) = cell.padding as real_t;
    buffer_data(buffer_ptr + 2) = cell.cluster_size as real_t;

    buffer_ptr += 3;

    let nparticles = cell.size + cell.padding;

    particle_counter += nparticles;

    if(nparticles > 0) {
      copy_offset(
        cell.masses, 0,
        mpi_buffer, buffer_ptr * sizeof[real_t](), nparticles);

      buffer_ptr += nparticles;

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        cell.positions, 0,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        cell.velocities, 0,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        cell.forces, 0,
        mpi_buffer, buffer_ptr, nparticles);
    }
  }

  particle_counter
}

fn mpi_unpack_exchange_cells(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> i32 {

  let buffer_data = get_array_of_reals(mpi_buffer);
  let mut buffer_ptr = 0;
  let mut particle_counter = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {

    let old_nparticles = cell.size + cell.padding;

    cell.size = buffer_data(buffer_ptr) as i32;
    cell.padding = buffer_data(buffer_ptr + 1) as i32;
    cell.cluster_size = buffer_data(buffer_ptr + 2) as i32;

    buffer_ptr += 3;

    if(cell.size >= cell.capacity) {
      reallocate_cell(cell.size, cell, alloc_cpu);
    }

    let nparticles = cell.size + cell.padding;

    particle_counter += nparticles;
    grid.nparticles += nparticles - old_nparticles;

    if(nparticles > 0) {
      copy_offset(
        mpi_buffer, buffer_ptr * sizeof[real_t](),
        cell.masses, 0, nparticles);

      buffer_ptr += nparticles;

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        cell.positions, 0, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        cell.velocities, 0, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        cell.forces, 0, nparticles);
    }
  }

  particle_counter
}

fn mpi_exchange_ghost_zone(
  grid: &mut Grid,
  world_size: i32,
  world_rank: i32) -> () {

  let mpih = mpi();
  let mut request: MPI_Request;
  let mut status: MPIStatus;

  let rank_send_ptr = bitcast[&mut[i32]](rank_send_particles.data);
  let rank_recv_ptr = bitcast[&mut[i32]](rank_recv_particles.data);

  let send_particles = max_send_particles + max_send_particles / 2;
  let recv_particles = max_recv_particles + max_recv_particles / 2;
  let send_length = send_particles + send_particles * 3 * 3;
  let recv_length = recv_particles + recv_particles * 3 * 3;

  max_send_particles = 0;
  max_recv_particles = 0;

  for exchange_rank, send_begin, send_end, recv_begin, recv_end in
      mpi_exchange_subdomains(world_size, world_rank, *grid) {

    let dims_length = 3 * (send_end(0) - send_begin(0)) *
                          (send_end(1) - send_begin(1)) *
                          (send_end(2) - send_begin(2));

    let rank_send_size =
      rank_send_ptr(exchange_rank) + rank_send_ptr(exchange_rank) / 2;
    let rank_recv_size =
      rank_recv_ptr(exchange_rank) + rank_recv_ptr(exchange_rank) / 2;

    resize_mpi_buffers(dims_length + send_length, dims_length + recv_length);

    rank_send_ptr(exchange_rank) = mpi_pack_exchange_cells(
      mpi_send_buffer, grid, send_begin, send_end);

    mpih.irecv(
      bitcast[&mut[real_t]](mpi_recv_buffer.data) as MPI_MutBuf,
      dims_length + rank_recv_size + rank_recv_size * 3 * 3,
      mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);

    mpih.send(
      bitcast[&mut[real_t]](mpi_send_buffer.data) as MPI_MutBuf,
      dims_length + rank_send_size + rank_send_size * 3 * 3,
      mpih.double_t, exchange_rank, 0, mpih.comms.world);

    mpih.wait(&mut request, &mut status);

    rank_recv_ptr(exchange_rank) = mpi_unpack_exchange_cells(
      mpi_recv_buffer, grid, recv_begin, recv_end);

    if(max_send_particles < rank_send_ptr(exchange_rank)) {
      max_send_particles = rank_send_ptr(exchange_rank);
    }

    if(max_recv_particles < rank_recv_ptr(exchange_rank)) {
      max_recv_particles = rank_recv_ptr(exchange_rank);
    }
  }
}
