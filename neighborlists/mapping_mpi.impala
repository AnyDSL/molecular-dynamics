static mut max_send_particles : i32;
static mut max_recv_particles : i32;
static mut rank_send_particles : [i32 * 8];
static mut rank_recv_particles : [i32 * 8];

fn @get_comm_time_steps() -> i32 { 2 }

fn mpi_initialize(world_size: &mut i32, world_rank: &mut i32) -> () {
  let mpih = mpi();

  mpih.init();

  mpih.comm_size(mpih.comms.world, world_size);
  mpih.comm_rank(mpih.comms.world, world_rank);
}

fn mpi_finalize() -> () {
  let mpih = mpi();

  mpih.finalize();
}

fn mpi_exchange_subdomains(
  world_size: i32,
  rank: i32,
  grid: Grid,
  body: fn(i32, [i32 * 3], [i32 * 3], [i32 * 3], [i32 * 3]) -> ()) -> () {

  if(rank < world_size - 1) {
    body(
      rank + 1,
      [0, 0, grid.nz - get_comm_time_steps() * 2],
      [grid.nx, grid.ny, grid.nz - get_comm_time_steps()],
      [0, 0, grid.nz - get_comm_time_steps()],
      [grid.nx, grid.ny, grid.nz]
    );
  }

  if(rank > 0) {
    body(
      rank - 1,
      [0, 0, get_comm_time_steps()],
      [grid.nx, grid.ny, get_comm_time_steps() * 2],
      [0, 0, 0],
      [grid.nx, grid.ny, get_comm_time_steps()]
    );
  }
}

fn @mpi_get_rank_bounding_box(
  world_size: i32,
  rank: i32,
  cell_spacing: f64,
  grid_aabb: AABB) -> AABB {

  let mut zmin: f64;
  let mut zmax: f64;

  if(world_size > 1) {
    let zcells = math.floor(
      (grid_aabb.max(2) - grid_aabb.min(2)) / cell_spacing
    ) as i32;

    let zlength = (zcells / world_size) as f64 * cell_spacing;

    zmin = grid_aabb.min(2) + zlength * (rank as f64);
    zmax = grid_aabb.min(2) + zlength * ((rank + 1) as f64);

    if(rank > 0) {
      zmin -= (get_comm_time_steps() as f64) * cell_spacing;
    }

    if(rank < world_size - 1) {
      zmax += (get_comm_time_steps() as f64) * cell_spacing;
    } else {
      zmax += cell_spacing;
    }

    /*
    print_i32(rank);
    print_string("- zmin = ");
    print_f64(zmin);
    print_string(", zmax = ");
    print_f64(zmax);
    print_string(", cell_spacing = ");
    print_f64(cell_spacing);
    print_string("\n");
    */
  } else {
    zmin = grid_aabb.min(2);
    zmax = grid_aabb.max(2);
  }

  AABB {
    min: [grid_aabb.min(0), grid_aabb.min(1), zmin],
    max: [grid_aabb.max(0), grid_aabb.max(1), zmax]
  }
}

fn mpi_initialize_grid_comm(
  grid: Grid,
  world_size: i32,
  world_rank: i32) -> () {

  max_send_particles = 0;
  max_recv_particles = 0;

  for exchange_rank, send_begin, send_end, recv_begin, recv_end in
      mpi_exchange_subdomains(world_size, world_rank, grid) {

    rank_send_particles(exchange_rank) = 0;
    rank_recv_particles(exchange_rank) = 0;

    for cell, index in
        map_over_grid_subdomain(grid, send_begin, send_end, range, range, range) {
      rank_send_particles(exchange_rank) += cell.size + cell.padding;
    }

    for cell, index in
        map_over_grid_subdomain(grid, recv_begin, recv_end, range, range, range) {
      rank_recv_particles(exchange_rank) += cell.size + cell.padding;
    }

    if(max_send_particles < rank_send_particles(exchange_rank)) {
      max_send_particles = rank_send_particles(exchange_rank);
    }

    if(max_recv_particles < rank_recv_particles(exchange_rank)) {
      max_recv_particles = rank_recv_particles(exchange_rank);
    }
  }
}

fn mpi_pack_ghost_zone(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  accelerator_grid: AcceleratorGrid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> () {

  let mut buffer_ptr = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {
    let flat_index = flatten_index(index, grid);
    let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
    let offset = cell_offsets(flat_index);
    let nparticles = cell.size + cell.padding;

    if(nparticles > 0) {
      buffer_ptr += copy_struct_of_arrays_to_buffer(
        accelerator_grid.positions_cpu, offset,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        accelerator_grid.velocities_cpu, offset,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        accelerator_grid.forces_cpu, offset,
        mpi_buffer, buffer_ptr, nparticles);
    }
  }
}

fn mpi_unpack_ghost_zone(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  accelerator_grid: AcceleratorGrid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> () {

  let mut buffer_ptr = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {
    let flat_index = flatten_index(index, grid);
    let cell_offsets = get_array_of_i32(accelerator_grid.cell_offsets);
    let offset = cell_offsets(flat_index);
    let nparticles = cell.size + cell.padding;

    if(nparticles > 0) {
      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        accelerator_grid.positions_cpu, offset, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        accelerator_grid.velocities_cpu, offset, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        accelerator_grid.forces_cpu, offset, nparticles);
    }
  }
}

fn copy_struct_of_arrays_to_buffer(
  source: StructOfArrays3D,
  offset_source: i32,
  dest: Buffer,
  offset_dest: i32,
  size: i32) -> i32 {

  let offset_ptr = offset_dest * sizeof[real_t]();
  let nbytes = size * sizeof[real_t]();

  copy_offset(
    source.x, offset_source * sizeof[real_t](),
    dest, offset_ptr, nbytes);

  copy_offset(
    source.y, offset_source * sizeof[real_t](),
    dest, offset_ptr + nbytes, nbytes);

  copy_offset(
    source.z, offset_source * sizeof[real_t](),
    dest, offset_ptr + nbytes * 2, nbytes);

  size * 3
}

fn copy_buffer_to_struct_of_arrays(
  source: Buffer,
  offset_source: i32,
  dest: StructOfArrays3D,
  offset_dest: i32,
  size: i32) -> i32 {

  let offset_ptr = offset_source * sizeof[real_t]();
  let nbytes = size * sizeof[real_t]();

  copy_offset(
    source, offset_ptr,
    dest.x, offset_dest * sizeof[real_t](), nbytes);

  copy_offset(
    source, offset_ptr + nbytes,
    dest.y, offset_dest * sizeof[real_t](), nbytes);

  copy_offset(
    source, offset_ptr + nbytes * 2,
    dest.z, offset_dest * sizeof[real_t](), nbytes);

  size * 3
}

fn mpi_synchronize_ghost_zone(
  grid: &mut Grid,
  accelerator_grid: AcceleratorGrid,
  world_size: i32,
  world_rank: i32) -> () {

  let mpih = mpi();
  let mut request: MPI_Request;
  let mut status: MPIStatus;

  print_i32(world_rank);
  print_string("> alloc_cpu\n");

  let mpi_send_buffer = alloc_cpu(sizeof[real_t]() * (max_send_particles * 3 * 3));
  let mpi_recv_buffer = alloc_cpu(sizeof[real_t]() * (max_recv_particles * 3 * 3));

  print_i32(world_rank);
  print_string("> mpi_synchronize_ghost_zone\n");

  let total_number_of_particles =
    accelerator_grid.total_number_of_clusters *
    accelerator_grid.cluster_size;

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.positions_accelerator,
    accelerator_grid.positions_cpu,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.velocities_accelerator,
    accelerator_grid.velocities_cpu,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.forces_accelerator,
    accelerator_grid.forces_cpu,
    total_number_of_particles);

  for exchange_rank, send_begin, send_end, recv_begin, recv_end in
      mpi_exchange_subdomains(world_size, world_rank, *grid) {

    print_i32(world_rank);
    print_string("> mpi_pack_ghost_zone\n");

    mpi_pack_ghost_zone(
      mpi_send_buffer, grid, accelerator_grid, send_begin, send_end);

    print_i32(world_rank);
    print_string("> mpi_irecv\n");

    mpih.irecv(
      bitcast[&mut[real_t]](mpi_recv_buffer.data) as MPI_MutBuf,
      rank_recv_particles(exchange_rank) * 3 * 3,
      mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);

    print_i32(world_rank);
    print_string("> mpi_send\n");

    mpih.send(
      bitcast[&mut[real_t]](mpi_send_buffer.data) as MPI_MutBuf,
      rank_send_particles(exchange_rank) * 3 * 3,
      mpih.double_t, exchange_rank, 0, mpih.comms.world);

    print_i32(world_rank);
    print_string("> mpi_wait\n");

    mpih.wait(&mut request, &mut status);

    print_i32(world_rank);
    print_string("> mpi_unpack_ghost_zone\n");

    mpi_unpack_ghost_zone(
      mpi_recv_buffer, grid, accelerator_grid, recv_begin, recv_end);
  }

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.positions_cpu,
    accelerator_grid.positions_accelerator,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.velocities_cpu,
    accelerator_grid.velocities_accelerator,
    total_number_of_particles);

  transfer_struct_of_arrays_between_devices(
    accelerator_grid.forces_cpu,
    accelerator_grid.forces_accelerator,
    total_number_of_particles);

  release(mpi_send_buffer);
  release(mpi_recv_buffer);
}

fn mpi_pack_exchange_cells(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> i32 {

  let buffer_data = get_array_of_reals(mpi_buffer);
  let mut buffer_ptr = 0;
  let mut particle_counter = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {

    buffer_data(buffer_ptr) = cell.size as real_t;
    buffer_data(buffer_ptr + 1) = cell.padding as real_t;
    buffer_data(buffer_ptr + 2) = cell.cluster_size as real_t;

    buffer_ptr += 3;

    let nparticles = cell.size + cell.padding;

    particle_counter += nparticles;

    if(nparticles > 0) {
      copy_offset(
        cell.masses, 0,
        mpi_buffer, buffer_ptr * sizeof[real_t](), nparticles);

      buffer_ptr += nparticles;

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        cell.positions, 0,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        cell.velocities, 0,
        mpi_buffer, buffer_ptr, nparticles);

      buffer_ptr += copy_struct_of_arrays_to_buffer(
        cell.forces, 0,
        mpi_buffer, buffer_ptr, nparticles);
    }
  }

  particle_counter
}

fn mpi_unpack_exchange_cells(
  mpi_buffer: Buffer,
  grid: &mut Grid,
  begin: [i32 * 3],
  end: [i32 * 3]) -> i32 {

  let buffer_data = get_array_of_reals(mpi_buffer);
  let mut buffer_ptr = 0;
  let mut particle_counter = 0;

  for cell, index in
      map_over_grid_subdomain(grid, begin, end, range, range, range) {

    let old_nparticles = cell.size + cell.padding;

    cell.size = buffer_data(buffer_ptr) as i32;
    cell.padding = buffer_data(buffer_ptr + 1) as i32;
    cell.cluster_size = buffer_data(buffer_ptr + 2) as i32;

    buffer_ptr += 3;

    if(cell.size >= cell.capacity) {
      reallocate_cell(cell.size, cell, alloc_cpu);
    }

    let nparticles = cell.size + cell.padding;

    particle_counter += nparticles;
    grid.nparticles += nparticles - old_nparticles;

    if(nparticles > 0) {
      copy_offset(
        mpi_buffer, buffer_ptr * sizeof[real_t](),
        cell.masses, 0, nparticles);

      buffer_ptr += nparticles;

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        cell.positions, 0, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        cell.velocities, 0, nparticles);

      buffer_ptr += copy_buffer_to_struct_of_arrays(
        mpi_buffer, buffer_ptr,
        cell.forces, 0, nparticles);
    }
  }

  particle_counter
}

fn mpi_exchange_ghost_zone(
  grid: &mut Grid,
  world_size: i32,
  world_rank: i32) -> () {

  let mpih = mpi();
  let mut request: MPI_Request;
  let mut status: MPIStatus;

  let dims_length = 3 * grid.nx * grid.ny * get_comm_time_steps();
  let send_particles = max_send_particles + max_send_particles / 2;
  let recv_particles = max_recv_particles + max_recv_particles / 2;
  let send_length = send_particles + send_particles * 3 * 3;
  let recv_length = recv_particles + recv_particles * 3 * 3;
  let mpi_send_buffer = alloc_cpu(sizeof[real_t]() * (dims_length + send_length));
  let mpi_recv_buffer = alloc_cpu(sizeof[real_t]() * (dims_length + recv_length));

  max_send_particles = 0;
  max_recv_particles = 0;

  print_i32(world_rank);
  print_string("> mpi_exchange_ghost_zone\n");

  for exchange_rank, send_begin, send_end, recv_begin, recv_end in
      mpi_exchange_subdomains(world_size, world_rank, *grid) {

    let rank_send_size =
      rank_send_particles(exchange_rank) + rank_send_particles(exchange_rank) / 2;
    let rank_recv_size =
      rank_recv_particles(exchange_rank) + rank_recv_particles(exchange_rank) / 2;

    rank_send_particles(exchange_rank) = mpi_pack_exchange_cells(
      mpi_send_buffer, grid, send_begin, send_end);

    mpih.irecv(
      bitcast[&mut[real_t]](mpi_recv_buffer.data) as MPI_MutBuf,
      dims_length + rank_recv_size + rank_recv_size * 3 * 3,
      mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);

    mpih.send(
      bitcast[&mut[real_t]](mpi_send_buffer.data) as MPI_MutBuf,
      dims_length + rank_send_size + rank_send_size * 3 * 3,
      mpih.double_t, exchange_rank, 0, mpih.comms.world);

    mpih.wait(&mut request, &mut status);

    rank_recv_particles(exchange_rank) = mpi_unpack_exchange_cells(
      mpi_recv_buffer, grid, recv_begin, recv_end);

    if(max_send_particles < rank_send_particles(exchange_rank)) {
      max_send_particles = rank_send_particles(exchange_rank);
    }

    if(max_recv_particles < rank_recv_particles(exchange_rank)) {
      max_recv_particles = rank_recv_particles(exchange_rank);
    }
  }

  release(mpi_send_buffer);
  release(mpi_recv_buffer);
}
