fn @is_x86() -> bool { false }
fn @is_sse() -> bool { false }
fn @is_avx() -> bool { false }
fn @is_avx2() -> bool { false }

fn @get_alignment() -> i32 {4}

fn @nvvm_shfldown_i32(var: i32, delta: i32, width: i32) -> i32 {
    let mut res: i32;
    let warp_size = 32; 
    let c = ((warp_size - width) << 8) | 0x1f;
    asm("shfl.down.b32 $0, $1, $2, $3;" : "=r"(res) : "r"(var), "r"(delta as u32), "r"(c));
    res 
}

fn @nvvm_shfldown_f64(var: f64, delta: i32, width: i32) -> f64 {
    let mut res = var;
    let mut lo: u32;
    let mut hi: u32;
    asm("mov.b64 { $0, $1 }, $2;" : "=r"(lo), "=r"(hi) : "d"(res));
    hi = nvvm_shfldown_i32(hi as i32, delta, width) as u32;
    lo = nvvm_shfldown_i32(lo as i32, delta, width) as u32;
    asm("mov.b64 $0, { $1, $2 };" : "=d"(res) : "r"(lo), "r"(hi));
    res 
}

fn @nvvm_shfl_i32(var: i32, srcLane: i32, width: i32) -> i32 {
    let mut res: i32;
    let warp_size = 32; 
    let c = ((warp_size - width) << 8) | 0x1f;
	  asm("shfl.idx.b32 $0, $1, $2, $3;" : "=r"(res) : "r"(var), "r"(srcLane as u32), "r"(c));
    res 
}

fn @nvvm_shfl_f64(var: f64, srcLane: i32, width: i32) -> f64 {
    let mut res = var;
    let mut lo: u32;
    let mut hi: u32;
    asm("mov.b64 { $0, $1 }, $2;" : "=r"(lo), "=r"(hi) : "d"(res));
    hi = nvvm_shfl_i32(hi as i32, srcLane, width) as u32;
    lo = nvvm_shfl_i32(lo as i32, srcLane, width) as u32;
    asm("mov.b64 $0, { $1, $2 };" : "=d"(res) : "r"(lo), "r"(hi));
    res 
}


fn @shuffle(x: real_t, srcLane: i32, laneOffset: i32) -> real_t {
	  nvvm_shfl_f64(x, srcLane, get_cluster_size()) 
}

fn @align(ptr: &[i8], alignment: i32) -> &[i8] {
    ptr
}

fn @accelerator_allocate(size: i32) -> Buffer {
    let acc = accelerator(device_id);
    acc.alloc(size)
}

fn @accelerator_allocate_3d_arrays(N: i32) -> Array3D {
    let acc = accelerator(device_id);
    let size = N * sizeof[real_t]();

    allocate_3d_arrays(size, acc.alloc)
}

fn @transfer_between_devices(source: Buffer, destination: Buffer, size: i32) -> () {
    //copy(source, destination, size);
    copy(source, destination);
}

fn @transfer_3d_arrays_between_devices(source: Array3D, destination: Array3D, N: i32) -> () {
    _transfer_3d_arrays_between_devices(source, destination, N);
}

fn @get_cluster_size() -> i32 {32}

fn loop_accelerator(accelerator_grid: AcceleratorGrid, size: i32, body: fn(i32, i32, i32, i32, i32, &mut[1][i32]) -> ()) -> () {
    let cluster_size = get_cluster_size();
    let acc = accelerator(device_id);
    let grid = (size * cluster_size, 1, 1);
    let block = (cluster_size, 1, 1);

    for work_item in acc.exec(grid, block) {
        let i = work_item.tidx();
        let j = work_item.bidx();
        let cluster_size = work_item.bdimx();
        let begin = i * cluster_size;
        let number_of_neighbors = get_number_of_neighbors(i, accelerator_grid);
        let neighborlist_offset = get_neighborlist_offset(i, accelerator_grid);
        let neighborlists = get_neighborlists(accelerator_grid);

        @@body(i, begin, j, number_of_neighbors, neighborlist_offset, neighborlists);
    }

    /*
    for tid, bid, bdim, gdim, gid in acc.exec(grid, block) {
        let (tidx, _, _) = tid;
        let j = tidx();
        let (bidx, _, _) = bid;
        let i = bidx();
        let (bdimx, _, _) = bdim;
        let cluster_size = bdimx();
        let begin = i * cluster_size;
        let number_of_neighbors = get_number_of_neighbors(i, accelerator_grid);
        let neighborlist_offset = get_neighborlist_offset(i, accelerator_grid);
        let neighborlists = get_neighborlists(accelerator_grid);
        @@body(i, begin, j, number_of_neighbors, neighborlist_offset, neighborlists);
    }
    */

    acc.sync();
}

fn @get_number_of_neighbors(cluster_index: i32, accelerator_grid: AcceleratorGrid) -> i32 {
    get_i32_accelerator(cluster_index, accelerator_grid.neighbors_per_cluster_accelerator)
}

fn @get_neighborlist_offset(cluster_index: i32, accelerator_grid: AcceleratorGrid) -> i32 {
    get_i32_accelerator(cluster_index, accelerator_grid.neighborlist_offsets_accelerator)
}

fn @get_neighborlists(accelerator_grid: AcceleratorGrid) -> &mut[1][i32] {
    get_array_of_i32_accelerator(accelerator_grid.neighborlists_accelerator)
}

fn @get_masses(accelerator_grid: AcceleratorGrid) -> &mut[1][real_t] {
    get_array_of_reals_accelerator(accelerator_grid.masses_accelerator)
}

fn @get_position(i: i32, accelerator_grid: AcceleratorGrid) -> Vector3D {
    get_vector_from_3d_arrays_accelerator(i, accelerator_grid.positions_accelerator)
}

fn @set_position(i: i32, accelerator_grid: AcceleratorGrid, position: Vector3D) -> () {
    set_3d_arrays_accelerator(i, accelerator_grid.positions_accelerator, position)
}

fn @get_velocity(i: i32, accelerator_grid: AcceleratorGrid) -> Vector3D {
    get_vector_from_3d_arrays_accelerator(i, accelerator_grid.velocities_accelerator)
}

fn @set_velocity(i: i32, accelerator_grid: AcceleratorGrid, velocity: Vector3D) -> () {
    set_3d_arrays_accelerator(i, accelerator_grid.velocities_accelerator, velocity)
}

fn @get_force(i: i32, accelerator_grid: AcceleratorGrid) -> Vector3D {
    get_vector_from_3d_arrays_accelerator(i, accelerator_grid.forces_accelerator)
}

fn @set_force(i: i32, accelerator_grid: AcceleratorGrid, force: Vector3D) -> () {
    set_3d_arrays_accelerator(i, accelerator_grid.forces_accelerator, force)
}

fn @reset_force(i: i32, accelerator_grid: AcceleratorGrid) -> () {
    set_3d_arrays_accelerator(i, accelerator_grid.forces_accelerator, Vector3D {x: 0.0 as real_t, y: 0.0 as real_t, z: 0.0 as real_t});
}

fn @add_to_force(i: i32, accelerator_grid: AcceleratorGrid, dF_x: real_t, dF_y: real_t, dF_z: real_t) -> () {
    let mut force = get_vector_from_3d_arrays_accelerator(i, accelerator_grid.forces_accelerator);
    force.x += dF_x;
    force.y += dF_y;
    force.z += dF_z;
    set_3d_arrays_accelerator(i, accelerator_grid.forces_accelerator, force);
}

fn @get_mask_value(i: i32, accelerator_grid: AcceleratorGrid) -> bool {
    get_bool_accelerator(i, accelerator_grid.interaction_mask_accelerator)
}

fn alloc_comm_offsets(world_size: i32, neighs: i32, send_capacity: i32, recv_capacity: i32) -> CommOffsets {
    CommOffsets {
        send_buffers: alloc_comm_offset_buffers(world_size, send_capacity),
        recv_buffers: alloc_comm_offset_buffers(world_size, recv_capacity),
        neighs: neighs
    }
}

fn alloc_comm_offset_buffers(world_size: i32, capacity: i32) -> CommOffsetsBuffers {
    let null_buf = Buffer {
        device: 0,
        data: 0 as &[i8],
        size: 0 as i64
    };

    CommOffsetBuffers {
        buffer_gpu: null_buf,
        rank_offsets: alloc_unaligned_cpu(world_size * sizeof[i32]()),
        start_buf: alloc_unaligned_cpu(capacity * sizeof[i32]()),
        sizes: alloc_unaligned_cpu(capacity * sizeof[i32]()),
        offsets: alloc_unaligned_cpu(capacity * sizeof[i32]()),
        rank_offsets_gpu: accelerator_allocate(world_size * sizeof[i32]()),
        start_buf_gpu: accelerator_allocate(capacity * sizeof[i32]()),
        sizes_gpu: accelerator_allocate(capacity * sizeof[i32]()),
        offsets_gpu: accelerator_allocate(capacity * sizeof[i32]()),
        capacity: send_capacity,
        noffsets: 0,
        length: 0
    }
}

fn release_comm_offsets(comm_offsets: CommOffsets) -> () {
    release_comm_offset_buffers(comm_offsets.send_buffers);
    release_comm_offset_buffers(comm_offsets.recv_buffers);
}

fn release_comm_offset_buffers(comm_offset_buf: CommOffsetsBuffers) -> () {
    if comm_offset_buf.capacity > 0 {
        release(comm_offset_buf.rank_offsets);
        release(comm_offset_buf.start_buf);
        release(comm_offset_buf.sizes);
        release(comm_offset_buf.offsets);
        release(comm_offset_buf.rank_offsets_gpu);
        release(comm_offset_buf.start_buf_gpu);
        release(comm_offset_buf.sizes_gpu);
        release(comm_offset_buf.offsets_gpu);
    }
}

fn build_comm_offsets_accelerator(grid: &Grid, accelerator_grid: &AcceleratorGrid) -> () {
    build_comm_offsets(grid, accelerator_grid);
}

fn gather_ghost_layer_cells(comm_buffer: Buffer, comm_offsets: CommOffsets) -> () {
    let send_buffers = comm_offsets.send_buffers;
    let noffsets = send_buffers.noffsets;
    let length = send_buffers.length;
    let linear_buffer = get_array_of_reals_accelerator(send_buffers.send_buffer_gpu);
    let rank_offsets = get_array_of_i32_accelerator(send_buffers.rank_offsets_gpu);
    let start_buf = get_array_of_i32_accelerator(send_buffers.start_buf_gpu);
    let offsets = get_array_of_i32_accelerator(send_buffers.offsets_gpu);
    let sizes = get_array_of_i32_accelerator(send_buffers.sizes_gpu);

    let acc = accelerator(device_id);
    let grid = (noffsets, 1, 1);
    let block = (64, 1, 1);

    for work_item in acc.exec(grid, block) {
        let th_idx = work_item.bidx() * work_item.bdimx() + work_item.tidx();

        if th_idx < noffsets {
            let start = start_buf(th_idx);
            let offset = offsets(th_idx);
            let size = sizes(th_idx);

            copy_3d_arrays_to_buffer(accelerator_grid.positions_gpu, offset, linear_buffer, start, size);
        }
    }

    copy(send_buffers.buffer_gpu, comm_buffer, length);
}

fn scatter_ghost_layer_cells(comm_buffer: Buffer, comm_offsets: CommOffsets) -> () {
    let recv_buffers = comm_offsets.recv_buffers;
    let noffsets = recv_buffers.noffsets;
    let length = recv_buffers.length;
    let linear_buffer = get_array_of_reals_accelerator(recv_buffers.recv_buffer_gpu);
    let rank_offsets = get_array_of_i32_accelerator(recv_buffers.rank_offsets_gpu);
    let start_buf = get_array_of_i32_accelerator(recv_buffers.start_buf_gpu);
    let offsets = get_array_of_i32_accelerator(recv_buffers.offsets_gpu);
    let sizes = get_array_of_i32_accelerator(recv_buffers.sizes_gpu);

    let acc = accelerator(device_id);
    let grid = (noffsets, 1, 1);
    let block = (64, 1, 1);

    copy(comm_buffer, recv_buffers.buffer_gpu, length);

    for work_item in acc.exec(grid, block) {
        let th_idx = work_item.bidx() * work_item.bdimx() + work_item.tidx();

        if th_idx < noffsets {
            let start = start_buf(th_idx);
            let offset = offsets(th_idx);
            let size = sizes(th_idx);

            copy_buffer_to_3d_arrays(linear_buffer, start, accelerator_grid.positions_gpu, offset, size);
        }
    }
}

// Synchronize ghost layer cells with neighbor ranks
fn synchronize_ghost_layer_cells(
  grid: &mut Grid,
  accelerator_grid: AcceleratorGrid,
  world_size: i32,
  world_rank: i32) -> () {

  let mpih = mpi();
  let mut request: MPI_Request;
  let mut status: MPIStatus;

  let rank_send_ptr = bitcast[&mut[i32]](rank_send_particles.data);
  let rank_recv_ptr = bitcast[&mut[i32]](rank_recv_particles.data);

  let send_buffers = comm_offsets.send_buffers;
  let recv_buffers = comm_offsets.recv_buffers;
  let send_rank_offsets = get_array_of_i32(send_buffers.rank_offsets);
  let recv_rank_offsets = get_array_of_i32(recv_buffers.rank_offsets);
  let send_start_buf = get_array_of_i32(send_buffers.start_buf);
  let recv_start_buf = get_array_of_i32(recv_buffers.start_buf);

  resize_comm_buffers(comm_offsets.neighs * max_send_particles * 3, comm_offsets.neighs * max_recv_particles * 3);
  gather_ghost_layer_cells(comm_send_buffer, comm_offsets);

  for exchange_rank,
      send_begin_x, send_begin_y, send_begin_z,
      send_end_x, send_end_y, send_end_z,
      recv_begin_x, recv_begin_y, recv_begin_z,
      recv_end_x, recv_end_y, recv_end_z in
      communication_nodes(world_size, world_rank, grid) {

    if(rank_recv_ptr(exchange_rank) > 0) {
      let recv_offset = recv_rank_offsets(exchange_rank);
      let start_buf = recv_start_buf(recv_offset);

      mpih.irecv(
        bitcast[&mut[real_t]](comm_recv_buffer.data + start_buf) as MPI_MutBuf,
        rank_recv_ptr(exchange_rank) * 3,
        mpih.double_t, exchange_rank, 0, mpih.comms.world, &mut request);
    }

    if(rank_send_ptr(exchange_rank) > 0) {
      let send_offset = send_rank_offsets(exchange_rank);
      let start_buf = send_start_buf(send_offset);

      mpih.send(
        bitcast[&mut[real_t]](comm_send_buffer.data + start_buf) as MPI_MutBuf,
        rank_send_ptr(exchange_rank) * 3,
        mpih.double_t, exchange_rank, 0, mpih.comms.world);
    }

    if(rank_recv_ptr(exchange_rank) > 0) {
      mpih.wait(&mut request, &mut status);
    }
  }

  scatter_ghost_layer_cells(comm_recv_buffer, comm_offsets);
}
